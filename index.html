
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>The Silicon Scroll | Weekly Research</title>
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@900&family=Libre+Baskerville:wght@400;700&display=swap');
            
            body { background: #f4f1ea; color: #1a1a1a; font-family: 'Libre Baskerville', serif; margin: 0; padding: 2vw; }
            .masthead { text-align: center; border-bottom: 5px double #333; margin-bottom: 40px; padding-bottom: 15px; }
            .masthead h1 { font-family: 'Playfair Display'; font-size: 5rem; margin: 0; letter-spacing: -2px; }
            
            .news-desk { margin-bottom: 50px; }
            .desk-title { 
                border-bottom: 2px solid #333; 
                font-family: 'Playfair Display'; 
                font-size: 1.8rem; 
                margin-bottom: 15px; 
                padding-bottom: 5px; 
                display: flex; 
                justify-content: space-between; 
                align-items: center; 
            }
            .desk-title span { font-size: 0.7rem; font-family: 'Libre Baskerville'; opacity: 0.5; }
            
            .horizontal-scroll { 
                display: flex; 
                overflow-x: auto; 
                gap: 25px; 
                padding-bottom: 20px;
                scrollbar-width: thin;
                scrollbar-color: #333 #f4f1ea;
            }
            
            .horizontal-scroll::-webkit-scrollbar { height: 8px; }
            .horizontal-scroll::-webkit-scrollbar-thumb { background: #333; border-radius: 4px; }

            .card { 
                flex: 0 0 350px; 
                background: #fffefc; 
                border: 1px solid #d1cec1; 
                padding: 25px; 
                box-shadow: 4px 4px 0px rgba(0,0,0,0.05);
                transition: transform 0.2s;
                display: flex;
                flex-direction: column;
            }
            .card:hover { transform: translateY(-5px); }
            
            .card-date { font-size: 10px; font-weight: bold; color: #777; margin-bottom: 10px; }
            h3 { font-family: 'Playfair Display'; font-size: 1.3rem; margin: 0 0 10px 0; line-height: 1.2; }
            h3 a { color: #1a1a1a; text-decoration: none; }
            .meta { font-size: 11px; font-weight: bold; text-transform: uppercase; color: #555; margin-bottom: 10px; display: block; }
            .text { font-size: 13px; line-height: 1.6; color: #333; flex-grow: 1; }

            .ai-accent { border-top: 6px solid #2c3e50; }
            .nlp-accent { border-top: 6px solid #27ae60; }
            .vision-accent { border-top: 6px solid #e67e22; }
        </style>
    </head>
    <body>
        <div class="masthead">
            <div style="font-size: 50px; margin-bottom: 10px;">ðŸ¦‰</div>
            <h1>The Silicon Scroll</h1>
            <p>TEMPE, AZ â€” FEBRUARY 21, 2026 â€” WEEKLY INTELLIGENCE</p>
        </div>
        
        <section class="news-desk">
            <h2 class="desk-title">AI & REINFORCEMENT DESK <span>284 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17544v1" target="_blank">ðŸ”¥ Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability</a></h3>
                <p class="meta">By Shashank Aggarwal, Ram Vikas Mishra</p>
                <p class="text">In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17452v1" target="_blank">ðŸ”¥ Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge</a></h3>
                <p class="meta">By Wyatt Benno, Alberto Centelles</p>
                <p class="text">We present Jolt Atlas, a zero-knowledge machine learning (zkML) framework that extends the Jolt proving system to model inference. Unlike zkVMs (zero-knowledge virtual machines), which emulate CPU instruction execution, Jolt Atlas adapts Jolt's lookup-centric approach and applies...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17308v1" target="_blank">ðŸ”¥ MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions</a></h3>
                <p class="meta">By Hui Min Wong, Philip Heesen</p>
                <p class="text">Large language models (LLMs) are increasingly used for diagnostic tasks in medicine. In clinical practice, the correct diagnosis can rarely be immediately inferred from the initial patient presentation alone. Rather, reaching a diagnosis often involves systematic history taking, ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17245v1" target="_blank">ðŸ”¥ Web Verbs: Typed Abstractions for Reliable Task Composition on the Agentic Web</a></h3>
                <p class="meta">By Linxi Jiang, Rui Xi</p>
                <p class="text">The Web is evolving from a medium that humans browse to an environment where software agents act on behalf of users. Advances in large language models (LLMs) make natural language a practical interface for goal-directed tasks, yet most current web agents operate on low-level prim...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17221v1" target="_blank">ðŸ”¥ From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences</a></h3>
                <p class="meta">By Yi-Chih Huang</p>
                <p class="text">Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a "methodological experiment," this study propose...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17096v1" target="_blank">ðŸ”¥ Agentic Wireless Communication for 6G: Intent-Aware and Continuously Evolving Physical-Layer Intelligence</a></h3>
                <p class="meta">By Zhaoyang Li, Xingzhi Jin</p>
                <p class="text">As 6G wireless systems evolve, growing functional complexity and diverse service demands are driving a shift from rule-based control to intent-driven autonomous intelligence. User requirements are no longer captured by a single metric (e.g., throughput or reliability), but by mul...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17062v1" target="_blank">ðŸ”¥ Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning</a></h3>
                <p class="meta">By Yonghyeon Jo, Sunwoo Lee</p>
                <p class="text">Value decomposition is a core approach for cooperative multi-agent reinforcement learning (MARL). However, existing methods still rely on a single optimal action and struggle to adapt when the underlying value function shifts during training, often converging to suboptimal polici...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17049v1" target="_blank">ðŸ”¥ IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents</a></h3>
                <p class="meta">By Seoyoung Lee, Seobin Yoon</p>
                <p class="text">Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17038v1" target="_blank">ðŸ”¥ Phase-Aware Mixture of Experts for Agentic Reinforcement Learning</a></h3>
                <p class="meta">By Shengtian Yang, Yu Li</p>
                <p class="text">Reinforcement learning (RL) has equipped LLM agents with a strong ability to solve complex tasks. However, existing RL methods normally use a \emph{single} policy network, causing \emph{simplicity bias} where simple tasks occupy most parameters and dominate gradient updates, leav...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17037v1" target="_blank">ðŸ”¥ Wink: Recovering from Misbehaviors in Coding Agents</a></h3>
                <p class="meta">By Rahul Nanda, Chandra Maddila</p>
                <p class="text">Autonomous coding agents, powered by large language models (LLMs), are increasingly being adopted in the software industry to automate complex engineering tasks. However, these agents are prone to a wide range of misbehaviors, such as deviating from the user's instructions, getti...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.16966v1" target="_blank">ðŸ”¥ A Unified Framework for Locality in Scalable MARL</a></h3>
                <p class="meta">By Sourav Chakraborty, Amit Kiran Rege</p>
                <p class="text">Scalable Multi-Agent Reinforcement Learning (MARL) is fundamentally challenged by the curse of dimensionality. A common solution is to exploit locality, which hinges on an Exponential Decay Property (EDP) of the value function. However, existing conditions that guarantee the EDP ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16953v1" target="_blank">ðŸ”¥ LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation</a></h3>
                <p class="meta">By Hejia Zhang, Zhongming Yu</p>
                <p class="text">Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its relianc...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16928v1" target="_blank">ðŸ”¥ Discovering Multiagent Learning Algorithms with Large Language Models</a></h3>
                <p class="meta">By Zun Li, John Schultz</p>
                <p class="text">Much of the advancement of Multi-Agent Reinforcement Learning (MARL) in imperfect-information games has historically depended on manual iterative refinement of baselines. While foundational families like Counterfactual Regret Minimization (CFR) and Policy Space Response Oracles (...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16873v1" target="_blank">ðŸ”¥ AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence</a></h3>
                <p class="meta">By Geunbin Yu</p>
                <p class="text">As large language models from diverse providers converge toward comparable benchmark performance, the traditional paradigm of selecting a single best model per task yields diminishing returns. We argue that orchestration topology -- the structural composition of how multiple agen...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16844v1" target="_blank">ðŸ”¥ Overseeing Agents Without Constant Oversight: Challenges and Opportunities</a></h3>
                <p class="meta">By Madeleine Grunde-McLaughlin, Hussein Mozannar</p>
                <p class="text">To enable human oversight, agentic AI systems often provide a trace of reasoning and action steps. Designing traces to have an informative, but not overwhelming, level of detail remains a critical challenge. In three user studies on a Computer User Agent, we investigate the utili...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16708v2" target="_blank">ðŸ”¥ Policy Compiler for Secure Agentic Systems</a></h3>
                <p class="meta">By Nils Palumbo, Sarthak Choudhary</p>
                <p class="text">LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We p...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16666v1" target="_blank">ðŸ”¥ Towards a Science of AI Agent Reliability</a></h3>
                <p class="meta">By Stephan Rabanser, Sayash Kapoor</p>
                <p class="text">AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing age...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16554v1" target="_blank">ðŸ”¥ MerLean: An Agentic Framework for Autoformalization in Quantum Computation</a></h3>
                <p class="meta">By Yuanjie Ren, Jinzheng Li</p>
                <p class="text">We introduce MerLean, a fully automated agentic framework for autoformalization in quantum computation. MerLean extracts mathematical statements from \LaTeX{} source files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into human-reada...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16435v1" target="_blank">ðŸ”¥ Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning</a></h3>
                <p class="meta">By Arun Vignesh Malarkkan, Wangyang Ying</p>
                <p class="text">Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a fr...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16301v1" target="_blank">ðŸ”¥ Multi-agent cooperation through in-context co-player inference</a></h3>
                <p class="meta">By Marissa A. Weis, Maciej WoÅ‚czyk</p>
                <p class="text">Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16246v1" target="_blank">ðŸ”¥ Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents</a></h3>
                <p class="meta">By Yun-Shiuan Chuang, Chaitanya Kulkarni</p>
                <p class="text">Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-be...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16196v1" target="_blank">ðŸ”¥ Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning</a></h3>
                <p class="meta">By Emile Anand, Richard Hoffmann</p>
                <p class="text">Coordinating large populations of interacting agents is a central challenge in multi-agent reinforcement learning (MARL), where the size of the joint state-action space scales exponentially with the number of agents. Mean-field methods alleviate this burden by aggregating agent i...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16179v2" target="_blank">ðŸ”¥ EnterpriseBench Corecraft: Training Generalizable Agents on High-Fidelity RL Environments</a></h3>
                <p class="meta">By Sushant Mehta, Logan Ritchie</p>
                <p class="text">We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce CoreCraft, the first environment in EnterpriseBench, Surge AI's suite of agentic RL environments. CoreCraft is...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15763v1" target="_blank">ðŸ”¥ GLM-5: from Vibe Coding to Agentic Engineering</a></h3>
                <p class="meta">By GLM-5 Team,  :</p>
                <p class="text">We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15721v1" target="_blank">ðŸ”¥ Lifelong Scalable Multi-Agent Realistic Testbed and A Comprehensive Study on Design Choices in Lifelong AGV Fleet Management Systems</a></h3>
                <p class="meta">By Jingtian Yan, Yulun Zhang</p>
                <p class="text">We present Lifelong Scalable Multi-Agent Realistic Testbed (LSMART), an open-source simulator to evaluate any Multi-Agent Path Finding (MAPF) algorithm in a Fleet Management System (FMS) with Automated Guided Vehicles (AGVs). MAPF aims to move a group of agents from their corresp...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15549v1" target="_blank">ðŸ”¥ VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing</a></h3>
                <p class="meta">By Guoqin Tang, Qingxuan Jia</p>
                <p class="text">Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17641v1" target="_blank">ðŸ”¥ FAMOSE: A ReAct Approach to Automated Feature Discovery</a></h3>
                <p class="meta">By Keith Burghardt, Jienan Liu</p>
                <p class="text">Feature engineering remains a critical yet challenging bottleneck in machine learning, particularly for tabular data, as identifying optimal features from an exponentially large feature space traditionally demands substantial domain expertise. To address this challenge, we introd...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17607v1" target="_blank">ðŸ”¥ AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing</a></h3>
                <p class="meta">By Jianda Du, Youran Sun</p>
                <p class="text">PDEs are central to scientific and engineering modeling, yet designing accurate numerical solvers typically requires substantial mathematical expertise and manual tuning. Recent neural network-based approaches improve flexibility but often demand high computational cost and suffe...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17547v1" target="_blank">ðŸ”¥ KLong: Training LLM Agent for Extremely Long-horizon Tasks</a></h3>
                <p class="meta">By Yue Liu, Zhiyuan Hu</p>
                <p class="text">This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17536v1" target="_blank">ðŸ”¥ Toward a Fully Autonomous, AI-Native Particle Accelerator</a></h3>
                <p class="meta">By Chris Tennant</p>
                <p class="text">This position paper presents a vision for self-driving particle accelerators that operate autonomously with minimal human intervention. We propose that future facilities be designed through artificial intelligence (AI) co-design, where AI jointly optimizes the accelerator lattice...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">NLP & LANGUAGE DESK <span>102 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17127v1" target="_blank">ðŸ”¥ The Emergence of Lab-Driven Alignment Signatures: A Psychometric Framework for Auditing Latent Bias and Compounding Risk in Generative AI</a></h3>
                <p class="meta">By Dusan Bosnjakovic</p>
                <p class="text">As Large Language Models (LLMs) transition from standalone chat interfaces to foundational reasoning layers in multi-agent systems and recursive evaluation loops (LLM-as-a-judge), the detection of durable, provider-level behavioral signatures becomes a critical requirement for sa...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16485v1" target="_blank">ðŸ”¥ Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling</a></h3>
                <p class="meta">By Jeffrey T. H. Wong, Zixi Zhang</p>
                <p class="text">Existing Multi-Agent Systems (MAS) typically rely on static, homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16313v1" target="_blank">ðŸ”¥ MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks</a></h3>
                <p class="meta">By Zexue He, Yu Wang</p>
                <p class="text">Existing evaluations of agents with memory typically assess memorization and action in isolation. One class of benchmarks evaluates memorization by testing recall of past conversations or text but fails to capture how memory is used to guide future decisions. Another class focuse...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17588v1" target="_blank">ðŸ”¥ Modeling Distinct Human Interaction in Web Agents</a></h3>
                <p class="meta">By Faria Huq, Zora Zhiruo Wang</p>
                <p class="text">Despite rapid progress in autonomous web agents, human involvement remains essential for shaping preferences and correcting agent behavior as tasks unfold. However, current agentic systems lack a principled understanding of when and why humans intervene, often proceeding autonomo...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16429v1" target="_blank">ðŸ”¥ TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers</a></h3>
                <p class="meta">By Ido Levy, Eilam Shapira</p>
                <p class="text">Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing, shortlisting, gating, and verification. While convenient, this...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16379v1" target="_blank">ðŸ”¥ Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents</a></h3>
                <p class="meta">By Mohammad H. A. Monfared, Lucie Flek</p>
                <p class="text">We propose an agentic data augmentation method for Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched prompting-b...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17623v1" target="_blank">âš¡ Unmasking the Factual-Conceptual Gap in Persian Language Models</a></h3>
                <p class="meta">By Alireza Sakhaeirad, Ali Ma'manpoosh</p>
                <p class="text">While emerging Persian NLP benchmarks have expanded into pragmatics and politeness, they rarely distinguish between memorized cultural facts and the ability to reason about implicit social norms. We introduce DivanBench, a diagnostic benchmark focused on superstitions and customs...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17546v1" target="_blank">âš¡ Learning to Stay Safe: Adaptive Regularization Against Safety Degradation during Fine-Tuning</a></h3>
                <p class="meta">By Jyotin Goel, Souvik Maji</p>
                <p class="text">Instruction-following language models are trained to be helpful and safe, yet their safety behavior can deteriorate under benign fine-tuning and worsen under adversarial updates. Existing defenses often offer limited protection or force a trade-off between safety and utility. We ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17443v1" target="_blank">âš¡ AIDG: Evaluating Asymmetry Between Information Extraction and Containment in Multi-Turn Dialogue</a></h3>
                <p class="meta">By Adib Sakhawat, Fardeen Sadab</p>
                <p class="text">Evaluating the strategic reasoning capabilities of Large Language Models (LLMs) requires moving beyond static benchmarks to dynamic, multi-turn interactions. We introduce AIDG (Adversarial Information Deduction Game), a game-theoretic framework that probes the asymmetry between i...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17072v1" target="_blank">âš¡ BankMathBench: A Benchmark for Numerical Reasoning in Banking Scenarios</a></h3>
                <p class="meta">By Yunseung Lee, Subin Kim</p>
                <p class="text">Large language models (LLMs)-based chatbots are increasingly being adopted in the financial domain, particularly in digital banking, to handle customer inquiries about products such as deposits, savings, and loans. However, these models still exhibit low accuracy in core banking ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17054v1" target="_blank">âš¡ ALPS: A Diagnostic Challenge Set for Arabic Linguistic & Pragmatic Reasoning</a></h3>
                <p class="meta">By Hussein S. Al-Olimat, Ahmad Alshareef</p>
                <p class="text">While recent Arabic NLP benchmarks focus on scale, they often rely on synthetic or translated data which may benefit from deeper linguistic verification. We introduce ALPS (Arabic Linguistic & Pragmatic Suite), a native, expert-curated diagnostic challenge set probing Deep Semant...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17045v1" target="_blank">âš¡ Large Language Models Persuade Without Planning Theory of Mind</a></h3>
                <p class="meta">By Jared Moore, Rasmus Overmark</p>
                <p class="text">A growing body of work attempts to evaluate the theory of mind (ToM) abilities of humans and large language models (LLMs) using static, non-interactive question-and-answer benchmarks. However, theoretical work in the field suggests that first-personal interaction is a crucial par...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17022v1" target="_blank">âš¡ ReIn: Conversational Error Recovery with Reasoning Inception</a></h3>
                <p class="meta">By Takyoung Kim, Jinseok Nam</p>
                <p class="text">Conversational agents powered by large language models (LLMs) with tool integration achieve strong performance on fixed task-oriented dialogue datasets but remain vulnerable to unanticipated, user-induced errors. Rather than focusing on error prevention, this work focuses on erro...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17003v1" target="_blank">âš¡ Persona2Web: Benchmarking Personalized Web Agents for Contextual Reasoning with User History</a></h3>
                <p class="meta">By Serin Kim, Sangam Lee</p>
                <p class="text">Large language models have advanced web agents, yet current agents lack personalization capabilities. Since users rarely specify every detail of their intent, practical web agents must be able to interpret ambiguous queries by inferring user preferences and contexts. To address t...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16802v1" target="_blank">âš¡ References Improve LLM Alignment in Non-Verifiable Domains</a></h3>
                <p class="meta">By Kejian Shi, Yixin Liu</p>
                <p class="text">While Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong effectiveness in reasoning tasks, it cannot be directly applied to non-verifiable domains lacking ground-truth verifiers, such as LLM alignment. In this work, we investigate whether reference-guided LLM-...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16704v1" target="_blank">âš¡ Reinforced Fast Weights with Next-Sequence Prediction</a></h3>
                <p class="meta">By Hee Seung Hwang, Xindi Wu</p>
                <p class="text">Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP op...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16516v1" target="_blank">âš¡ Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification</a></h3>
                <p class="meta">By Taja Kuzman PungerÅ¡ek, Peter Rupnik</p>
                <p class="text">This paper introduces ParlaCAP, a large-scale dataset for analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the multilingual Pa...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16490v1" target="_blank">âš¡ From Growing to Looping: A Unified View of Iterative Computation in LLMs</a></h3>
                <p class="meta">By Ferdinand Kapl, Emmanouil Angelis</p>
                <p class="text">Looping, reusing a block of layers across depth, and depth growing, training shallow-to-deep models by duplicating middle layers, have both been linked to stronger reasoning, but their relationship remains unclear. We provide a mechanistic unification: looped and depth-grown mode...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16467v1" target="_blank">âš¡ IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models</a></h3>
                <p class="meta">By Saurabh Bharti, Gaurav Azad</p>
                <p class="text">The rapid advancement of large language models (LLMs) necessitates evaluation frameworks that reflect real-world academic rigor and multilingual complexity. This paper introduces IndicEval, a scalable benchmarking platform designed to assess LLM performance using authentic high-s...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16162v1" target="_blank">âš¡ LLMs Exhibit Significantly Lower Uncertainty in Creative Writing Than Professional Writers</a></h3>
                <p class="meta">By Peiqi Sui</p>
                <p class="text">We argue that uncertainty is a key and understudied limitation of LLMs' performance in creative writing, which is often characterized as trite and clichÃ©-ridden. Literary theory identifies uncertainty as a necessary condition for creative expression, while current alignment strat...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16154v1" target="_blank">âš¡ Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution</a></h3>
                <p class="meta">By Nithin Sivakumaran, Shoubin Yu</p>
                <p class="text">Chain-of-thought (CoT) reasoning sometimes fails to faithfully reflect the true computation of a large language model (LLM), hampering its utility in explaining how LLMs arrive at their answers. Moreover, optimizing for faithfulness and interpretability in reasoning often degrade...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.16093v1" target="_blank">âš¡ Updating Parametric Knowledge with Context Distillation Retains Post-Training Capabilities</a></h3>
                <p class="meta">By Shankar Padmanabhan, Mustafa Omer Gul</p>
                <p class="text">Post-training endows pretrained LLMs with a variety of desirable skills, including instruction-following, reasoning, and others. However, these post-trained LLMs only encode knowledge up to a cut-off date, necessitating continual adaptation. Unfortunately, existing solutions cann...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.16085v1" target="_blank">âš¡ Language Statistics and False Belief Reasoning: Evidence from 41 Open-Weight LMs</a></h3>
                <p class="meta">By Sean Trott, Samuel Taylor</p>
                <p class="text">Research on mental state reasoning in language models (LMs) has the potential to inform theories of human social cognition--such as the theory that mental state reasoning emerges in part from language exposure--and our understanding of LMs themselves. Yet much published work on L...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15689v2" target="_blank">âš¡ A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models</a></h3>
                <p class="meta">By Noa Linder, Meirav Segal</p>
                <p class="text">Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15620v2" target="_blank">âš¡ STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens</a></h3>
                <p class="meta">By Shiqi Liu, Zeyu He</p>
                <p class="text">Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often suffer from late-stage per...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15564v1" target="_blank">âš¡ Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL</a></h3>
                <p class="meta">By Yihan Wang, Peiyu Liu</p>
                <p class="text">Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of re...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15449v1" target="_blank">âš¡ TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models</a></h3>
                <p class="meta">By Chansung Park, Juyong Jiang</p>
                <p class="text">Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Re...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17664v1" target="_blank">Sink-Aware Pruning for Diffusion Language Models</a></h3>
                <p class="meta">By Aidar Myrzakhan, Tianyi Li</p>
                <p class="text">Diffusion Language Models (DLMs) incur high inference cost due to iterative denoising, motivating efficient pruning. Existing pruning heuristics largely inherited from autoregressive (AR) LLMs, typically preserve attention sink tokens because AR sinks serve as stable global ancho...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17655v1" target="_blank">What Language is This? Ask Your Tokenizer</a></h3>
                <p class="meta">By Clara Meister, Ahmetcan Yavuz</p>
                <p class="text">Language Identification (LID) is an important component of many multilingual natural language processing pipelines, where it facilitates corpus curation, training data analysis, and cross-lingual evaluation of large language models. Despite near-perfect performance on high-resour...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17653v1" target="_blank">Differences in Typological Alignment in Language Models' Treatment of Differential Argument Marking</a></h3>
                <p class="meta">By Iskar Deng, Nathalia Xu</p>
                <p class="text">Recent work has shown that language models (LMs) trained on synthetic corpora can exhibit typological preferences that resemble cross-linguistic regularities in human languages, particularly for syntactic phenomena such as word order. In this paper, we extend this paradigm to dif...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">VISION & MULTIMODAL DESK <span>114 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17030v1" target="_blank">ðŸ”¥ Patch-Based Spatial Authorship Attribution in Human-Robot Collaborative Paintings</a></h3>
                <p class="meta">By Eric Chen, Patricia Alves-Oliveira</p>
                <p class="text">As agentic AI becomes increasingly involved in creative production, documenting authorship has become critical for artists, collectors, and legal contexts. We present a patch-based framework for spatial authorship attribution within human-robot collaborative painting practice, de...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17665v1" target="_blank">âš¡ OpenEarthAgent: A Unified Framework for Tool-Augmented Geospatial Agents</a></h3>
                <p class="meta">By Akashah Shabbir, Muhammad Umer Sheikh</p>
                <p class="text">Recent progress in multimodal reasoning has enabled agents that can interpret imagery, connect it with language, and perform structured analytical tasks. Extending such capabilities to the remote sensing domain remains challenging, as models must reason over spatial scale, geogra...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17659v1" target="_blank">âš¡ When Vision Overrides Language: Evaluating and Mitigating Counterfactual Failures in VLAs</a></h3>
                <p class="meta">By Yu Fang, Yuchun Feng</p>
                <p class="text">Vision-Language-Action models (VLAs) promise to ground language instructions in robot control, yet in practice often fail to faithfully follow language. When presented with instructions that lack strong scene-specific supervision, VLAs suffer from counterfactual failures: they ac...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17605v1" target="_blank">âš¡ Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery</a></h3>
                <p class="meta">By Jowaria Khan, Anindya Sarkar</p>
                <p class="text">In many real-world settings, such as environmental monitoring, disaster response, or public health, with costly and difficult data collection and dynamic environments, strategically sampling from unobserved regions is essential for efficiently uncovering hidden targets under tigh...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17558v1" target="_blank">âš¡ RetouchIQ: MLLM Agents for Instruction-Based Image Retouching with Generalist Reward</a></h3>
                <p class="meta">By Qiucheng Wu, Jing Shi</p>
                <p class="text">Recent advances in multimodal large language models (MLLMs) have shown great potential for extending vision-language reasoning to professional tool-based image editing, enabling intuitive and creative editing. A promising direction is to use reinforcement learning (RL) to enable ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17555v1" target="_blank">âš¡ GraphThinker: Reinforcing Video Reasoning with Event Graph Thinking</a></h3>
                <p class="meta">By Zixu Cheng, Da Li</p>
                <p class="text">Video reasoning requires understanding the causal relationships between events in a video. However, such relationships are often implicit and costly to annotate manually. While existing multimodal large language models (MLLMs) often infer event relations through dense captions or...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17134v1" target="_blank">âš¡ B$^3$-Seg: Camera-Free, Training-Free 3DGS Segmentation via Analytic EIG and Beta-Bernoulli Bayesian Updates</a></h3>
                <p class="meta">By Hiromichi Kamata, Samuel Arthur Munro</p>
                <p class="text">Interactive 3D Gaussian Splatting (3DGS) segmentation is essential for real-time editing of pre-reconstructed assets in film and game production. However, existing methods rely on predefined camera viewpoints, ground-truth labels, or costly retraining, making them impractical for...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16702v1" target="_blank">âš¡ Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning</a></h3>
                <p class="meta">By Mingjia Shi, Yinhan He</p>
                <p class="text">Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16682v1" target="_blank">âš¡ Learning Situated Awareness in the Real World</a></h3>
                <p class="meta">By Chuhan Li, Ruilin Han</p>
                <p class="text">A core aspect of human perception is situated awareness, the ability to relate ourselves to the surrounding physical environment and reason over possible actions in context. However, most existing benchmarks for multimodal foundation models (MFMs) emphasize environment-centric sp...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16669v1" target="_blank">âš¡ PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction</a></h3>
                <p class="meta">By Bo Lang, Nirav Savaliya</p>
                <p class="text">High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which le...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16455v1" target="_blank">âš¡ Visual Self-Refine: A Pixel-Guided Paradigm for Accurate Chart Parsing</a></h3>
                <p class="meta">By Jinsong Li, Xiaoyi Dong</p>
                <p class="text">While Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities for reasoning and self-correction at the textual level, these strengths provide minimal benefits for complex tasks centered on visual perception, such as Chart Parsing. Existing models often stru...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16160v1" target="_blank">âš¡ Uncertainty-Guided Inference-Time Depth Adaptation for Transformer-Based Visual Tracking</a></h3>
                <p class="meta">By Patrick Poggi, Divake Kumar</p>
                <p class="text">Transformer-based single-object trackers achieve state-of-the-art accuracy but rely on fixed-depth inference, executing the full encoder--decoder stack for every frame regardless of visual complexity, thereby incurring unnecessary computational cost in long video sequences domina...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16110v1" target="_blank">âš¡ OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis</a></h3>
                <p class="meta">By Tianwei Lin, Zhongwei Qiu</p>
                <p class="text">Computed Tomography (CT) is one of the most widely used and diagnostically information-dense imaging modalities, covering critical organs such as the heart, lungs, liver, and colon. Clinical interpretation relies on both slice-driven local features (e.g., sub-centimeter nodules, ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15950v1" target="_blank">âš¡ Can Vision-Language Models See Squares? Text-Recognition Mediates Spatial Reasoning Across Three Model Families</a></h3>
                <p class="meta">By Yuval Levental</p>
                <p class="text">We present a simple experiment that exposes a fundamental limitation in vision-language models (VLMs): the inability to accurately localize filled cells in binary grids when those cells lack textual identity. We generate fifteen 15x15 grids with varying density (10.7%-41.8% fille...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15819v1" target="_blank">âš¡ VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation</a></h3>
                <p class="meta">By Hui Ren, Yuval Alaluf</p>
                <p class="text">Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. We present a data-effic...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15775v1" target="_blank">âš¡ NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy</a></h3>
                <p class="meta">By Laura Salort-Benejam, Antonio Agudo</p>
                <p class="text">Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15724v1" target="_blank">âš¡ Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation</a></h3>
                <p class="meta">By Shutian Gu, Chengkai Huang</p>
                <p class="text">Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning c...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15556v1" target="_blank">âš¡ Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs</a></h3>
                <p class="meta">By Guangtao Lyu, Qi Liu</p>
                <p class="text">LVLMs have achieved strong multimodal reasoning capabilities but remain prone to hallucinations, producing outputs inconsistent with visual inputs or user instructions. Existing training-free methods, including contrastive decoding and auxiliary expert models, which incur several...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15461v1" target="_blank">âš¡ Emergent Morphing Attack Detection in Open Multi-modal Large Language Models</a></h3>
                <p class="meta">By Marija Ivanovska, Vitomir Å truc</p>
                <p class="text">Face morphing attacks threaten biometric verification, yet most morphing attack detection (MAD) systems require task-specific training and generalize poorly to unseen attack types. Meanwhile, open-source multimodal large language models (MLLMs) have demonstrated strong visual-lin...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17650v1" target="_blank">Human-level 3D shape perception emerges from multi-view learning</a></h3>
                <p class="meta">By Tyler Bonnen, Jitendra Malik</p>
                <p class="text">Humans can infer the three-dimensional structure of objects from two-dimensional visual inputs. Modeling this ability has been a longstanding goal for the science and engineering of visual intelligence, yet decades of computational methods have fallen short of human performance. ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17639v1" target="_blank">IntRec: Intent-based Retrieval with Contrastive Refinement</a></h3>
                <p class="meta">By Pourya Shamsolmoali, Masoumeh Zareapoor</p>
                <p class="text">Retrieving user-specified objects from complex scenes remains a challenging task, especially when queries are ambiguous or involve multiple similar objects. Existing open-vocabulary detectors operate in a one-shot manner, lacking the ability to refine predictions based on user fe...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17636v1" target="_blank">CORAL: Correspondence Alignment for Improved Virtual Try-On</a></h3>
                <p class="meta">By Jiyoung Kim, Youngjin Shin</p>
                <p class="text">Existing methods for Virtual Try-On (VTON) often struggle to preserve fine garment details, especially in unpaired settings where accurate person-garment correspondence is required. These methods do not explicitly enforce person-garment alignment and fail to explain how correspon...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17599v1" target="_blank">Art2Mus: Artwork-to-Music Generation via Visual Conditioning and Large-Scale Cross-Modal Alignment</a></h3>
                <p class="meta">By Ivan Rinaldi, Matteo Mendula</p>
                <p class="text">Music generation has advanced markedly through multimodal deep learning, enabling models to synthesize audio from text and, more recently, from images. However, existing image-conditioned systems suffer from two fundamental limitations: (i) they are typically trained on natural p...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17535v1" target="_blank">LATA: Laplacian-Assisted Transductive Adaptation for Conformal Uncertainty in Medical VLMs</a></h3>
                <p class="meta">By Behzad Bozorgtabar, Dwarikanath Mahapatra</p>
                <p class="text">Medical vision-language models (VLMs) are strong zero-shot recognizers for medical imaging, but their reliability under domain shift hinges on calibrated uncertainty with guarantees. Split conformal prediction (SCP) offers finite-sample coverage, yet prediction sets often become ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17517v1" target="_blank">FoundationPose-Initialized 3D-2D Liver Registration for Surgical Augmented Reality</a></h3>
                <p class="meta">By Hanyuan Zhang, Lucas He</p>
                <p class="text">Augmented reality can improve tumor localization in laparoscopic liver surgery. Existing registration pipelines typically depend on organ contours; deformable (non-rigid) alignment is often handled with finite-element (FE) models coupled to dimensionality-reduction or machine-lea...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17484v1" target="_blank">Tracing Copied Pixels and Regularizing Patch Affinity in Copy Detection</a></h3>
                <p class="meta">By Yichen Lu, Siwei Nie</p>
                <p class="text">Image Copy Detection (ICD) aims to identify manipulated content between image pairs through robust feature representation learning. While self-supervised learning (SSL) has advanced ICD systems, existing view-level contrastive methods struggle with sophisticated edits due to insu...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17478v1" target="_blank">QuPAINT: Physics-Aware Instruction Tuning Approach to Quantum Material Discovery</a></h3>
                <p class="meta">By Xuan-Bac Nguyen, Hoang-Quan Nguyen</p>
                <p class="text">Characterizing two-dimensional quantum materials from optical microscopy images is challenging due to the subtle layer-dependent contrast, limited labeled data, and significant variation across laboratories and imaging setups. Existing vision models struggle in this domain since ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17473v1" target="_blank">4D Monocular Surgical Reconstruction under Arbitrary Camera Motions</a></h3>
                <p class="meta">By Jiwei Shan, Zeyu Cai</p>
                <p class="text">Reconstructing deformable surgical scenes from endoscopic videos is challenging and clinically important. Recent state-of-the-art methods based on implicit neural representations or 3D Gaussian splatting have made notable progress. However, most are designed for deformable scenes...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17419v1" target="_blank">EAGLE: Expert-Augmented Attention Guidance for Tuning-Free Industrial Anomaly Detection in Multimodal Large Language Models</a></h3>
                <p class="meta">By Xiaomeng Peng, Xilang Huang</p>
                <p class="text">Industrial anomaly detection is important for smart manufacturing, but many deep learning approaches produce only binary decisions and provide limited semantic explanations. Multimodal large language models (MLLMs) can potentially generate fine-grained, language-based analyses, y...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17397v1" target="_blank">A High-Level Survey of Optical Remote Sensing</a></h3>
                <p class="meta">By Panagiotis Koletsis, Vasilis Efthymiou</p>
                <p class="text">In recent years, significant advances in computer vision have also propelled progress in remote sensing. Concurrently, the use of drones has expanded, with many organizations incorporating them into their operations. Most drones are equipped by default with RGB cameras, which are...</p>
            </div>
            
            </div>
        </section>
        
    </body>
    </html>
    