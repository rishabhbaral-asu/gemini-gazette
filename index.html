
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>The Silicon Scroll | Weekly Research</title>
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@900&family=Libre+Baskerville:wght@400;700&display=swap');
            
            body { background: #f4f1ea; color: #1a1a1a; font-family: 'Libre Baskerville', serif; margin: 0; padding: 2vw; }
            .masthead { text-align: center; border-bottom: 5px double #333; margin-bottom: 40px; padding-bottom: 15px; }
            .masthead h1 { font-family: 'Playfair Display'; font-size: 5rem; margin: 0; letter-spacing: -2px; }
            
            .news-desk { margin-bottom: 50px; }
            .desk-title { 
                border-bottom: 2px solid #333; 
                font-family: 'Playfair Display'; 
                font-size: 1.8rem; 
                margin-bottom: 15px; 
                padding-bottom: 5px; 
                display: flex; 
                justify-content: space-between; 
                align-items: center; 
            }
            .desk-title span { font-size: 0.7rem; font-family: 'Libre Baskerville'; opacity: 0.5; }
            
            .horizontal-scroll { 
                display: flex; 
                overflow-x: auto; 
                gap: 25px; 
                padding-bottom: 20px;
                scrollbar-width: thin;
                scrollbar-color: #333 #f4f1ea;
            }
            
            .horizontal-scroll::-webkit-scrollbar { height: 8px; }
            .horizontal-scroll::-webkit-scrollbar-thumb { background: #333; border-radius: 4px; }

            .card { 
                flex: 0 0 350px; 
                background: #fffefc; 
                border: 1px solid #d1cec1; 
                padding: 25px; 
                box-shadow: 4px 4px 0px rgba(0,0,0,0.05);
                transition: transform 0.2s;
                display: flex;
                flex-direction: column;
            }
            .card:hover { transform: translateY(-5px); }
            
            .card-date { font-size: 10px; font-weight: bold; color: #777; margin-bottom: 10px; }
            h3 { font-family: 'Playfair Display'; font-size: 1.3rem; margin: 0 0 10px 0; line-height: 1.2; }
            h3 a { color: #1a1a1a; text-decoration: none; }
            .meta { font-size: 11px; font-weight: bold; text-transform: uppercase; color: #555; margin-bottom: 10px; display: block; }
            .text { font-size: 13px; line-height: 1.6; color: #333; flex-grow: 1; }

            .ai-accent { border-top: 6px solid #2c3e50; }
            .nlp-accent { border-top: 6px solid #27ae60; }
            .vision-accent { border-top: 6px solid #e67e22; }
        </style>
    </head>
    <body>
        <div class="masthead">
            <div style="font-size: 50px; margin-bottom: 10px;">ðŸ¦‰</div>
            <h1>The Silicon Scroll</h1>
            <p>TEMPE, AZ â€” FEBRUARY 19, 2026 â€” WEEKLY INTELLIGENCE</p>
        </div>
        
        <section class="news-desk">
            <h2 class="desk-title">AI & REINFORCEMENT DESK <span>271 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16708v1" target="_blank">ðŸ”¥ Policy Compiler for Secure Agentic Systems</a></h3>
                <p class="meta">By Nils Palumbo, Sarthak Choudhary</p>
                <p class="text">LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We p...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16666v1" target="_blank">ðŸ”¥ Towards a Science of AI Agent Reliability</a></h3>
                <p class="meta">By Stephan Rabanser, Sayash Kapoor</p>
                <p class="text">AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing age...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16554v1" target="_blank">ðŸ”¥ MerLean: An Agentic Framework for Autoformalization in Quantum Computation</a></h3>
                <p class="meta">By Yuanjie Ren, Jinzheng Li</p>
                <p class="text">We introduce MerLean, a fully automated agentic framework for autoformalization in quantum computation. MerLean extracts mathematical statements from \LaTeX{} source files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into human-reada...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16435v1" target="_blank">ðŸ”¥ Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning</a></h3>
                <p class="meta">By Arun Vignesh Malarkkan, Wangyang Ying</p>
                <p class="text">Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a fr...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16301v1" target="_blank">ðŸ”¥ Multi-agent cooperation through in-context co-player inference</a></h3>
                <p class="meta">By Marissa A. Weis, Maciej WoÅ‚czyk</p>
                <p class="text">Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16246v1" target="_blank">ðŸ”¥ Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents</a></h3>
                <p class="meta">By Yun-Shiuan Chuang, Chaitanya Kulkarni</p>
                <p class="text">Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-be...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16196v1" target="_blank">ðŸ”¥ Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning</a></h3>
                <p class="meta">By Emile Anand, Richard Hoffmann</p>
                <p class="text">Coordinating large populations of interacting agents is a central challenge in multi-agent reinforcement learning (MARL), where the size of the joint state-action space scales exponentially with the number of agents. Mean-field methods alleviate this burden by aggregating agent i...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16179v1" target="_blank">ðŸ”¥ EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments</a></h3>
                <p class="meta">By Sushant Mehta, Logan Ritchie</p>
                <p class="text">We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \corecraft{}, the first environment in \textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments. \c...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15763v1" target="_blank">ðŸ”¥ GLM-5: from Vibe Coding to Agentic Engineering</a></h3>
                <p class="meta">By GLM-5 Team,  :</p>
                <p class="text">We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15721v1" target="_blank">ðŸ”¥ Lifelong Scalable Multi-Agent Realistic Testbed and A Comprehensive Study on Design Choices in Lifelong AGV Fleet Management Systems</a></h3>
                <p class="meta">By Jingtian Yan, Yulun Zhang</p>
                <p class="text">We present Lifelong Scalable Multi-Agent Realistic Testbed (LSMART), an open-source simulator to evaluate any Multi-Agent Path Finding (MAPF) algorithm in a Fleet Management System (FMS) with Automated Guided Vehicles (AGVs). MAPF aims to move a group of agents from their corresp...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15549v1" target="_blank">ðŸ”¥ VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing</a></h3>
                <p class="meta">By Guoqin Tang, Qingxuan Jia</p>
                <p class="text">Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15325v1" target="_blank">ðŸ”¥ AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents</a></h3>
                <p class="meta">By Zhixing Zhang, Jesen Zhang</p>
                <p class="text">Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based rea...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15294v1" target="_blank">ðŸ”¥ EAA: Automating materials characterization with vision language model agents</a></h3>
                <p class="meta">By Ming Du, Yanqi Luo</p>
                <p class="text">We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous proced...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.15212v1" target="_blank">ðŸ”¥ Secure and Energy-Efficient Wireless Agentic AI Networks</a></h3>
                <p class="meta">By Yuanyan Song, Kezhi Wang</p>
                <p class="text">In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifical...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.15173v1" target="_blank">ðŸ”¥ Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs</a></h3>
                <p class="meta">By Luise Ge, Yongyan Zhang</p>
                <p class="text">The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices a...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14926v1" target="_blank">ðŸ”¥ MAC-AMP: A Closed-Loop Multi-Agent Collaboration System for Multi-Objective Antimicrobial Peptide Design</a></h3>
                <p class="meta">By Gen Zhou, Sugitha Janarthanan</p>
                <p class="text">To address the global health threat of antimicrobial resistance, antimicrobial peptides (AMP) are being explored for their potent and promising ability to fight resistant pathogens. While artificial intelligence (AI) is being employed to advance AMP discovery and design, most AMP...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14857v1" target="_blank">ðŸ”¥ World Models for Policy Refinement in StarCraft II</a></h3>
                <p class="meta">By Yixin Zhang, Ziyi Wang</p>
                <p class="text">Large Language Models (LLMs) have recently shown strong reasoning and generalization capabilities, motivating their use as decision-making policies in complex environments. StarCraft II (SC2), with its massive state-action space and partial observability, is a challenging testbed...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14721v1" target="_blank">ðŸ”¥ WebWorld: A Large-Scale World Model for Web Agent Training</a></h3>
                <p class="meta">By Zikai Xiao, Jianhong Tu</p>
                <p class="text">Web agents require massive trajectories to generalize, yet real-world training is constrained by network latency, rate limits, and safety risks. We introduce \textbf{WebWorld} series, the first open-web simulator trained at scale. While existing simulators are restricted to close...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14697v1" target="_blank">ðŸ”¥ Evolutionary System Prompt Learning can Facilitate Reinforcement Learning for LLMs</a></h3>
                <p class="meta">By Lunjun Zhang, Ryan Chen</p>
                <p class="text">Building agentic systems that can autonomously self-improve from experience is a longstanding goal of AI. Large language models (LLMs) today primarily self-improve via two mechanisms: self-reflection for context updates, and reinforcement learning (RL) for weight updates. In this...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14691v1" target="_blank">ðŸ”¥ Removing Planner Bias in Goal Recognition Through Multi-Plan Dataset Generation</a></h3>
                <p class="meta">By Mustafa F. Abdelwahed, Felipe Meneguzzi Kin Max Piamolini Gusmao</p>
                <p class="text">Autonomous agents require some form of goal and plan recognition to interact in multiagent settings. Unfortunately, all existing goal recognition datasets suffer from a systematical bias induced by the planning systems that generated them, namely heuristic-based forward search. T...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14606v1" target="_blank">ðŸ”¥ Towards Selection as Power: Bounding Decision Authority in Autonomous Agents</a></h3>
                <p class="meta">By Jose Manuel de la Chica Rodriguez, Juan Manuel Vera DÃ­az</p>
                <p class="text">Autonomous agentic systems are increasingly deployed in regulated, high-stakes domains where decisions may be irreversible and institutionally constrained. Existing safety approaches emphasize alignment, interpretability, or action-level filtering. We argue that these mechanisms ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14559v1" target="_blank">ðŸ”¥ Fluid-Agent Reinforcement Learning</a></h3>
                <p class="meta">By Shishir Sharma, Doina Precup</p>
                <p class="text">The primary focus of multi-agent reinforcement learning (MARL) has been to study interactions among a fixed number of agents embedded in an environment. However, in the real world, the number of agents is neither fixed nor known a priori. Moreover, an agent can decide to create o...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14471v1" target="_blank">ðŸ”¥ Socially-Weighted Alignment: A Game-Theoretic Framework for Multi-Agent LLM Systems</a></h3>
                <p class="meta">By Furkan Mumcu, Yasin Yilmaz</p>
                <p class="text">Deploying large language model (LLM) agents in shared environments introduces a fundamental tension between individual alignment and collective stability: locally rational decisions can impose negative externalities that degrade system-level performance. We propose Socially-Weigh...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16585v1" target="_blank">ðŸ”¥ DataJoint 2.0: A Computational Substrate for Agentic Scientific Workflows</a></h3>
                <p class="meta">By Dimitri Yatsenko, Thinh T. Nguyen</p>
                <p class="text">Operational rigor determines whether human-agent collaboration succeeds or fails. Scientific data pipelines need the equivalent of DevOps -- SciOps -- yet common approaches fragment provenance across disconnected systems without transactional guarantees. DataJoint 2.0 addresses t...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16520v1" target="_blank">ðŸ”¥ Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents</a></h3>
                <p class="meta">By Doron Shavit</p>
                <p class="text">Jailbreak prompts are a practical and evolving threat to large language models (LLMs), particularly in agentic systems that execute tools over untrusted content. Many attacks exploit long-context hiding, semantic camouflage, and lightweight obfuscations that can evade single-pass...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16444v1" target="_blank">ðŸ”¥ RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation</a></h3>
                <p class="meta">By Yixue Zhang, Kun Wu</p>
                <p class="text">The pursuit of general-purpose robotic manipulation is hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or language, robotic data collection is an active process incurring prohibitive physical costs. Consequently, automat...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.16037v1" target="_blank">ðŸ”¥ Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection</a></h3>
                <p class="meta">By Cameron Cagan, Pedram Fard</p>
                <p class="text">Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifie...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15776v1" target="_blank">ðŸ”¥ GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems</a></h3>
                <p class="meta">By Yiqin Yang, Xu Yang</p>
                <p class="text">In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are l...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15384v1" target="_blank">ðŸ”¥ World-Model-Augmented Web Agents with Action Correction</a></h3>
                <p class="meta">By Zhouzhou Shen, Xueyu Hu</p>
                <p class="text">Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.15198v1" target="_blank">ðŸ”¥ Colosseum: Auditing Collusion in Cooperative Multi-Agent Systems</a></h3>
                <p class="meta">By Mason Nakamura, Abhinav Kumar</p>
                <p class="text">Multi-agent systems, where LLM agents communicate through free-form language, enable sophisticated coordination for solving complex cooperative tasks. This surfaces a unique safety problem when individual agents form a coalition and \emph{collude} to pursue secondary goals and de...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">NLP & LANGUAGE DESK <span>103 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16485v1" target="_blank">ðŸ”¥ Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling</a></h3>
                <p class="meta">By Jeffrey T. H. Wong, Zixi Zhang</p>
                <p class="text">Existing Multi-Agent Systems (MAS) typically rely on static, homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16313v1" target="_blank">ðŸ”¥ MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks</a></h3>
                <p class="meta">By Zexue He, Yu Wang</p>
                <p class="text">Existing evaluations of agents with memory typically assess memorization and action in isolation. One class of benchmarks evaluates memorization by testing recall of past conversations or text but fails to capture how memory is used to guide future decisions. Another class focuse...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15382v1" target="_blank">ðŸ”¥ The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems</a></h3>
                <p class="meta">By Xiaoze Liu, Ruowang Zhang</p>
                <p class="text">Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.15012v1" target="_blank">ðŸ”¥ Cold-Start Personalization via Training-Free Priors from Structured World Models</a></h3>
                <p class="meta">By Avinandan Bose, Shuyue Stella Li</p>
                <p class="text">Cold-start personalization requires inferring user preferences through interaction when no user-specific historical data is available. The core challenge is a routing problem: each task admits dozens of preference dimensions, yet individual users care about only a few, and which ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14955v1" target="_blank">ðŸ”¥ Tool-Aware Planning in Contact Center AI: Evaluating LLMs through Lineage-Guided Query Decomposition</a></h3>
                <p class="meta">By Varun Nathan, Shreyas Guha</p>
                <p class="text">We present a domain-grounded framework and benchmark for tool-aware plan generation in contact centers, where answering a query for business insights, our target use case, requires decomposing it into executable steps over structured tools (Text2SQL (T2S)/Snowflake) and unstructu...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16429v1" target="_blank">ðŸ”¥ TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers</a></h3>
                <p class="meta">By Ido Levy, Eilam Shapira</p>
                <p class="text">Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing, shortlisting, gating, and verification. While convenient, this...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16379v1" target="_blank">ðŸ”¥ Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents</a></h3>
                <p class="meta">By Mohammad H. A. Monfared, Lucie Flek</p>
                <p class="text">We propose an agentic data augmentation method for Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched prompting-b...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.15197v1" target="_blank">ðŸ”¥ OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction</a></h3>
                <p class="meta">By Skyler Hallinan, Thejas Venkatesh</p>
                <p class="text">Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general "search" APIs) are often opaque, lacking clear best practices or failure modes. ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14778v2" target="_blank">ðŸ”¥ A Geometric Analysis of Small-sized Language Model Hallucinations</a></h3>
                <p class="meta">By Emanuele Ricco, Elia Onofri</p>
                <p class="text">Hallucinations -- fluent but factually incorrect responses -- pose a major challenge to the reliability of language models, especially in multi-step or agentic settings.   This work investigates hallucinations in small-sized LLMs through a geometric perspective, starting from the...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14770v2" target="_blank">ðŸ”¥ Multi-Agent Comedy Club: Investigating Community Discussion Effects on LLM Humor Generation</a></h3>
                <p class="meta">By Shiwei Hong, Lingyao Li</p>
                <p class="text">Prior work has explored multi-turn interaction and feedback for LLM writing, but evaluations still largely center on prompts and localized feedback, leaving persistent public reception in online communities underexamined. We test whether broadcast community discussion improves st...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16704v1" target="_blank">âš¡ Reinforced Fast Weights with Next-Sequence Prediction</a></h3>
                <p class="meta">By Hee Seung Hwang, Xindi Wu</p>
                <p class="text">Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP op...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16516v1" target="_blank">âš¡ Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification</a></h3>
                <p class="meta">By Taja Kuzman PungerÅ¡ek, Peter Rupnik</p>
                <p class="text">This paper introduces ParlaCAP, a large-scale dataset for analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the multilingual Pa...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16490v1" target="_blank">âš¡ From Growing to Looping: A Unified View of Iterative Computation in LLMs</a></h3>
                <p class="meta">By Ferdinand Kapl, Emmanouil Angelis</p>
                <p class="text">Looping, reusing a block of layers across depth, and depth growing, training shallow-to-deep models by duplicating middle layers, have both been linked to stronger reasoning, but their relationship remains unclear. We provide a mechanistic unification: looped and depth-grown mode...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16467v1" target="_blank">âš¡ IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models</a></h3>
                <p class="meta">By Saurabh Bharti, Gaurav Azad</p>
                <p class="text">The rapid advancement of large language models (LLMs) necessitates evaluation frameworks that reflect real-world academic rigor and multilingual complexity. This paper introduces IndicEval, a scalable benchmarking platform designed to assess LLM performance using authentic high-s...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16162v1" target="_blank">âš¡ LLMs Exhibit Significantly Lower Uncertainty in Creative Writing Than Professional Writers</a></h3>
                <p class="meta">By Peiqi Sui</p>
                <p class="text">We argue that uncertainty is a key and understudied limitation of LLMs' performance in creative writing, which is often characterized as trite and clichÃ©-ridden. Literary theory identifies uncertainty as a necessary condition for creative expression, while current alignment strat...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16154v1" target="_blank">âš¡ Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution</a></h3>
                <p class="meta">By Nithin Sivakumaran, Shoubin Yu</p>
                <p class="text">Chain-of-thought (CoT) reasoning sometimes fails to faithfully reflect the true computation of a large language model (LLM), hampering its utility in explaining how LLMs arrive at their answers. Moreover, optimizing for faithfulness and interpretability in reasoning often degrade...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.16093v1" target="_blank">âš¡ Updating Parametric Knowledge with Context Distillation Retains Post-Training Capabilities</a></h3>
                <p class="meta">By Shankar Padmanabhan, Mustafa Omer Gul</p>
                <p class="text">Post-training endows pretrained LLMs with a variety of desirable skills, including instruction-following, reasoning, and others. However, these post-trained LLMs only encode knowledge up to a cut-off date, necessitating continual adaptation. Unfortunately, existing solutions cann...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.16085v1" target="_blank">âš¡ Language Statistics and False Belief Reasoning: Evidence from 41 Open-Weight LMs</a></h3>
                <p class="meta">By Sean Trott, Samuel Taylor</p>
                <p class="text">Research on mental state reasoning in language models (LMs) has the potential to inform theories of human social cognition--such as the theory that mental state reasoning emerges in part from language exposure--and our understanding of LMs themselves. Yet much published work on L...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15689v2" target="_blank">âš¡ A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models</a></h3>
                <p class="meta">By Noa Linder, Meirav Segal</p>
                <p class="text">Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15620v2" target="_blank">âš¡ STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens</a></h3>
                <p class="meta">By Shiqi Liu, Zeyu He</p>
                <p class="text">Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often suffer from late-stage per...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15564v1" target="_blank">âš¡ Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL</a></h3>
                <p class="meta">By Yihan Wang, Peiyu Liu</p>
                <p class="text">Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of re...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15449v1" target="_blank">âš¡ TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models</a></h3>
                <p class="meta">By Chansung Park, Juyong Jiang</p>
                <p class="text">Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Re...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15353v1" target="_blank">âš¡ NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering</a></h3>
                <p class="meta">By Rong Fu, Yang Li</p>
                <p class="text">Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factu...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15313v1" target="_blank">âš¡ Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory</a></h3>
                <p class="meta">By Zihao Tang, Xin Yu</p>
                <p class="text">AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-st...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.15139v1" target="_blank">âš¡ CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding</a></h3>
                <p class="meta">By Tahir Hussain, Saddam Hussain Khan</p>
                <p class="text">Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.15005v1" target="_blank">âš¡ Learning User Interests via Reasoning and Distillation for Cross-Domain News Recommendation</a></h3>
                <p class="meta">By Mengdan Zhu, Yufan Zhao</p>
                <p class="text">News recommendation plays a critical role in online news platforms by helping users discover relevant content. Cross-domain news recommendation further requires inferring user's underlying information needs from heterogeneous signals that often extend beyond direct news consumpti...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14917v1" target="_blank">âš¡ BFS-PO: Best-First Search for Large Reasoning Models</a></h3>
                <p class="meta">By Fiorenzo Parascandolo, Wenhui Tan</p>
                <p class="text">Large Reasoning Models (LRMs) such as OpenAI o1 and DeepSeek-R1 have shown excellent performance in reasoning tasks using long reasoning chains. However, this has also led to a significant increase of computational costs and the generation of verbose output, a phenomenon known as...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14812v1" target="_blank">âš¡ Physical Commonsense Reasoning for Lower-Resourced Languages and Dialects: a Study on Basque</a></h3>
                <p class="meta">By Jaione Bengoetxea, Itziar Gonzalez-Dios</p>
                <p class="text">Physical commonsense reasoning represents a fundamental capability of human intelligence, enabling individuals to understand their environment, predict future events, and navigate physical spaces. Recent years have witnessed growing interest in reasoning tasks within Natural Lang...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14763v1" target="_blank">âš¡ Unlocking Reasoning Capability on Machine Translation in Large Language Models</a></h3>
                <p class="meta">By Sara Rajaee, Sebastian Vincent</p>
                <p class="text">Reasoning-oriented large language models (RLMs) achieve strong gains on tasks such as mathematics and coding by generating explicit intermediate reasoning. However, their impact on machine translation (MT) remains underexplored. We systematically evaluate several open- and closed...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14649v1" target="_blank">âš¡ GradMAP: Faster Layer Pruning with Gradient Metric and Projection Compensation</a></h3>
                <p class="meta">By Hao Liu, Guangyan Li</p>
                <p class="text">Large Language Models (LLMs) exhibit strong reasoning abilities, but their high computational costs limit their practical deployment. Recent studies reveal significant redundancy in LLMs layers, making layer pruning an active research topic. Layer pruning research primarily focus...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">VISION & MULTIMODAL DESK <span>126 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15918v1" target="_blank">ðŸ”¥ EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLMs on Earth Imagery</a></h3>
                <p class="meta">By Zelin Xu, Yupu Zhang</p>
                <p class="text">Benchmarking spatial reasoning in multimodal large language models (MLLMs) has attracted growing interest in computer vision due to its importance for embodied AI and other agentic systems that require precise interaction with the physical world. However, spatial reasoning on Ear...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15329v1" target="_blank">ðŸ”¥ EventMemAgent: Hierarchical Event-Centric Memory for Online Video Understanding with Adaptive Tool Use</a></h3>
                <p class="meta">By Siwei Wen, Zhangcheng Wang</p>
                <p class="text">Online video understanding requires models to perform continuous perception and long-range reasoning within potentially infinite visual streams. Its fundamental challenge lies in the conflict between the unbounded nature of streaming media input and the limited context window of ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16702v1" target="_blank">âš¡ Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning</a></h3>
                <p class="meta">By Mingjia Shi, Yinhan He</p>
                <p class="text">Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16682v1" target="_blank">âš¡ Learning Situated Awareness in the Real World</a></h3>
                <p class="meta">By Chuhan Li, Ruilin Han</p>
                <p class="text">A core aspect of human perception is situated awareness, the ability to relate ourselves to the surrounding physical environment and reason over possible actions in context. However, most existing benchmarks for multimodal foundation models (MFMs) emphasize environment-centric sp...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16669v1" target="_blank">âš¡ PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction</a></h3>
                <p class="meta">By Bo Lang, Nirav Savaliya</p>
                <p class="text">High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which le...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16455v1" target="_blank">âš¡ Visual Self-Refine: A Pixel-Guided Paradigm for Accurate Chart Parsing</a></h3>
                <p class="meta">By Jinsong Li, Xiaoyi Dong</p>
                <p class="text">While Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities for reasoning and self-correction at the textual level, these strengths provide minimal benefits for complex tasks centered on visual perception, such as Chart Parsing. Existing models often stru...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16160v1" target="_blank">âš¡ Uncertainty-Guided Inference-Time Depth Adaptation for Transformer-Based Visual Tracking</a></h3>
                <p class="meta">By Patrick Poggi, Divake Kumar</p>
                <p class="text">Transformer-based single-object trackers achieve state-of-the-art accuracy but rely on fixed-depth inference, executing the full encoder--decoder stack for every frame regardless of visual complexity, thereby incurring unnecessary computational cost in long video sequences domina...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16110v1" target="_blank">âš¡ OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis</a></h3>
                <p class="meta">By Tianwei Lin, Zhongwei Qiu</p>
                <p class="text">Computed Tomography (CT) is one of the most widely used and diagnostically information-dense imaging modalities, covering critical organs such as the heart, lungs, liver, and colon. Clinical interpretation relies on both slice-driven local features (e.g., sub-centimeter nodules, ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15950v1" target="_blank">âš¡ Can Vision-Language Models See Squares? Text-Recognition Mediates Spatial Reasoning Across Three Model Families</a></h3>
                <p class="meta">By Yuval Levental</p>
                <p class="text">We present a simple experiment that exposes a fundamental limitation in vision-language models (VLMs): the inability to accurately localize filled cells in binary grids when those cells lack textual identity. We generate fifteen 15x15 grids with varying density (10.7%-41.8% fille...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15819v1" target="_blank">âš¡ VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation</a></h3>
                <p class="meta">By Hui Ren, Yuval Alaluf</p>
                <p class="text">Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. We present a data-effic...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15775v1" target="_blank">âš¡ NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy</a></h3>
                <p class="meta">By Laura Salort-Benejam, Antonio Agudo</p>
                <p class="text">Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15724v1" target="_blank">âš¡ Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation</a></h3>
                <p class="meta">By Shutian Gu, Chengkai Huang</p>
                <p class="text">Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning c...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15556v1" target="_blank">âš¡ Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs</a></h3>
                <p class="meta">By Guangtao Lyu, Qi Liu</p>
                <p class="text">LVLMs have achieved strong multimodal reasoning capabilities but remain prone to hallucinations, producing outputs inconsistent with visual inputs or user instructions. Existing training-free methods, including contrastive decoding and auxiliary expert models, which incur several...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15461v1" target="_blank">âš¡ Emergent Morphing Attack Detection in Open Multi-modal Large Language Models</a></h3>
                <p class="meta">By Marija Ivanovska, Vitomir Å truc</p>
                <p class="text">Face morphing attacks threaten biometric verification, yet most morphing attack detection (MAD) systems require task-specific training and generalize poorly to unseen attack types. Meanwhile, open-source multimodal large language models (MLLMs) have demonstrated strong visual-lin...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-17</div>
                <h3><a href="http://arxiv.org/abs/2602.15915v1" target="_blank">âš¡ MaS-VQA: A Mask-and-Select Framework for Knowledge-Based Visual Question Answering</a></h3>
                <p class="meta">By Xianwei Mao, Kai Ye</p>
                <p class="text">Knowledge-based Visual Question Answering (KB-VQA) requires models to answer questions by integrating visual information with external knowledge. However, retrieved knowledge is often noisy, partially irrelevant, or misaligned with the visual content, while internal model knowled...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14989v1" target="_blank">âš¡ ThermEval: A Structured Benchmark for Evaluation of Vision-Language Models on Thermal Imagery</a></h3>
                <p class="meta">By Ayush Shrivastava, Kirtan Gangani</p>
                <p class="text">Vision language models (VLMs) achieve strong performance on RGB imagery, but they do not generalize to thermal images. Thermal sensing plays a critical role in settings where visible light fails, including nighttime surveillance, search and rescue, autonomous driving, and medical...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14771v1" target="_blank">âš¡ GOT-JEPA: Generic Object Tracking with Model Adaptation and Occlusion Handling using Joint-Embedding Predictive Architecture</a></h3>
                <p class="meta">By Shih-Fang Chen, Jun-Cheng Chen</p>
                <p class="text">The human visual system tracks objects by integrating current observations with previously observed information, adapting to target and scene changes, and reasoning about occlusion at fine granularity. In contrast, recent generic object trackers are often optimized for training t...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14577v1" target="_blank">âš¡ DriveFine: Refining-Augmented Masked Diffusion VLA for Precise and Robust Driving</a></h3>
                <p class="meta">By Chenxu Dang, Sining Ang</p>
                <p class="text">Vision-Language-Action (VLA) models for autonomous driving increasingly adopt generative planners trained with imitation learning followed by reinforcement learning. Diffusion-based planners suffer from modality alignment difficulties, low training efficiency, and limited general...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14534v1" target="_blank">âš¡ MoRL: Reinforced Reasoning for Unified Motion Understanding and Generation</a></h3>
                <p class="meta">By Hongpeng Wang, Zeyu Zhang</p>
                <p class="text">Human motion understanding and generation are crucial for vision and robotics but remain limited in reasoning capability and test-time planning. We propose MoRL, a unified multimodal motion model trained with supervised fine-tuning and reinforcement learning with verifiable rewar...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14482v1" target="_blank">âš¡ TikArt: Aperture-Guided Observation for Fine-Grained Visual Reasoning via Reinforcement Learning</a></h3>
                <p class="meta">By Hao Ding, Zhichuan Yang</p>
                <p class="text">We address fine-grained visual reasoning in multimodal large language models (MLLMs), where key evidence may reside in tiny objects, cluttered regions, or subtle markings that are lost under a single global image encoding. We introduce TikArt (Thinking Aperture), an aperture-guid...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14441v1" target="_blank">âš¡ D-SECURE: Dual-Source Evidence Combination for Unified Reasoning in Misinformation Detection</a></h3>
                <p class="meta">By Gagandeep Singh, Samudi Amarasinghe</p>
                <p class="text">Multimodal misinformation increasingly mixes realistic im-age edits with fluent but misleading text, producing persuasive posts that are difficult to verify. Existing systems usually rely on a single evidence source. Content-based detectors identify local inconsistencies within a...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-16</div>
                <h3><a href="http://arxiv.org/abs/2602.14409v1" target="_blank">âš¡ Learning Proposes, Geometry Disposes: A Modular Framework for Efficient Spatial Reasoning</a></h3>
                <p class="meta">By Haichao Zhu, Zhaorui Yang</p>
                <p class="text">Spatial perception aims to estimate camera motion and scene structure from visual observations, a problem traditionally addressed through geometric modeling and physical consistency constraints. Recent learning-based methods have demonstrated strong representational capacity for ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16711v1" target="_blank">TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos</a></h3>
                <p class="meta">By Namitha Padmanabhan, Matthew Gwilliam</p>
                <p class="text">Implicit Neural Representations (INRs) have recently demonstrated impressive performance for video compression. However, since a separate INR must be overfit for each video, scaling to high-resolution videos while maintaining encoding efficiency remains a significant challenge. H...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16689v1" target="_blank">Are Object-Centric Representations Better At Compositional Generalization?</a></h3>
                <p class="meta">By Ferdinand Kapl, Amir Mohammad Karimi Mamaghan</p>
                <p class="text">Compositional generalization, the ability to reason about novel combinations of familiar concepts, is fundamental to human cognition and a critical challenge for machine learning. Object-centric (OC) representations, which encode a scene as a set of objects, are often argued to s...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16681v1" target="_blank">VETime: Vision Enhanced Zero-Shot Time Series Anomaly Detection</a></h3>
                <p class="meta">By Yingyuan Yang, Tian Lan</p>
                <p class="text">Time-series anomaly detection (TSAD) requires identifying both immediate Point Anomalies and long-range Context Anomalies. However, existing foundation models face a fundamental trade-off: 1D temporal models provide fine-grained pointwise localization but lack a global contextual...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16664v1" target="_blank">Unpaired Image-to-Image Translation via a Self-Supervised Semantic Bridge</a></h3>
                <p class="meta">By Jiaming Liu, Felix Petersen</p>
                <p class="text">Adversarial diffusion and diffusion-inversion methods have advanced unpaired image-to-image translation, but each faces key limitations. Adversarial approaches require target-domain adversarial loss during training, which can limit generalization to unseen data, while diffusion-i...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16590v1" target="_blank">A Contrastive Learning Framework Empowered by Attention-based Feature Adaptation for Street-View Image Classification</a></h3>
                <p class="meta">By Qi You, Yitai Cheng</p>
                <p class="text">Street-view image attribute classification is a vital downstream task of image classification, enabling applications such as autonomous driving, urban analytics, and high-definition map construction. It remains computationally demanding whether training from scratch, initialising...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16569v1" target="_blank">Arc2Morph: Identity-Preserving Facial Morphing with Arc2Face</a></h3>
                <p class="meta">By NicolÃ² Di Domenico, Annalisa Franco</p>
                <p class="text">Face morphing attacks are widely recognized as one of the most challenging threats to face recognition systems used in electronic identity documents. These attacks exploit a critical vulnerability in passport enrollment procedures adopted by many countries, where the facial image...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16545v1" target="_blank">Let's Split Up: Zero-Shot Classifier Edits for Fine-Grained Video Understanding</a></h3>
                <p class="meta">By Kaiting Liu, Hazel Doughty</p>
                <p class="text">Video recognition models are typically trained on fixed taxonomies which are often too coarse, collapsing distinctions in object, manner or outcome under a single label. As tasks and definitions evolve, such models cannot accommodate emerging distinctions and collecting new annot...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16502v1" target="_blank">DressWild: Feed-Forward Pose-Agnostic Garment Sewing Pattern Generation from In-the-Wild Images</a></h3>
                <p class="meta">By Zeng Tao, Ying Jiang</p>
                <p class="text">Recent advances in garment pattern generation have shown promising progress. However, existing feed-forward methods struggle with diverse poses and viewpoints, while optimization-based approaches are computationally expensive and difficult to scale. This paper focuses on sewing p...</p>
            </div>
            
            </div>
        </section>
        
    </body>
    </html>
    