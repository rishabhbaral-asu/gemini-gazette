
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>The Silicon Scroll | Weekly Research</title>
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@900&family=Libre+Baskerville:wght@400;700&display=swap');
            
            body { background: #f4f1ea; color: #1a1a1a; font-family: 'Libre Baskerville', serif; margin: 0; padding: 2vw; }
            .masthead { text-align: center; border-bottom: 5px double #333; margin-bottom: 40px; padding-bottom: 15px; }
            .masthead h1 { font-family: 'Playfair Display'; font-size: 5rem; margin: 0; letter-spacing: -2px; }
            
            .news-desk { margin-bottom: 50px; }
            .desk-title { 
                border-bottom: 2px solid #333; 
                font-family: 'Playfair Display'; 
                font-size: 1.8rem; 
                margin-bottom: 15px; 
                padding-bottom: 5px; 
                display: flex; 
                justify-content: space-between; 
                align-items: center; 
            }
            .desk-title span { font-size: 0.7rem; font-family: 'Libre Baskerville'; opacity: 0.5; }
            
            .horizontal-scroll { 
                display: flex; 
                overflow-x: auto; 
                gap: 25px; 
                padding-bottom: 20px;
                scrollbar-width: thin;
                scrollbar-color: #333 #f4f1ea;
            }
            
            .horizontal-scroll::-webkit-scrollbar { height: 8px; }
            .horizontal-scroll::-webkit-scrollbar-thumb { background: #333; border-radius: 4px; }

            .card { 
                flex: 0 0 350px; 
                background: #fffefc; 
                border: 1px solid #d1cec1; 
                padding: 25px; 
                box-shadow: 4px 4px 0px rgba(0,0,0,0.05);
                transition: transform 0.2s;
                display: flex;
                flex-direction: column;
            }
            .card:hover { transform: translateY(-5px); }
            
            .card-date { font-size: 10px; font-weight: bold; color: #777; margin-bottom: 10px; }
            h3 { font-family: 'Playfair Display'; font-size: 1.3rem; margin: 0 0 10px 0; line-height: 1.2; }
            h3 a { color: #1a1a1a; text-decoration: none; }
            .meta { font-size: 11px; font-weight: bold; text-transform: uppercase; color: #555; margin-bottom: 10px; display: block; }
            .text { font-size: 13px; line-height: 1.6; color: #333; flex-grow: 1; }

            .ai-accent { border-top: 6px solid #2c3e50; }
            .nlp-accent { border-top: 6px solid #27ae60; }
            .vision-accent { border-top: 6px solid #e67e22; }
        </style>
    </head>
    <body>
        <div class="masthead">
            <div style="font-size: 50px; margin-bottom: 10px;">ðŸ¦‰</div>
            <h1>The Silicon Scroll</h1>
            <p>TEMPE, AZ â€” FEBRUARY 25, 2026 â€” WEEKLY INTELLIGENCE</p>
        </div>
        
        <section class="news-desk">
            <h2 class="desk-title">AI & REINFORCEMENT DESK <span>229 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21136v1" target="_blank">ðŸ”¥ SparkMe: Adaptive Semi-Structured Interviewing for Qualitative Insight Discovery</a></h3>
                <p class="meta">By David Anugraha, Vishakh Padmakumar</p>
                <p class="text">Qualitative insights from user experiences are critical for informing product and policy decisions, but collecting such data at scale is constrained by the time and availability of experts to conduct semi-structured interviews. Recent work has explored using large language models...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21119v1" target="_blank">ðŸ”¥ Cooperative-Competitive Team Play of Real-World Craft Robots</a></h3>
                <p class="meta">By Rui Zhao, Xihui Li</p>
                <p class="text">Multi-agent deep Reinforcement Learning (RL) has made significant progress in developing intelligent game-playing agents in recent years. However, the efficient training of collective robots using multi-agent RL and the transfer of learned policies to real-world applications rema...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20946v1" target="_blank">ðŸ”¥ Some Simple Economics of AGI</a></h3>
                <p class="meta">By Christian Catalini, Xiang Hui</p>
                <p class="text">For millennia, human cognition was the primary engine of progress on Earth. As AI decouples cognition from biology, the marginal cost of measurable execution falls to zero, absorbing any labor capturable by metrics--including creative, analytical, and innovative work. The binding...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20934v1" target="_blank">ðŸ”¥ Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence</a></h3>
                <p class="meta">By ChengYou Li, XiaoDong Liu</p>
                <p class="text">The paradigm of Large Language Models is undergoing a fundamental transition from static inference engines to dynamic autonomous cognitive systems.While current research primarily focuses on scaling context windows or optimizing prompt engineering the theoretical bridge between m...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20924v1" target="_blank">ðŸ”¥ Airavat: An Agentic Framework for Internet Measurement</a></h3>
                <p class="meta">By Alagappan Ramanathan, Eunju Kang</p>
                <p class="text">Internet measurement faces twin challenges: complex analyses require expert-level orchestration of tools, yet even syntactically correct implementations can have methodological flaws and can be difficult to verify. Democratizing measurement capabilities thus demands automating bo...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20867v1" target="_blank">ðŸ”¥ SoK: Agentic Skills -- Beyond Tool Use in LLM Agents</a></h3>
                <p class="meta">By Yanna Jiang, Delong Li</p>
                <p class="text">Agentic systems increasingly rely on reusable procedural capabilities, \textit{a.k.a., agentic skills}, to execute long-horizon workflows reliably. These capabilities are callable modules that package procedural knowledge with explicit applicability conditions, execution policies...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20739v1" target="_blank">ðŸ”¥ PyVision-RL: Forging Open Agentic Vision Models via RL</a></h3>
                <p class="meta">By Shitian Zhao, Shaoheng Lin</p>
                <p class="text">Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20424v1" target="_blank">ðŸ”¥ Implicit Intelligence -- Evaluating Agents on What Users Don't Say</a></h3>
                <p class="meta">By Ved Sirdeshmukh, Marc Wetter</p>
                <p class="text">Real-world requests to AI agents are fundamentally underspecified. Natural human communication relies on shared context and unstated constraints that speakers expect listeners to infer. Current agentic benchmarks test explicit instruction-following but fail to evaluate whether ag...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20292v1" target="_blank">ðŸ”¥ Quantifying the Expectation-Realisation Gap for Agentic AI Systems</a></h3>
                <p class="meta">By Sebastian Lobentanzer</p>
                <p class="text">Agentic AI systems are deployed with expectations of substantial productivity gains, yet rigorous empirical evidence reveals systematic discrepancies between pre-deployment expectations and post-deployment outcomes. We review controlled trials and independent validations across s...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20078v1" target="_blank">ðŸ”¥ Descent-Guided Policy Gradient for Scalable Cooperative Multi-Agent Learning</a></h3>
                <p class="meta">By Shan Yang, Yang Liu</p>
                <p class="text">Scaling cooperative multi-agent reinforcement learning (MARL) is fundamentally limited by cross-agent noise: when agents share a common reward, the actions of all $N$ agents jointly determine each agent's learning signal, so cross-agent noise grows with $N$. In the policy gradien...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20064v1" target="_blank">ðŸ”¥ The LLMbda Calculus: AI Agents, Conversations, and Information Flow</a></h3>
                <p class="meta">By Zac Garby, Andrew D. Gordon</p>
                <p class="text">A conversation with a large language model (LLM) is a sequence of prompts and responses, with each response generated from the preceding conversation. AI agents build such conversations automatically: given an initial human prompt, a planner loop interleaves LLM calls with tool i...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20057v1" target="_blank">ðŸ”¥ AdaWorldPolicy: World-Model-Driven Diffusion Policy with Online Adaptive Learning for Robotic Manipulation</a></h3>
                <p class="meta">By Ge Yuan, Qiyuan Qiao</p>
                <p class="text">Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. In this work, we introduce a u...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19843v1" target="_blank">ðŸ”¥ MAS-FIRE: Fault Injection and Reliability Evaluation for LLM-Based Multi-Agent Systems</a></h3>
                <p class="meta">By Jin Jia, Zhiling Deng</p>
                <p class="text">As LLM-based Multi-Agent Systems (MAS) are increasingly deployed for complex tasks, ensuring their reliability has become a pressing challenge. Since MAS coordinate through unstructured natural language rather than rigid protocols, they are prone to semantic failures (e.g., hallu...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19634v1" target="_blank">ðŸ”¥ Compositional Planning with Jumpy World Models</a></h3>
                <p class="meta">By Jesse Farebrother, Matteo Pirotta</p>
                <p class="text">The ability to plan with temporal abstractions is central to intelligent decision-making. Rather than reasoning over primitive actions, we study agents that compose pre-trained policies as temporally extended actions, enabling solutions to complex tasks that no constituent alone ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19538v1" target="_blank">ðŸ”¥ Cost-Aware Diffusion Active Search</a></h3>
                <p class="meta">By Arundhati Banerjee, Jeff Schneider</p>
                <p class="text">Active search for recovering objects of interest through online, adaptive decision making with autonomous agents requires trading off exploration of unknown environments with exploitation of prior observations in the search space. Prior work has proposed information gain and Thom...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-22</div>
                <h3><a href="http://arxiv.org/abs/2602.19326v1" target="_blank">ðŸ”¥ City Editing: Hierarchical Agentic Execution for Dependency-Aware Urban Geospatial Modification</a></h3>
                <p class="meta">By Rui Liu, Steven Jige Quan</p>
                <p class="text">As cities evolve over time, challenges such as traffic congestion and functional imbalance increasingly necessitate urban renewal through efficient modification of existing plans, rather than complete re-planning. In practice, even minor urban changes require substantial manual e...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-22</div>
                <h3><a href="http://arxiv.org/abs/2602.19304v1" target="_blank">ðŸ”¥ Safe and Interpretable Multimodal Path Planning for Multi-Agent Cooperation</a></h3>
                <p class="meta">By Haojun Shi, Suyu Ye</p>
                <p class="text">Successful cooperation among decentralized agents requires each agent to quickly adapt its plan to the behavior of other agents. In scenarios where agents cannot confidently predict one another's intentions and plans, language communication can be crucial for ensuring safety. In ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21127v1" target="_blank">ðŸ”¥ "Are You Sure?": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems</a></h3>
                <p class="meta">By Xinfeng Li, Shenyu Dai</p>
                <p class="text">Large language model (LLM) agents are rapidly becoming trusted copilots in high-stakes domains like software development and healthcare. However, this deepening trust introduces a novel attack surface: Agent-Mediated Deception (AMD), where compromised agents are weaponized agains...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20979v1" target="_blank">ðŸ”¥ Toward an Agentic Infused Software Ecosystem</a></h3>
                <p class="meta">By Mark Marron</p>
                <p class="text">Fully leveraging the capabilities of AI agents in software development requires a rethinking of the software ecosystem itself. To this end, this paper outlines the creation of an Agentic Infused Software Ecosystem (AISE), that rests on three pillars. The first, of course, is the ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20720v1" target="_blank">ðŸ”¥ AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs</a></h3>
                <p class="meta">By Che Wang, Jiaming Zhang</p>
                <p class="text">The integration of external data services (e.g., Model Context Protocol, MCP) has made large language model-based agents increasingly powerful for complex task execution. However, this advancement introduces critical security vulnerabilities, particularly indirect prompt injectio...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20708v1" target="_blank">ðŸ”¥ ICON: Indirect Prompt Injection Defense for Agents based on Inference-Time Correction</a></h3>
                <p class="meta">By Che Wang, Fuyao Zhang</p>
                <p class="text">Large Language Model (LLM) agents are susceptible to Indirect Prompt Injection (IPI) attacks, where malicious instructions in retrieved content hijack the agent's execution. Existing defenses typically rely on strict filtering or refusal mechanisms, which suffer from a critical l...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20541v1" target="_blank">ðŸ”¥ Maximin Share Guarantees via Limited Cost-Sensitive Sharing</a></h3>
                <p class="meta">By Hana Salavcova, Martin ÄŒernÃ½</p>
                <p class="text">We study the problem of fairly allocating indivisible goods when limited sharing is allowed, that is, each good may be allocated to up to $k$ agents, while incurring a cost for sharing. While classic maximin share (MMS) allocations may not exist in many instances, we demonstrate ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20144v1" target="_blank">ðŸ”¥ Agentic AI for Scalable and Robust Optical Systems Control</a></h3>
                <p class="meta">By Zehao Wang, Mingzhe Han</p>
                <p class="text">We present AgentOptics, an agentic AI framework for high-fidelity, autonomous optical system control built on the Model Context Protocol (MCP). AgentOptics interprets natural language tasks and executes protocol-compliant actions on heterogeneous optical devices through a structu...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20059v1" target="_blank">ðŸ”¥ Interaction Theater: A case of LLM Agents Interacting at Scale</a></h3>
                <p class="meta">By Sarath Shekkizhar, Adam Earle</p>
                <p class="text">As multi-agent architectures and agent-to-agent protocols proliferate, a fundamental question arises: what actually happens when autonomous LLM agents interact at scale? We study this question empirically using data from Moltbook, an AI-agent-only social platform, with 800K posts...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20048v1" target="_blank">ðŸ”¥ CodeCompass: Navigating the Navigation Paradox in Agentic Code Intelligence</a></h3>
                <p class="meta">By Tarakanath Paipuru</p>
                <p class="text">Modern code intelligence agents operate in contexts exceeding 1 million tokens--far beyond the scale where humans manually locate relevant files. Yet agents consistently fail to discover architecturally critical files when solving real-world coding tasks. We identify the Navigati...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19810v1" target="_blank">ðŸ”¥ OpenClaw, Moltbook, and ClawdLab: From Agent-Only Social Networks to Autonomous Scientific Research</a></h3>
                <p class="meta">By Lukas Weidener, Marko BrkiÄ‡</p>
                <p class="text">In January 2026, the open-source agent framework OpenClaw and the agent-only social network Moltbook produced a large-scale dataset of autonomous AI-to-AI interaction, attracting six academic publications within fourteen days. This study conducts a multivocal literature review of...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19555v1" target="_blank">ðŸ”¥ Agentic AI as a Cybersecurity Attack Surface: Threats, Exploits, and Defenses in Runtime Supply Chains</a></h3>
                <p class="meta">By Xiaochong Jiang, Shiqi Yang</p>
                <p class="text">Agentic systems built on large language models (LLMs) extend beyond text generation to autonomously retrieve information and invoke tools. This runtime execution model shifts the attack surface from build-time artifacts to inference-time dependencies, exposing agents to manipulat...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19502v1" target="_blank">ðŸ”¥ Human-Guided Agentic AI for Multimodal Clinical Prediction: Lessons from the AgentDS Healthcare Benchmark</a></h3>
                <p class="meta">By Lalitha Pranathi Pulavarthy, Raajitha Muthyala</p>
                <p class="text">Agentic AI systems are increasingly capable of autonomous data science workflows, yet clinical prediction tasks demand domain expertise that purely automated approaches struggle to provide. We investigate how human guidance of agentic AI can improve multimodal clinical prediction...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19458v1" target="_blank">ðŸ”¥ ComplLLM: Fine-tuning LLMs to Discover Complementary Signals for Decision-making</a></h3>
                <p class="meta">By Ziyang Guo, Yifan Wu</p>
                <p class="text">Multi-agent decision pipelines can outperform single agent workflows when complementarity holds, i.e., different agents bring unique information to the table to inform a final decision. We propose ComplLLM, a post-training framework based on decision theory that fine-tunes a deci...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21203v1" target="_blank">âš¡ Squint: Fast Visual Reinforcement Learning for Sim-to-Real Robotics</a></h3>
                <p class="meta">By Abdulaziz Almuzairee, Henrik I. Christensen</p>
                <p class="text">Visual reinforcement learning is appealing for robotics but expensive -- off-policy methods are sample-efficient yet slow; on-policy methods parallelize well but waste samples. Recent work has shown that off-policy methods can train faster than on-policy methods in wall-clock tim...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">NLP & LANGUAGE DESK <span>65 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card nlp-accent">
                <div class="card-date">2026-02-22</div>
                <h3><a href="http://arxiv.org/abs/2602.19320v1" target="_blank">ðŸ”¥ Anatomy of Agentic Memory: Taxonomy and Empirical Analysis of Evaluation and System Limitations</a></h3>
                <p class="meta">By Dongming Jiang, Yi Li</p>
                <p class="text">Agentic memory systems enable large language model (LLM) agents to maintain state across long interactions, supporting long-horizon reasoning and personalization beyond fixed context windows. Despite rapid architectural development, the empirical foundations of these systems rema...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20040v1" target="_blank">ðŸ”¥ AgenticSum: An Agentic Inference-Time Framework for Faithful Clinical Text Summarization</a></h3>
                <p class="meta">By Fahmida Liza Piya, Rahmatollah Beheshti</p>
                <p class="text">Large language models (LLMs) offer substantial promise for automating clinical text summarization, yet maintaining factual consistency remains challenging due to the length, noise, and heterogeneity of clinical documentation. We present AgenticSum, an inference-time, agentic fram...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19961v1" target="_blank">ðŸ”¥ Unlocking Multimodal Document Intelligence: From Current Triumphs to Future Frontiers of Visual Document Retrieval</a></h3>
                <p class="meta">By Yibo Yan, Jiahao Huo</p>
                <p class="text">With the rapid proliferation of multimodal information, Visual Document Retrieval (VDR) has emerged as a critical frontier in bridging the gap between unstructured visually rich data and precise information acquisition. Unlike traditional natural image retrieval, visual documents...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19840v1" target="_blank">ðŸ”¥ SAMAS: A Spectrum-Guided Multi-Agent System for Achieving Style Fidelity in Literary Translation</a></h3>
                <p class="meta">By Jingzhuo Wu, Jiajun Zhang</p>
                <p class="text">Modern large language models (LLMs) excel at generating fluent and faithful translations. However, they struggle to preserve an author's unique literary style, often producing semantically correct but generic outputs. This limitation stems from the inability of current single-mod...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21103v1" target="_blank">âš¡ Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning</a></h3>
                <p class="meta">By Sanket Badhe, Deep Shah</p>
                <p class="text">Advanced reasoning typically requires Chain-of-Thought prompting, which is accurate but incurs prohibitive latency and substantial test-time inference costs. The standard alternative, fine-tuning smaller models, often sacrifices interpretability while introducing significant reso...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20973v1" target="_blank">âš¡ Linear Reasoning vs. Proof by Cases: Obstacles for Large Language Models in FOL Problem Solving</a></h3>
                <p class="meta">By Yuliang Ji, Fuchen Shen</p>
                <p class="text">To comprehensively evaluate the mathematical reasoning capabilities of Large Language Models (LLMs), researchers have introduced abundant mathematical reasoning datasets. However, most existing datasets primarily focus on linear reasoning, neglecting other parts such as proof by ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20966v1" target="_blank">âš¡ Blackbird Language Matrices: A Framework to Investigate the Linguistic Competence of Language Models</a></h3>
                <p class="meta">By Paola Merlo, Chunyang Jiang</p>
                <p class="text">This article describes a novel language task, the Blackbird Language Matrices (BLM) task, inspired by intelligence tests, and illustrates the BLM datasets, their construction and benchmarking, and targeted experiments on chunking and systematicity. BLMs are multiple-choice proble...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20945v1" target="_blank">âš¡ The Art of Efficient Reasoning: Data, Reward, and Optimization</a></h3>
                <p class="meta">By Taiqiang Wu, Zenan Zu</p>
                <p class="text">Large Language Models (LLMs) consistently benefit from scaled Chain-of-Thought (CoT) reasoning, but also suffer from heavy computational overhead. To address this issue, efficient reasoning aims to incentivize short yet accurate thinking trajectories, typically through reward sha...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20759v1" target="_blank">âš¡ Overton Pluralistic Reinforcement Learning for Large Language Models</a></h3>
                <p class="meta">By Yu Fu, Seongho Son</p>
                <p class="text">Existing alignment paradigms remain limited in capturing the pluralistic nature of human values. Overton Pluralism addresses this gap by generating responses with diverse perspectives from a single query. This paper introduces OP-GRPO (Overton Pluralistic Group Relative Policy Op...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20751v1" target="_blank">âš¡ SibylSense: Adaptive Rubric Learning via Memory Tuning and Adversarial Probing</a></h3>
                <p class="meta">By Yifei Xu, Guilherme Potje</p>
                <p class="text">Designing aligned and robust rewards for open-ended generation remains a key barrier to RL post-training. Rubrics provide structured, interpretable supervision, but scaling rubric construction is difficult: expert rubrics are costly, prompted rubrics are often superficial or inco...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20727v1" target="_blank">âš¡ ID-LoRA: Efficient Low-Rank Adaptation Inspired by Matrix Interpolative Decomposition</a></h3>
                <p class="meta">By Xindian Ma, Rundong Kong</p>
                <p class="text">LoRA has become a universal Parameter-Efficient Fine-Tuning (PEFT) technique that equips Large Language Models (LLMs) to adapt quickly to new tasks. However, when these models are scaled up, even the latest LoRA variants still introduce considerable overhead in trainable paramete...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20670v1" target="_blank">âš¡ CAMEL: Confidence-Gated Reflection for Reward Modeling</a></h3>
                <p class="meta">By Zirui Zhu, Hailun Xu</p>
                <p class="text">Reward models play a fundamental role in aligning large language models with human preferences. Existing methods predominantly follow two paradigms: scalar discriminative preference models, which are efficient but lack interpretability, and generative judging models, which offer ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20528v1" target="_blank">âš¡ Stop-Think-AutoRegress: Language Modeling with Latent Diffusion Planning</a></h3>
                <p class="meta">By Justin Lovelace, Christian Belardi</p>
                <p class="text">The Stop-Think-AutoRegress Language Diffusion Model (STAR-LDM) integrates latent diffusion planning with autoregressive generation. Unlike conventional autoregressive language models limited to token-by-token decisions, STAR-LDM incorporates a "thinking" phase that pauses generat...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20332v1" target="_blank">âš¡ No One Size Fits All: QueryBandits for Hallucination Mitigation</a></h3>
                <p class="meta">By Nicole Cho, William Watson</p>
                <p class="text">Advanced reasoning capabilities in Large Language Models (LLMs) have led to more frequent hallucinations; yet most mitigation work focuses on open-source models for post-hoc detection and parameter editing. The dearth of studies focusing on hallucinations in closed-source models ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20130v1" target="_blank">âš¡ To Reason or Not to: Selective Chain-of-Thought in Medical Question Answering</a></h3>
                <p class="meta">By Zaifu Zhan, Min Zeng</p>
                <p class="text">Objective: To improve the efficiency of medical question answering (MedQA) with large language models (LLMs) by avoiding unnecessary reasoning while maintaining accuracy.   Methods: We propose Selective Chain-of-Thought (Selective CoT), an inference-time strategy that first predi...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20017v1" target="_blank">âš¡ QUIETT: Query-Independent Table Transformation for Robust Reasoning</a></h3>
                <p class="meta">By Gaurav Najpande, Tampu Ravi Kumar</p>
                <p class="text">Real-world tables often exhibit irregular schemas, heterogeneous value formats, and implicit relational structure, which degrade the reliability of downstream table reasoning and question answering. Most existing approaches address these issues in a query-dependent manner, entang...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19948v1" target="_blank">âš¡ Assessing Risks of Large Language Models in Mental Health Support: A Framework for Automated Clinical AI Red Teaming</a></h3>
                <p class="meta">By Ian Steenstra, Paola Pedrelli</p>
                <p class="text">Large Language Models (LLMs) are increasingly utilized for mental health support; however, current safety benchmarks often fail to detect the complex, longitudinal risks inherent in therapeutic dialogue. We introduce an evaluation framework that pairs AI psychotherapists with sim...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19919v1" target="_blank">âš¡ Janus-Q: End-to-End Event-Driven Trading via Hierarchical-Gated Reward Modeling</a></h3>
                <p class="meta">By Xiang Li, Zikai Wei</p>
                <p class="text">Financial market movements are often driven by discrete financial events conveyed through news, whose impacts are heterogeneous, abrupt, and difficult to capture under purely numerical prediction objectives. These limitations have motivated growing interest in using textual infor...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19883v1" target="_blank">âš¡ Denotational Semantics for ODRL: Knowledge-Based Constraint Conflict Detection</a></h3>
                <p class="meta">By Daham Mustafa, Diego Collarana</p>
                <p class="text">ODRL's six set-based operators -- isA, isPartOf, hasPart, isAnyOf, isAllOf, isNoneOf -- depend on external domain knowledge that the W3C specification leaves unspecified. Without it, every cross-dataspace policy comparison defaults to Unknown. We present a denotational semantics ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19878v1" target="_blank">âš¡ Axis Decomposition for ODRL: Resolving Dimensional Ambiguity in Policy Constraints through Interval Semantics</a></h3>
                <p class="meta">By Daham Mustafa, Diego Collarana</p>
                <p class="text">Every ODRL 2.2 constraint compares a single scalar value: (leftOperand, operator, rightOperand). Five of ODRL's approximately 34 left operands, however, denote multi-dimensional quantities--image dimensions, canvas positions, geographic coordinates--whose specification text expli...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19569v1" target="_blank">âš¡ Temporal-Aware Heterogeneous Graph Reasoning with Multi-View Fusion for Temporal Question Answering</a></h3>
                <p class="meta">By Wuzhenghong Wen, Bowen Zhou</p>
                <p class="text">Question Answering over Temporal Knowledge Graphs (TKGQA) has attracted growing interest for handling time-sensitive queries. However, existing methods still struggle with: 1) weak incorporation of temporal constraints in question representation, causing biased reasoning; 2) limi...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19526v1" target="_blank">âš¡ How to Train Your Deep Research Agent? Prompt, Reward, and Policy Optimization in Search-R1</a></h3>
                <p class="meta">By Yinuo Xu, Shuo Lu</p>
                <p class="text">Deep Research agents tackle knowledge-intensive tasks through multi-round retrieval and decision-oriented generation. While reinforcement learning (RL) has been shown to improve performance in this paradigm, its contributions remain underexplored. To fully understand the role of ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19509v1" target="_blank">âš¡ Pyramid MoA: A Probabilistic Framework for Cost-Optimized Anytime Inference</a></h3>
                <p class="meta">By Arindam Khaled</p>
                <p class="text">Large Language Models (LLMs) face a persistent trade-off between inference cost and reasoning capability. While "Oracle" models (e.g., Llama-3-70B) achieve state-of-the-art accuracy, they are prohibitively expensive for high-volume deployment. Smaller models (e.g., 8B parameters)...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-22</div>
                <h3><a href="http://arxiv.org/abs/2602.19317v1" target="_blank">âš¡ Learning to Reason for Multi-Step Retrieval of Personal Context in Personalized Question Answering</a></h3>
                <p class="meta">By Maryam Amirizaniani, Alireza Salemi</p>
                <p class="text">Personalization in Question Answering (QA) requires answers that are both accurate and aligned with users' background, preferences, and historical context. Existing state-of-the-art methods primarily rely on retrieval-augmented generation (RAG) solutions that construct personal c...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21193v1" target="_blank">On Data Engineering for Scaling LLM Terminal Capabilities</a></h3>
                <p class="meta">By Renjie Pi, Grace Lam</p>
                <p class="text">Despite rapid recent progress in the terminal capabilities of large language models, the training data strategies behind state-of-the-art terminal agents remain largely undisclosed. We address this gap through a systematic study of data engineering practices for terminal agents, ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21165v1" target="_blank">PVminer: A Domain-Specific Tool to Detect the Patient Voice in Patient Generated Data</a></h3>
                <p class="meta">By Samah Fodeh, Linhai Ma</p>
                <p class="text">Patient-generated text such as secure messages, surveys, and interviews contains rich expressions of the patient voice (PV), reflecting communicative behaviors and social determinants of health (SDoH). Traditional qualitative coding frameworks are labor intensive and do not scale...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21082v1" target="_blank">Beyond the Star Rating: A Scalable Framework for Aspect-Based Sentiment Analysis Using LLMs and Text Classification</a></h3>
                <p class="meta">By Vishal Patil, Shree Vaishnavi Bacha</p>
                <p class="text">Customer-provided reviews have become an important source of information for business owners and other customers alike. However, effectively analyzing millions of unstructured reviews remains challenging. While large language models (LLMs) show promise for natural language unders...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20976v1" target="_blank">Evaluating Proactive Risk Awareness of Large Language Models</a></h3>
                <p class="meta">By Xuan Luo, Yubin Chen</p>
                <p class="text">As large language models (LLMs) are increasingly embedded in everyday decision-making, their safety responsibilities extend beyond reacting to explicit harmful intent toward anticipating unintended but consequential risks. In this work, we introduce a proactive risk awareness eva...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20892v1" target="_blank">Exa-PSD: a new Persian sentiment analysis dataset on Twitter</a></h3>
                <p class="meta">By Seyed Himan Ghaderi, Saeed Sarbazi Azad</p>
                <p class="text">Today, Social networks such as Twitter are the most widely used platforms for communication of people. Analyzing this data has useful information to recognize the opinion of people in tweets. Sentiment analysis plays a vital role in NLP, which identifies the opinion of the indivi...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20859v1" target="_blank">FinAnchor: Aligned Multi-Model Representations for Financial Prediction</a></h3>
                <p class="meta">By Zirui He, Huopu Zhang</p>
                <p class="text">Financial prediction from long documents involves significant challenges, as actionable signals are often sparse and obscured by noise, and the optimal LLM for generating embeddings varies across tasks and time periods. In this paper, we propose FinAnchor(Financial Anchored Repre...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">VISION & MULTIMODAL DESK <span>206 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21137v1" target="_blank">ðŸ”¥ UDVideoQA: A Traffic Video Question Answering Dataset for Multi-Object Spatio-Temporal Reasoning in Urban Dynamics</a></h3>
                <p class="meta">By Joseph Raj Vishal, Nagasiri Poluri</p>
                <p class="text">Understanding the complex, multi-agent dynamics of urban traffic remains a fundamental challenge for video language models. This paper introduces Urban Dynamics VideoQA, a benchmark dataset that captures the unscripted real-world behavior of dynamic urban scenes. UDVideoQA is cur...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21053v1" target="_blank">ðŸ”¥ OCR-Agent: Agentic OCR with Capability and Memory Reflection</a></h3>
                <p class="meta">By Shimin Wen, Zeyu Zhang</p>
                <p class="text">Large Vision-Language Models (VLMs) have demonstrated significant potential on complex visual understanding tasks through iterative optimization methods.However, these models generally lack effective self-correction mechanisms, making it difficult for them to independently rectif...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20685v1" target="_blank">ðŸ”¥ RAYNOVA: 3D-Geometry-Free Auto-Regressive Driving World Modeling with Unified Spatio-Temporal Representation</a></h3>
                <p class="meta">By Yichen Xie, Chensheng Peng</p>
                <p class="text">World foundation models aim to simulate the evolution of the real world with physically plausible behavior. Unlike prior methods that handle spatial and temporal correlations separately, we propose RAYNOVA, a geometry-free world model that employs a dual-causal autoregressive fra...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19571v1" target="_blank">ðŸ”¥ HOCA-Bench: Beyond Semantic Perception to Predictive World Modeling via Hegelian Ontological-Causal Anomalies</a></h3>
                <p class="meta">By Chang Liu, Yunfan Ye</p>
                <p class="text">Video-LLMs have improved steadily on semantic perception, but they still fall short on predictive world modeling, which is central to physically grounded intelligence. We introduce HOCA-Bench, a benchmark that frames physical anomalies through a Hegelian lens. HOCA-Bench separate...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19442v1" target="_blank">ðŸ”¥ UrbanAlign: Post-hoc Semantic Calibration for VLM-Human Preference Alignment</a></h3>
                <p class="meta">By Yecheng Zhang, Rong Zhao</p>
                <p class="text">Aligning vision-language model (VLM) outputs with human preferences in domain-specific tasks typically requires fine-tuning or reinforcement learning, both of which demand labelled data and GPU compute. We show that for subjective perception tasks, this alignment can be achieved ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20951v1" target="_blank">ðŸ”¥ See and Fix the Flaws: Enabling VLMs and Diffusion Models to Comprehend Visual Artifacts via Agentic Data Synthesis</a></h3>
                <p class="meta">By Jaehyun Park, Minyoung Ahn</p>
                <p class="text">Despite recent advances in diffusion models, AI generated images still often contain visual artifacts that compromise realism. Although more thorough pre-training and bigger models might reduce artifacts, there is no assurance that they can be completely eliminated, which makes a...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20664v1" target="_blank">ðŸ”¥ AnimeAgent: Is the Multi-Agent via Image-to-Video models a Good Disney Storytelling Artist?</a></h3>
                <p class="meta">By Hailong Yan, Shice Liu</p>
                <p class="text">Custom Storyboard Generation (CSG) aims to produce high-quality, multi-character consistent storytelling. Current approaches based on static diffusion models, whether used in a one-shot manner or within multi-agent frameworks, face three key limitations: (1) Static models lack dy...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20550v1" target="_blank">ðŸ”¥ The Finite Primitive Basis Theorem for Computational Imaging: Formal Foundations of the OperatorGraph Representation</a></h3>
                <p class="meta">By Chengshuai Yang</p>
                <p class="text">Computational imaging forward models, from coded aperture spectral cameras to MRI scanners, are traditionally implemented as monolithic, modality-specific codes. We prove that every forward model in a broad, precisely defined operator class Cimg (encompassing clinical, scientific...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20543v1" target="_blank">ðŸ”¥ Beyond Human Performance: A Vision-Language Multi-Agent Approach for Quality Control in Pharmaceutical Manufacturing</a></h3>
                <p class="meta">By Subhra Jyoti Mandal, Lara Rachidi</p>
                <p class="text">Colony-forming unit (CFU) detection is critical in pharmaceutical manufacturing, serving as a key component of Environmental Monitoring programs and ensuring compliance with stringent quality standards. Manual counting is labor-intensive and error-prone, while deep learning (DL) ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19570v1" target="_blank">ðŸ”¥ VALD: Multi-Stage Vision Attack Detection for Efficient LVLM Defense</a></h3>
                <p class="meta">By Nadav Kadvil, Ayellet Tal</p>
                <p class="text">Large Vision-Language Models (LVLMs) can be vulnerable to adversarial images that subtly bias their outputs toward plausible yet incorrect responses. We introduce a general, efficient, and training-free defense that combines image transformations with agentic data consolidation t...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19542v1" target="_blank">ðŸ”¥ Vinedresser3D: Agentic Text-guided 3D Editing</a></h3>
                <p class="meta">By Yankuan Chi, Xiang Li</p>
                <p class="text">Text-guided 3D editing aims to modify existing 3D assets using natural-language instructions. Current methods struggle to jointly understand complex prompts, automatically localize edits in 3D, and preserve unedited content. We introduce Vinedresser3D, an agentic framework for hi...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.19503v1" target="_blank">ðŸ”¥ A Text-Guided Vision Model for Enhanced Recognition of Small Instances</a></h3>
                <p class="meta">By Hyun-Ki Jung</p>
                <p class="text">As drone-based object detection technology continues to evolve, the demand is shifting from merely detecting objects to enabling users to accurately identify specific targets. For example, users can input particular targets as prompts to precisely detect desired objects. To addre...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-22</div>
                <h3><a href="http://arxiv.org/abs/2602.19285v1" target="_blank">ðŸ”¥ MRI Contrast Enhancement Kinetics World Model</a></h3>
                <p class="meta">By Jindi Kong, Yuting He</p>
                <p class="text">Clinical MRI contrast acquisition suffers from inefficient information yield, which presents as a mismatch between the risky and costly acquisition protocol and the fixed and sparse acquisition sequence. Applying world models to simulate the contrast enhancement kinetics in the h...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21186v1" target="_blank">âš¡ Spa3R: Predictive Spatial Field Modeling for 3D Visual Reasoning</a></h3>
                <p class="meta">By Haoyi Jiang, Liu Liu</p>
                <p class="text">While Vision-Language Models (VLMs) exhibit exceptional 2D visual understanding, their ability to comprehend and reason about 3D space--a cornerstone of spatial intelligence--remains superficial. Current methodologies attempt to bridge this domain gap either by relying on explici...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21178v1" target="_blank">âš¡ XMorph: Explainable Brain Tumor Analysis Via LLM-Assisted Hybrid Deep Intelligence</a></h3>
                <p class="meta">By Sepehr Salem Ghahfarokhi, M. Moein Esfahani</p>
                <p class="text">Deep learning has significantly advanced automated brain tumor diagnosis, yet clinical adoption remains limited by interpretability and computational constraints. Conventional models often act as opaque ''black boxes'' and fail to quantify the complex, irregular tumor boundaries ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21015v1" target="_blank">âš¡ From Perception to Action: An Interactive Benchmark for Vision Reasoning</a></h3>
                <p class="meta">By Yuhao Wu, Maojia Song</p>
                <p class="text">Understanding the physical structure is essential for real-world applications such as embodied agents, interactive design, and long-horizon manipulation. Yet, prevailing Vision-Language Model (VLM) evaluations still center on structure-agnostic, single-turn setups (e.g., VQA), wh...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20980v1" target="_blank">âš¡ CrystaL: Spontaneous Emergence of Visual Latents in MLLMs</a></h3>
                <p class="meta">By Yang Zhang, Danyang Li</p>
                <p class="text">Multimodal Large Language Models (MLLMs) have achieved remarkable performance by integrating powerful language backbones with large-scale visual encoders. Among these, latent Chain-of-Thought (CoT) methods enable implicit reasoning in continuous hidden states, facilitating seamle...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20913v1" target="_blank">âš¡ LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding</a></h3>
                <p class="meta">By Jihao Qiu, Lingxi Xie</p>
                <p class="text">This paper addresses the critical and underexplored challenge of long video understanding with low computational budgets. We propose LongVideo-R1, an active, reasoning-equipped multimodal large language model (MLLM) agent designed for efficient video context navigation, avoiding ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20901v1" target="_blank">âš¡ SpatiaLQA: A Benchmark for Evaluating Spatial Logical Reasoning in Vision-Language Models</a></h3>
                <p class="meta">By Yuechen Xie, Xiaoyan Zhang</p>
                <p class="text">Vision-Language Models (VLMs) have been increasingly applied in real-world scenarios due to their outstanding understanding and reasoning capabilities. Although VLMs have already demonstrated impressive capabilities in common visual question answering and logical reasoning, they ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20853v1" target="_blank">âš¡ On the Explainability of Vision-Language Models in Art History</a></h3>
                <p class="meta">By Stefanie Schneider</p>
                <p class="text">Vision-Language Models (VLMs) transfer visual and textual data into a shared embedding space. In so doing, they enable a wide range of multimodal tasks, while also raising critical questions about the nature of machine 'understanding.' In this paper, we examine how Explainable Ar...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20851v1" target="_blank">âš¡ Hybrid Fusion: One-Minute Efficient Training for Zero-Shot Cross-Domain Image Fusion</a></h3>
                <p class="meta">By Ran Zhang, Xuanhua He</p>
                <p class="text">Image fusion seeks to integrate complementary information from multiple sources into a single, superior image. While traditional methods are fast, they lack adaptability and performance. Conversely, deep learning approaches achieve state-of-the-art (SOTA) results but suffer from ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20794v1" target="_blank">âš¡ VGGDrive: Empowering Vision-Language Models with Cross-View Geometric Grounding for Autonomous Driving</a></h3>
                <p class="meta">By Jie Wang, Guang Li</p>
                <p class="text">The significance of cross-view 3D geometric modeling capabilities for autonomous driving is self-evident, yet existing Vision-Language Models (VLMs) inherently lack this capability, resulting in their mediocre performance. While some promising approaches attempt to mitigate this ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20731v1" target="_blank">âš¡ Communication-Inspired Tokenization for Structured Image Representations</a></h3>
                <p class="meta">By Aram Davtyan, Yusuf Sahin</p>
                <p class="text">Discrete image tokenizers have emerged as a key component of modern vision and multimodal systems, providing a sequential interface for transformer-based architectures. However, most existing approaches remain primarily optimized for reconstruction and compression, often yielding...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20636v1" target="_blank">âš¡ SurgAtt-Tracker: Online Surgical Attention Tracking via Temporal Proposal Reranking and Motion-Aware Refinement</a></h3>
                <p class="meta">By Rulin Zhou, Guankun Wang</p>
                <p class="text">Accurate and stable field-of-view (FoV) guidance is critical for safe and efficient minimally invasive surgery, yet existing approaches often conflate visual attention estimation with downstream camera control or rely on direct object-centric assumptions. In this work, we formula...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20630v1" target="_blank">âš¡ From Pairs to Sequences: Track-Aware Policy Gradients for Keypoint Detection</a></h3>
                <p class="meta">By Yepeng Liu, Hao Li</p>
                <p class="text">Keypoint-based matching is a fundamental component of modern 3D vision systems, such as Structure-from-Motion (SfM) and SLAM. Most existing learning-based methods are trained on image pairs, a paradigm that fails to explicitly optimize for the long-term trackability of keypoints ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20608v1" target="_blank">âš¡ VAGNet: Grounding 3D Affordance from Human-Object Interactions in Videos</a></h3>
                <p class="meta">By Aihua Mao, Kaihang Huang</p>
                <p class="text">3D object affordance grounding aims to identify regions on 3D objects that support human-object interaction (HOI), a capability essential to embodied visual reasoning. However, most existing approaches rely on static visual or textual cues, neglecting that affordances are inheren...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20577v1" target="_blank">âš¡ Efficient and Explainable End-to-End Autonomous Driving via Masked Vision-Language-Action Diffusion</a></h3>
                <p class="meta">By Jiaru Zhang, Manav Gagvani</p>
                <p class="text">Large Language Models (LLMs) and Vision-Language Models (VLMs) have emerged as promising candidates for end-to-end autonomous driving. However, these models typically face challenges in inference latency, action precision, and explainability. Existing autoregressive approaches st...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20575v1" target="_blank">âš¡ An interactive enhanced driving dataset for autonomous driving</a></h3>
                <p class="meta">By Haojie Feng, Peizhi Zhang</p>
                <p class="text">The evolution of autonomous driving towards full automation demands robust interactive capabilities; however, the development of Vision-Language-Action (VLA) models is constrained by the sparsity of interactive scenarios and inadequate multimodal alignment in existing data. To th...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20511v1" target="_blank">âš¡ Leveraging Causal Reasoning Method for Explaining Medical Image Segmentation Models</a></h3>
                <p class="meta">By Limai Jiang, Ruitao Xie</p>
                <p class="text">Medical image segmentation plays a vital role in clinical decision-making, enabling precise localization of lesions and guiding interventions. Despite significant advances in segmentation accuracy, the black-box nature of most deep models has raised growing concerns about their t...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20501v1" target="_blank">âš¡ Probing and Bridging Geometry-Interaction Cues for Affordance Reasoning in Vision Foundation Models</a></h3>
                <p class="meta">By Qing Zhang, Xuesong Li</p>
                <p class="text">What does it mean for a visual system to truly understand affordance? We argue that this understanding hinges on two complementary capacities: geometric perception, which identifies the structural parts of objects that enable interaction, and interaction perception, which models ...</p>
            </div>
            
            </div>
        </section>
        
    </body>
    </html>
    