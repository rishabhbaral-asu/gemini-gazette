
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>The Silicon Scroll | Weekly Research</title>
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@900&family=Libre+Baskerville:wght@400;700&display=swap');
            
            body { background: #f4f1ea; color: #1a1a1a; font-family: 'Libre Baskerville', serif; margin: 0; padding: 2vw; }
            .masthead { text-align: center; border-bottom: 5px double #333; margin-bottom: 40px; padding-bottom: 15px; }
            .masthead h1 { font-family: 'Playfair Display'; font-size: 5rem; margin: 0; letter-spacing: -2px; }
            
            .news-desk { margin-bottom: 50px; }
            .desk-title { 
                border-bottom: 2px solid #333; 
                font-family: 'Playfair Display'; 
                font-size: 1.8rem; 
                margin-bottom: 15px; 
                padding-bottom: 5px; 
                display: flex; 
                justify-content: space-between; 
                align-items: center; 
            }
            .desk-title span { font-size: 0.7rem; font-family: 'Libre Baskerville'; opacity: 0.5; }
            
            .horizontal-scroll { 
                display: flex; 
                overflow-x: auto; 
                gap: 25px; 
                padding-bottom: 20px;
                scrollbar-width: thin;
                scrollbar-color: #333 #f4f1ea;
            }
            
            .horizontal-scroll::-webkit-scrollbar { height: 8px; }
            .horizontal-scroll::-webkit-scrollbar-thumb { background: #333; border-radius: 4px; }

            .card { 
                flex: 0 0 350px; 
                background: #fffefc; 
                border: 1px solid #d1cec1; 
                padding: 25px; 
                box-shadow: 4px 4px 0px rgba(0,0,0,0.05);
                transition: transform 0.2s;
                display: flex;
                flex-direction: column;
            }
            .card:hover { transform: translateY(-5px); }
            
            .card-date { font-size: 10px; font-weight: bold; color: #777; margin-bottom: 10px; }
            h3 { font-family: 'Playfair Display'; font-size: 1.3rem; margin: 0 0 10px 0; line-height: 1.2; }
            h3 a { color: #1a1a1a; text-decoration: none; }
            .meta { font-size: 11px; font-weight: bold; text-transform: uppercase; color: #555; margin-bottom: 10px; display: block; }
            .text { font-size: 13px; line-height: 1.6; color: #333; flex-grow: 1; }

            .ai-accent { border-top: 6px solid #2c3e50; }
            .nlp-accent { border-top: 6px solid #27ae60; }
            .vision-accent { border-top: 6px solid #e67e22; }
        </style>
    </head>
    <body>
        <div class="masthead">
            <div style="font-size: 50px; margin-bottom: 10px;">ðŸ¦‰</div>
            <h1>The Silicon Scroll</h1>
            <p>TEMPE, AZ â€” FEBRUARY 23, 2026 â€” WEEKLY INTELLIGENCE</p>
        </div>
        
        <section class="news-desk">
            <h2 class="desk-title">AI & REINFORCEMENT DESK <span>283 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card ai-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18291v1" target="_blank">ðŸ”¥ Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies</a></h3>
                <p class="meta">By Zhuoran Li, Hai Zhong</p>
                <p class="text">Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18026v1" target="_blank">ðŸ”¥ Mean-Field Reinforcement Learning without Synchrony</a></h3>
                <p class="meta">By Shan Yang</p>
                <p class="text">Mean-field reinforcement learning (MF-RL) scales multi-agent RL to large populations by reducing each agent's dependence on others to a single summary statistic -- the mean action. However, this reduction requires every agent to act at every time step; when some agents are idle, ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18008v1" target="_blank">ðŸ”¥ NIMMGen: Learning Neural-Integrated Mechanistic Digital Twins with LLMs</a></h3>
                <p class="meta">By Zihan Guan, Rituparna Datta</p>
                <p class="text">Mechanistic models encode scientific knowledge about dynamical systems and are widely used in downstream scientific and policy applications. Recent work has explored LLM-based agentic frameworks to automatically construct mechanistic models from data; however, existing problem se...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17902v1" target="_blank">ðŸ”¥ El Agente GrÃ¡fico: Structured Execution Graphs for Scientific Agents</a></h3>
                <p class="meta">By Jiaru Bai, Abdulrahman Aldossary</p>
                <p class="text">Large language models (LLMs) are increasingly used to automate scientific workflows, yet their integration with heterogeneous computational tools remains ad hoc and fragile. Current agentic approaches often rely on unstructured text to manage context and coordinate execution, gen...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17753v1" target="_blank">ðŸ”¥ The 2025 AI Agent Index: Documenting Technical and Safety Features of Deployed Agentic AI Systems</a></h3>
                <p class="meta">By Leon Staufer, Kevin Feng</p>
                <p class="text">Agentic AI systems are increasingly capable of performing professional and personal tasks with limited human involvement. However, tracking these developments is difficult because the AI agent ecosystem is complex, rapidly evolving, and inconsistently documented, posing obstacles...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17544v1" target="_blank">ðŸ”¥ Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability</a></h3>
                <p class="meta">By Shashank Aggarwal, Ram Vikas Mishra</p>
                <p class="text">In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17452v1" target="_blank">ðŸ”¥ Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge</a></h3>
                <p class="meta">By Wyatt Benno, Alberto Centelles</p>
                <p class="text">We present Jolt Atlas, a zero-knowledge machine learning (zkML) framework that extends the Jolt proving system to model inference. Unlike zkVMs (zero-knowledge virtual machines), which emulate CPU instruction execution, Jolt Atlas adapts Jolt's lookup-centric approach and applies...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17308v1" target="_blank">ðŸ”¥ MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions</a></h3>
                <p class="meta">By Hui Min Wong, Philip Heesen</p>
                <p class="text">Large language models (LLMs) are increasingly used for diagnostic tasks in medicine. In clinical practice, the correct diagnosis can rarely be immediately inferred from the initial patient presentation alone. Rather, reaching a diagnosis often involves systematic history taking, ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17245v1" target="_blank">ðŸ”¥ Web Verbs: Typed Abstractions for Reliable Task Composition on the Agentic Web</a></h3>
                <p class="meta">By Linxi Jiang, Rui Xi</p>
                <p class="text">The Web is evolving from a medium that humans browse to an environment where software agents act on behalf of users. Advances in large language models (LLMs) make natural language a practical interface for goal-directed tasks, yet most current web agents operate on low-level prim...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17221v1" target="_blank">ðŸ”¥ From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences</a></h3>
                <p class="meta">By Yi-Chih Huang</p>
                <p class="text">Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a "methodological experiment," this study propose...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17096v1" target="_blank">ðŸ”¥ Agentic Wireless Communication for 6G: Intent-Aware and Continuously Evolving Physical-Layer Intelligence</a></h3>
                <p class="meta">By Zhaoyang Li, Xingzhi Jin</p>
                <p class="text">As 6G wireless systems evolve, growing functional complexity and diverse service demands are driving a shift from rule-based control to intent-driven autonomous intelligence. User requirements are no longer captured by a single metric (e.g., throughput or reliability), but by mul...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17062v1" target="_blank">ðŸ”¥ Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning</a></h3>
                <p class="meta">By Yonghyeon Jo, Sunwoo Lee</p>
                <p class="text">Value decomposition is a core approach for cooperative multi-agent reinforcement learning (MARL). However, existing methods still rely on a single optimal action and struggle to adapt when the underlying value function shifts during training, often converging to suboptimal polici...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17049v1" target="_blank">ðŸ”¥ IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents</a></h3>
                <p class="meta">By Seoyoung Lee, Seobin Yoon</p>
                <p class="text">Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17038v1" target="_blank">ðŸ”¥ Phase-Aware Mixture of Experts for Agentic Reinforcement Learning</a></h3>
                <p class="meta">By Shengtian Yang, Yu Li</p>
                <p class="text">Reinforcement learning (RL) has equipped LLM agents with a strong ability to solve complex tasks. However, existing RL methods normally use a \emph{single} policy network, causing \emph{simplicity bias} where simple tasks occupy most parameters and dominate gradient updates, leav...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17037v2" target="_blank">ðŸ”¥ Wink: Recovering from Misbehaviors in Coding Agents</a></h3>
                <p class="meta">By Rahul Nanda, Chandra Maddila</p>
                <p class="text">Autonomous coding agents, powered by large language models (LLMs), are increasingly being adopted in the software industry to automate complex engineering tasks. However, these agents are prone to a wide range of misbehaviors, such as deviating from the user's instructions, getti...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.16966v1" target="_blank">ðŸ”¥ A Unified Framework for Locality in Scalable MARL</a></h3>
                <p class="meta">By Sourav Chakraborty, Amit Kiran Rege</p>
                <p class="text">Scalable Multi-Agent Reinforcement Learning (MARL) is fundamentally challenged by the curse of dimensionality. A common solution is to exploit locality, which hinges on an Exponential Decay Property (EDP) of the value function. However, existing conditions that guarantee the EDP ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16953v1" target="_blank">ðŸ”¥ LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation</a></h3>
                <p class="meta">By Hejia Zhang, Zhongming Yu</p>
                <p class="text">Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its relianc...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16928v1" target="_blank">ðŸ”¥ Discovering Multiagent Learning Algorithms with Large Language Models</a></h3>
                <p class="meta">By Zun Li, John Schultz</p>
                <p class="text">Much of the advancement of Multi-Agent Reinforcement Learning (MARL) in imperfect-information games has historically depended on manual iterative refinement of baselines. While foundational families like Counterfactual Regret Minimization (CFR) and Policy Space Response Oracles (...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16898v2" target="_blank">ðŸ”¥ MALLVI: A Multi-Agent Framework for Integrated Generalized Robotics Manipulation</a></h3>
                <p class="meta">By Iman Ahmadi, Mehrshad Taji</p>
                <p class="text">Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16873v1" target="_blank">ðŸ”¥ AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence</a></h3>
                <p class="meta">By Geunbin Yu</p>
                <p class="text">As large language models from diverse providers converge toward comparable benchmark performance, the traditional paradigm of selecting a single best model per task yields diminishing returns. We argue that orchestration topology -- the structural composition of how multiple agen...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16844v1" target="_blank">ðŸ”¥ Overseeing Agents Without Constant Oversight: Challenges and Opportunities</a></h3>
                <p class="meta">By Madeleine Grunde-McLaughlin, Hussein Mozannar</p>
                <p class="text">To enable human oversight, agentic AI systems often provide a trace of reasoning and action steps. Designing traces to have an informative, but not overwhelming, level of detail remains a critical challenge. In three user studies on a Computer User Agent, we investigate the utili...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.17734v1" target="_blank">ðŸ”¥ Five Fatal Assumptions: Why T-Shirt Sizing Systematically Fails for AI Projects</a></h3>
                <p class="meta">By Raja Soundaramourty, Ozkan Kilic</p>
                <p class="text">Agile estimation techniques, particularly T-shirt sizing, are widely used in software development for their simplicity and utility in scoping work. However, when we apply these methods to artificial intelligence initiatives -- especially those involving large language models (LLM...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16708v2" target="_blank">ðŸ”¥ Policy Compiler for Secure Agentic Systems</a></h3>
                <p class="meta">By Nils Palumbo, Sarthak Choudhary</p>
                <p class="text">LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We p...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16666v1" target="_blank">ðŸ”¥ Towards a Science of AI Agent Reliability</a></h3>
                <p class="meta">By Stephan Rabanser, Sayash Kapoor</p>
                <p class="text">AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing age...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16554v1" target="_blank">ðŸ”¥ MerLean: An Agentic Framework for Autoformalization in Quantum Computation</a></h3>
                <p class="meta">By Yuanjie Ren, Jinzheng Li</p>
                <p class="text">We introduce MerLean, a fully automated agentic framework for autoformalization in quantum computation. MerLean extracts mathematical statements from \LaTeX{} source files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into human-reada...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16435v1" target="_blank">ðŸ”¥ Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning</a></h3>
                <p class="meta">By Arun Vignesh Malarkkan, Wangyang Ying</p>
                <p class="text">Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a fr...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16301v1" target="_blank">ðŸ”¥ Multi-agent cooperation through in-context co-player inference</a></h3>
                <p class="meta">By Marissa A. Weis, Maciej WoÅ‚czyk</p>
                <p class="text">Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16246v1" target="_blank">ðŸ”¥ Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents</a></h3>
                <p class="meta">By Yun-Shiuan Chuang, Chaitanya Kulkarni</p>
                <p class="text">Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-be...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16196v1" target="_blank">ðŸ”¥ Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning</a></h3>
                <p class="meta">By Emile Anand, Richard Hoffmann</p>
                <p class="text">Coordinating large populations of interacting agents is a central challenge in multi-agent reinforcement learning (MARL), where the size of the joint state-action space scales exponentially with the number of agents. Mean-field methods alleviate this burden by aggregating agent i...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16179v3" target="_blank">ðŸ”¥ EnterpriseBench Corecraft: Training Generalizable Agents on High-Fidelity RL Environments</a></h3>
                <p class="meta">By Sushant Mehta, Logan Ritchie</p>
                <p class="text">We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce CoreCraft, the first environment in EnterpriseBench, Surge AI's suite of agentic RL environments. CoreCraft is...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">NLP & LANGUAGE DESK <span>98 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18137v1" target="_blank">ðŸ”¥ Agentic Adversarial QA for Improving Domain-Specific LLMs</a></h3>
                <p class="meta">By Vincent Grari, Ciprian Tomoiaga</p>
                <p class="text">Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17127v1" target="_blank">ðŸ”¥ The Emergence of Lab-Driven Alignment Signatures: A Psychometric Framework for Auditing Latent Bias and Compounding Risk in Generative AI</a></h3>
                <p class="meta">By Dusan Bosnjakovic</p>
                <p class="text">As Large Language Models (LLMs) transition from standalone chat interfaces to foundational reasoning layers in multi-agent systems and recursive evaluation loops (LLM-as-a-judge), the detection of durable, provider-level behavioral signatures becomes a critical requirement for sa...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16485v1" target="_blank">ðŸ”¥ Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling</a></h3>
                <p class="meta">By Jeffrey T. H. Wong, Zixi Zhang</p>
                <p class="text">Existing Multi-Agent Systems (MAS) typically rely on static, homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16313v1" target="_blank">ðŸ”¥ MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks</a></h3>
                <p class="meta">By Zexue He, Yu Wang</p>
                <p class="text">Existing evaluations of agents with memory typically assess memorization and action in isolation. One class of benchmarks evaluates memorization by testing recall of past conversations or text but fails to capture how memory is used to guide future decisions. Another class focuse...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18425v1" target="_blank">ðŸ”¥ RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering</a></h3>
                <p class="meta">By Deniz Qian, Hung-Ting Chen</p>
                <p class="text">Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original quer...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18029v1" target="_blank">ðŸ”¥ Towards More Standardized AI Evaluation: From Models to Agents</a></h3>
                <p class="meta">By Ali El Filali, InÃ¨s Bedar</p>
                <p class="text">Evaluation is no longer a final checkpoint in the machine learning lifecycle. As AI systems evolve from static models to compound, tool-using agents, evaluation becomes a core control function. The question is no longer "How good is the model?" but "Can we trust the system to beh...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17588v1" target="_blank">ðŸ”¥ Modeling Distinct Human Interaction in Web Agents</a></h3>
                <p class="meta">By Faria Huq, Zora Zhiruo Wang</p>
                <p class="text">Despite rapid progress in autonomous web agents, human involvement remains essential for shaping preferences and correcting agent behavior as tasks unfold. However, current agentic systems lack a principled understanding of when and why humans intervene, often proceeding autonomo...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16429v1" target="_blank">ðŸ”¥ TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers</a></h3>
                <p class="meta">By Ido Levy, Eilam Shapira</p>
                <p class="text">Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing, shortlisting, gating, and verification. While convenient, this...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16379v1" target="_blank">ðŸ”¥ Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents</a></h3>
                <p class="meta">By Mohammad H. A. Monfared, Lucie Flek</p>
                <p class="text">We propose an agentic data augmentation method for Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched prompting-b...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18429v1" target="_blank">âš¡ VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning</a></h3>
                <p class="meta">By Harshul Raj Surana, Arijit Maji</p>
                <p class="text">Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18351v1" target="_blank">âš¡ Validating Political Position Predictions of Arguments</a></h3>
                <p class="meta">By Jordan Robinson, Angus R. Williams</p>
                <p class="text">Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validati...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18346v1" target="_blank">âš¡ Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System</a></h3>
                <p class="meta">By Pavithra PM Nair, Preethu Rose Anish</p>
                <p class="text">In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts rev...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18232v1" target="_blank">âš¡ Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning</a></h3>
                <p class="meta">By Lexiang Tang, Weihao Gao</p>
                <p class="text">Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18176v1" target="_blank">âš¡ Improving Sampling for Masked Diffusion Models via Information Gain</a></h3>
                <p class="meta">By Kaisen Yang, Jayden Teoh</p>
                <p class="text">Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to d...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18092v1" target="_blank">âš¡ Perceived Political Bias in LLMs Reduces Persuasive Abilities</a></h3>
                <p class="meta">By Matthew DiGiuseppe, Joshua Robison</p>
                <p class="text">Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligne...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.17949v1" target="_blank">âš¡ CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications</a></h3>
                <p class="meta">By Victoria Blake, Mathew Miller</p>
                <p class="text">Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related syno...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.17937v1" target="_blank">âš¡ Analyzing LLM Instruction Optimization for Tabular Fact Verification</a></h3>
                <p class="meta">By Xiaotang Du, Giwon Hong</p>
                <p class="text">Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.17911v1" target="_blank">âš¡ Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering</a></h3>
                <p class="meta">By Jash Rajesh Parekh, Wonbin Kweon</p>
                <p class="text">Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing b...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17623v1" target="_blank">âš¡ Unmasking the Factual-Conceptual Gap in Persian Language Models</a></h3>
                <p class="meta">By Alireza Sakhaeirad, Ali Ma'manpoosh</p>
                <p class="text">While emerging Persian NLP benchmarks have expanded into pragmatics and politeness, they rarely distinguish between memorized cultural facts and the ability to reason about implicit social norms. We introduce DivanBench, a diagnostic benchmark focused on superstitions and customs...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17546v1" target="_blank">âš¡ Learning to Stay Safe: Adaptive Regularization Against Safety Degradation during Fine-Tuning</a></h3>
                <p class="meta">By Jyotin Goel, Souvik Maji</p>
                <p class="text">Instruction-following language models are trained to be helpful and safe, yet their safety behavior can deteriorate under benign fine-tuning and worsen under adversarial updates. Existing defenses often offer limited protection or force a trade-off between safety and utility. We ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17443v1" target="_blank">âš¡ AIDG: Evaluating Asymmetry Between Information Extraction and Containment in Multi-Turn Dialogue</a></h3>
                <p class="meta">By Adib Sakhawat, Fardeen Sadab</p>
                <p class="text">Evaluating the strategic reasoning capabilities of Large Language Models (LLMs) requires moving beyond static benchmarks to dynamic, multi-turn interactions. We introduce AIDG (Adversarial Information Deduction Game), a game-theoretic framework that probes the asymmetry between i...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17072v1" target="_blank">âš¡ BankMathBench: A Benchmark for Numerical Reasoning in Banking Scenarios</a></h3>
                <p class="meta">By Yunseung Lee, Subin Kim</p>
                <p class="text">Large language models (LLMs)-based chatbots are increasingly being adopted in the financial domain, particularly in digital banking, to handle customer inquiries about products such as deposits, savings, and loans. However, these models still exhibit low accuracy in core banking ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17054v1" target="_blank">âš¡ ALPS: A Diagnostic Challenge Set for Arabic Linguistic & Pragmatic Reasoning</a></h3>
                <p class="meta">By Hussein S. Al-Olimat, Ahmad Alshareef</p>
                <p class="text">While recent Arabic NLP benchmarks focus on scale, they often rely on synthetic or translated data which may benefit from deeper linguistic verification. We introduce ALPS (Arabic Linguistic & Pragmatic Suite), a native, expert-curated diagnostic challenge set probing Deep Semant...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17045v1" target="_blank">âš¡ Large Language Models Persuade Without Planning Theory of Mind</a></h3>
                <p class="meta">By Jared Moore, Rasmus Overmark</p>
                <p class="text">A growing body of work attempts to evaluate the theory of mind (ToM) abilities of humans and large language models (LLMs) using static, non-interactive question-and-answer benchmarks. However, theoretical work in the field suggests that first-personal interaction is a crucial par...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17022v1" target="_blank">âš¡ ReIn: Conversational Error Recovery with Reasoning Inception</a></h3>
                <p class="meta">By Takyoung Kim, Jinseok Nam</p>
                <p class="text">Conversational agents powered by large language models (LLMs) with tool integration achieve strong performance on fixed task-oriented dialogue datasets but remain vulnerable to unanticipated, user-induced errors. Rather than focusing on error prevention, this work focuses on erro...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17003v1" target="_blank">âš¡ Persona2Web: Benchmarking Personalized Web Agents for Contextual Reasoning with User History</a></h3>
                <p class="meta">By Serin Kim, Sangam Lee</p>
                <p class="text">Large language models have advanced web agents, yet current agents lack personalization capabilities. Since users rarely specify every detail of their intent, practical web agents must be able to interpret ambiguous queries by inferring user preferences and contexts. To address t...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16802v1" target="_blank">âš¡ References Improve LLM Alignment in Non-Verifiable Domains</a></h3>
                <p class="meta">By Kejian Shi, Yixin Liu</p>
                <p class="text">While Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong effectiveness in reasoning tasks, it cannot be directly applied to non-verifiable domains lacking ground-truth verifiers, such as LLM alignment. In this work, we investigate whether reference-guided LLM-...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16704v1" target="_blank">âš¡ Reinforced Fast Weights with Next-Sequence Prediction</a></h3>
                <p class="meta">By Hee Seung Hwang, Xindi Wu</p>
                <p class="text">Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP op...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16516v1" target="_blank">âš¡ Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification</a></h3>
                <p class="meta">By Taja Kuzman PungerÅ¡ek, Peter Rupnik</p>
                <p class="text">This paper introduces ParlaCAP, a large-scale dataset for analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the multilingual Pa...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16490v1" target="_blank">âš¡ From Growing to Looping: A Unified View of Iterative Computation in LLMs</a></h3>
                <p class="meta">By Ferdinand Kapl, Emmanouil Angelis</p>
                <p class="text">Looping, reusing a block of layers across depth, and depth growing, training shallow-to-deep models by duplicating middle layers, have both been linked to stronger reasoning, but their relationship remains unclear. We provide a mechanistic unification: looped and depth-grown mode...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">VISION & MULTIMODAL DESK <span>119 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18432v1" target="_blank">ðŸ”¥ SARAH: Spatially Aware Real-time Agentic Humans</a></h3>
                <p class="meta">By Evonne Ng, Siwei Zhang</p>
                <p class="text">As embodied agents become central to VR, telepresence, and digital human applications, their motion must go beyond speech-aligned gestures: agents should turn toward users, respond to their movement, and maintain natural gaze. Current methods lack this spatial awareness. We close...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18422v1" target="_blank">ðŸ”¥ Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control</a></h3>
                <p class="meta">By Linxi Xie, Lisong C. Sun</p>
                <p class="text">Extended reality (XR) demands generative models that respond to users' tracked real-world motion, yet current video world models accept only coarse control signals such as text or keyboard input, limiting their utility for embodied interaction. We introduce a human-centric video ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17030v1" target="_blank">ðŸ”¥ Patch-Based Spatial Authorship Attribution in Human-Robot Collaborative Paintings</a></h3>
                <p class="meta">By Eric Chen, Patricia Alves-Oliveira</p>
                <p class="text">As agentic AI becomes increasingly involved in creative production, documenting authorship has become critical for artists, collectors, and legal contexts. We present a patch-based framework for spatial authorship attribution within human-robot collaborative painting practice, de...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18434v1" target="_blank">âš¡ Going Down Memory Lane: Scaling Tokens for Video Stream Understanding with Dynamic KV-Cache Memory</a></h3>
                <p class="meta">By Vatsal Agarwal, Saksham Suri</p>
                <p class="text">Streaming video understanding requires models to robustly encode, store, and retrieve information from a continuous video stream to support accurate video question answering (VQA). Existing state-of-the-art approaches rely on key-value caching to accumulate frame-level informatio...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18424v1" target="_blank">âš¡ CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation</a></h3>
                <p class="meta">By Xia Su, Ruiqi Chen</p>
                <p class="text">Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the a...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18193v1" target="_blank">âš¡ BLM-Guard: Explainable Multimodal Ad Moderation with Chain-of-Thought and Policy-Aligned Rewards</a></h3>
                <p class="meta">By Yiran Yang, Zhaowei Liu</p>
                <p class="text">Short-video platforms now host vast multimodal ads whose deceptive visuals, speech and subtitles demand finer-grained, policy-driven moderation than community safety filters. We present BLM-Guard, a content-audit framework for commercial ads that fuses Chain-of-Thought reasoning ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18064v1" target="_blank">âš¡ 3DMedAgent: Unified Perception-to-Understanding for 3D Medical Analysis</a></h3>
                <p class="meta">By Ziyue Wang, Linghan Cai</p>
                <p class="text">3D CT analysis spans a continuum from low-level perception to high-level clinical understanding. Existing 3D-oriented analysis methods adopt either isolated task-specific modeling or task-agnostic end-to-end paradigms to produce one-hop outputs, impeding the systematic accumulati...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17871v1" target="_blank">âš¡ Understanding the Fine-Grained Knowledge Capabilities of Vision-Language Models</a></h3>
                <p class="meta">By Dhruba Ghosh, Yuhui Zhang</p>
                <p class="text">Vision-language models (VLMs) have made substantial progress across a wide range of visual question answering benchmarks, spanning visual reasoning, document understanding, and multimodal dialogue. These improvements are evident in a wide range of VLMs built on a variety of base ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17799v1" target="_blank">âš¡ Enabling Training-Free Text-Based Remote Sensing Segmentation</a></h3>
                <p class="meta">By Jose Sosa, Danila Rukhovich</p>
                <p class="text">Recent advances in Vision Language Models (VLMs) and Vision Foundation Models (VFMs) have opened new opportunities for zero-shot text-guided segmentation of remote sensing imagery. However, most existing approaches still rely on additional trainable components, limiting their gen...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17665v1" target="_blank">âš¡ OpenEarthAgent: A Unified Framework for Tool-Augmented Geospatial Agents</a></h3>
                <p class="meta">By Akashah Shabbir, Muhammad Umer Sheikh</p>
                <p class="text">Recent progress in multimodal reasoning has enabled agents that can interpret imagery, connect it with language, and perform structured analytical tasks. Extending such capabilities to the remote sensing domain remains challenging, as models must reason over spatial scale, geogra...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17659v1" target="_blank">âš¡ When Vision Overrides Language: Evaluating and Mitigating Counterfactual Failures in VLAs</a></h3>
                <p class="meta">By Yu Fang, Yuchun Feng</p>
                <p class="text">Vision-Language-Action models (VLAs) promise to ground language instructions in robot control, yet in practice often fail to faithfully follow language. When presented with instructions that lack strong scene-specific supervision, VLAs suffer from counterfactual failures: they ac...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17605v1" target="_blank">âš¡ Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery</a></h3>
                <p class="meta">By Jowaria Khan, Anindya Sarkar</p>
                <p class="text">In many real-world settings, such as environmental monitoring, disaster response, or public health, with costly and difficult data collection and dynamic environments, strategically sampling from unobserved regions is essential for efficiently uncovering hidden targets under tigh...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17558v1" target="_blank">âš¡ RetouchIQ: MLLM Agents for Instruction-Based Image Retouching with Generalist Reward</a></h3>
                <p class="meta">By Qiucheng Wu, Jing Shi</p>
                <p class="text">Recent advances in multimodal large language models (MLLMs) have shown great potential for extending vision-language reasoning to professional tool-based image editing, enabling intuitive and creative editing. A promising direction is to use reinforcement learning (RL) to enable ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17555v1" target="_blank">âš¡ GraphThinker: Reinforcing Video Reasoning with Event Graph Thinking</a></h3>
                <p class="meta">By Zixu Cheng, Da Li</p>
                <p class="text">Video reasoning requires understanding the causal relationships between events in a video. However, such relationships are often implicit and costly to annotate manually. While existing multimodal large language models (MLLMs) often infer event relations through dense captions or...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-19</div>
                <h3><a href="http://arxiv.org/abs/2602.17134v1" target="_blank">âš¡ B$^3$-Seg: Camera-Free, Training-Free 3DGS Segmentation via Analytic EIG and Beta-Bernoulli Bayesian Updates</a></h3>
                <p class="meta">By Hiromichi Kamata, Samuel Arthur Munro</p>
                <p class="text">Interactive 3D Gaussian Splatting (3DGS) segmentation is essential for real-time editing of pre-reconstructed assets in film and game production. However, existing methods rely on predefined camera viewpoints, ground-truth labels, or costly retraining, making them impractical for...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16702v1" target="_blank">âš¡ Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning</a></h3>
                <p class="meta">By Mingjia Shi, Yinhan He</p>
                <p class="text">Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16682v1" target="_blank">âš¡ Learning Situated Awareness in the Real World</a></h3>
                <p class="meta">By Chuhan Li, Ruilin Han</p>
                <p class="text">A core aspect of human perception is situated awareness, the ability to relate ourselves to the surrounding physical environment and reason over possible actions in context. However, most existing benchmarks for multimodal foundation models (MFMs) emphasize environment-centric sp...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16669v1" target="_blank">âš¡ PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction</a></h3>
                <p class="meta">By Bo Lang, Nirav Savaliya</p>
                <p class="text">High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which le...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16455v1" target="_blank">âš¡ Visual Self-Refine: A Pixel-Guided Paradigm for Accurate Chart Parsing</a></h3>
                <p class="meta">By Jinsong Li, Xiaoyi Dong</p>
                <p class="text">While Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities for reasoning and self-correction at the textual level, these strengths provide minimal benefits for complex tasks centered on visual perception, such as Chart Parsing. Existing models often stru...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-18</div>
                <h3><a href="http://arxiv.org/abs/2602.16160v2" target="_blank">âš¡ Uncertainty-Guided Inference-Time Depth Adaptation for Transformer-Based Visual Tracking</a></h3>
                <p class="meta">By Patrick Poggi, Divake Kumar</p>
                <p class="text">Transformer-based single-object trackers achieve state-of-the-art accuracy but rely on fixed-depth inference, executing the full encoder--decoder stack for every frame regardless of visual complexity, thereby incurring unnecessary computational cost in long video sequences domina...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18406v1" target="_blank">Latent Equivariant Operators for Robust Object Recognition: Promise and Challenges</a></h3>
                <p class="meta">By Minh Dinh, StÃ©phane Deny</p>
                <p class="text">Despite the successes of deep learning in computer vision, difficulties persist in recognizing objects that have undergone group-symmetric transformations rarely seen during training-for example objects seen in unusual poses, scales, positions, or combinations thereof. Equivarian...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18394v1" target="_blank">Self-Aware Object Detection via Degradation Manifolds</a></h3>
                <p class="meta">By Stefan Becker, Simon Weiss</p>
                <p class="text">Object detectors achieve strong performance under nominal imaging conditions but can fail silently when exposed to blur, noise, compression, adverse weather, or resolution changes. In safety-critical settings, it is therefore insufficient to produce predictions without assessing ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18329v1" target="_blank">G-LoG Bi-filtration for Medical Image Classification</a></h3>
                <p class="meta">By Qingsong Wang, Jiaxing He</p>
                <p class="text">Building practical filtrations on objects to detect topological and geometric features is an important task in the field of Topological Data Analysis (TDA). In this paper, leveraging the ability of the Laplacian of Gaussian operator to enhance the boundaries of medical images, we...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18322v1" target="_blank">Unifying Color and Lightness Correction with View-Adaptive Curve Adjustment for Robust 3D Novel View Synthesis</a></h3>
                <p class="meta">By Ziteng Cui, Shuhong Liu</p>
                <p class="text">High-quality image acquisition in real-world environments remains challenging due to complex illumination variations and inherent limitations of camera imaging pipelines. These issues are exacerbated in multi-view capture, where differences in lighting, sensor responses, and imag...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18314v1" target="_blank">Diff2DGS: Reliable Reconstruction of Occluded Surgical Scenes via 2D Gaussian Splatting</a></h3>
                <p class="meta">By Tianyi Song, Danail Stoyanov</p>
                <p class="text">Real-time reconstruction of deformable surgical scenes is vital for advancing robotic surgery, improving surgeon guidance, and enabling automation. Recent methods achieve dense reconstructions from da Vinci robotic surgery videos, with Gaussian Splatting (GS) offering real-time p...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18309v1" target="_blank">Multi-Level Conditioning by Pairing Localized Text and Sketch for Fashion Image Generation</a></h3>
                <p class="meta">By Ziyue Liu, Davide Talon</p>
                <p class="text">Sketches offer designers a concise yet expressive medium for early-stage fashion ideation by specifying structure, silhouette, and spatial relationships, while textual descriptions complement sketches to convey material, color, and stylistic details. Effectively combining textual...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18282v1" target="_blank">DEIG: Detail-Enhanced Instance Generation with Fine-Grained Semantic Control</a></h3>
                <p class="meta">By Shiyan Du, Conghan Yue</p>
                <p class="text">Multi-Instance Generation has advanced significantly in spatial placement and attribute binding. However, existing approaches still face challenges in fine-grained semantic understanding, particularly when dealing with complex textual descriptions. To overcome these limitations, ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18252v1" target="_blank">On the Adversarial Robustness of Discrete Image Tokenizers</a></h3>
                <p class="meta">By Rishika Bhagwatkar, Irina Rish</p>
                <p class="text">Discrete image tokenizers encode visual inputs as sequences of tokens from a finite vocabulary and are gaining popularity in multimodal systems, including encoder-only, encoder-decoder, and decoder-only models. However, unlike CLIP encoders, their vulnerability to adversarial att...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18199v1" target="_blank">A Self-Supervised Approach on Motion Calibration for Enhancing Physical Plausibility in Text-to-Motion</a></h3>
                <p class="meta">By Gahyeon Shim, Soogeun Park</p>
                <p class="text">Generating semantically aligned human motion from textual descriptions has made rapid progress, but ensuring both semantic and physical realism in motion remains a challenge. In this paper, we introduce the Distortion-aware Motion Calibrator (DMC), a post-hoc module that refines ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-20</div>
                <h3><a href="http://arxiv.org/abs/2602.18178v1" target="_blank">Evaluating Graphical Perception Capabilities of Vision Transformers</a></h3>
                <p class="meta">By Poonam Poonam, Pere-Pau VÃ¡zquez</p>
                <p class="text">Vision Transformers, ViTs, have emerged as a powerful alternative to convolutional neural networks, CNNs, in a variety of image-based tasks. While CNNs have previously been evaluated for their ability to perform graphical perception tasks, which are essential for interpreting vis...</p>
            </div>
            
            </div>
        </section>
        
    </body>
    </html>
    