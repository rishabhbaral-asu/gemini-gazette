
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>The Silicon Scroll | Weekly Research</title>
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@900&family=Libre+Baskerville:wght@400;700&display=swap');
            
            body { background: #f4f1ea; color: #1a1a1a; font-family: 'Libre Baskerville', serif; margin: 0; padding: 2vw; }
            .masthead { text-align: center; border-bottom: 5px double #333; margin-bottom: 40px; padding-bottom: 15px; }
            .masthead h1 { font-family: 'Playfair Display'; font-size: 5rem; margin: 0; letter-spacing: -2px; }
            
            .news-desk { margin-bottom: 50px; }
            .desk-title { 
                border-bottom: 2px solid #333; 
                font-family: 'Playfair Display'; 
                font-size: 1.8rem; 
                margin-bottom: 15px; 
                padding-bottom: 5px; 
                display: flex; 
                justify-content: space-between; 
                align-items: center; 
            }
            .desk-title span { font-size: 0.7rem; font-family: 'Libre Baskerville'; opacity: 0.5; }
            
            .horizontal-scroll { 
                display: flex; 
                overflow-x: auto; 
                gap: 25px; 
                padding-bottom: 20px;
                scrollbar-width: thin;
                scrollbar-color: #333 #f4f1ea;
            }
            
            .horizontal-scroll::-webkit-scrollbar { height: 8px; }
            .horizontal-scroll::-webkit-scrollbar-thumb { background: #333; border-radius: 4px; }

            .card { 
                flex: 0 0 350px; 
                background: #fffefc; 
                border: 1px solid #d1cec1; 
                padding: 25px; 
                box-shadow: 4px 4px 0px rgba(0,0,0,0.05);
                transition: transform 0.2s;
                display: flex;
                flex-direction: column;
            }
            .card:hover { transform: translateY(-5px); }
            
            .card-date { font-size: 10px; font-weight: bold; color: #777; margin-bottom: 10px; }
            h3 { font-family: 'Playfair Display'; font-size: 1.3rem; margin: 0 0 10px 0; line-height: 1.2; }
            h3 a { color: #1a1a1a; text-decoration: none; }
            .meta { font-size: 11px; font-weight: bold; text-transform: uppercase; color: #555; margin-bottom: 10px; display: block; }
            .text { font-size: 13px; line-height: 1.6; color: #333; flex-grow: 1; }

            .ai-accent { border-top: 6px solid #2c3e50; }
            .nlp-accent { border-top: 6px solid #27ae60; }
            .vision-accent { border-top: 6px solid #e67e22; }
        </style>
    </head>
    <body>
        <div class="masthead">
            <div style="font-size: 50px; margin-bottom: 10px;">ðŸ¦‰</div>
            <h1>The Silicon Scroll</h1>
            <p>TEMPE, AZ â€” MARCH 01, 2026 â€” WEEKLY INTELLIGENCE</p>
        </div>
        
        <section class="news-desk">
            <h2 class="desk-title">AI & REINFORCEMENT DESK <span>215 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23258v1" target="_blank">ðŸ”¥ AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning</a></h3>
                <p class="meta">By Yutong Wang, Siyuan Xiong</p>
                <p class="text">While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability a...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23193v1" target="_blank">ðŸ”¥ ESAA: Event Sourcing for Autonomous Agents in LLM-Based Software Engineering</a></h3>
                <p class="meta">By Elzo Brito dos Santos Filho</p>
                <p class="text">Autonomous agents based on Large Language Models (LLMs) have evolved from reactive assistants to systems capable of planning, executing actions via tools, and iterating over environment observations. However, they remain vulnerable to structural limitations: lack of native state,...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23152v1" target="_blank">ðŸ”¥ The Trinity of Consistency as a Defining Principle for General World Models</a></h3>
                <p class="meta">By Jingxuan Wei, Siyuan Li</p>
                <p class="text">The construction of World Models capable of learning, simulating, and reasoning about objective physical laws constitutes a foundational challenge in the pursuit of Artificial General Intelligence. Recent advancements represented by video generation models like Sora have demonstr...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23148v1" target="_blank">ðŸ”¥ On Sample-Efficient Generalized Planning via Learned Transition Models</a></h3>
                <p class="meta">By Nitin Gupta, Vishal Pallagani</p>
                <p class="text">Generalized planning studies the construction of solution strategies that generalize across families of planning problems sharing a common domain model, formally defined by a transition function $Î³: S \times A \rightarrow S$. Classical approaches achieve such generalization throu...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23073v1" target="_blank">ðŸ”¥ Accelerated Online Risk-Averse Policy Evaluation in POMDPs with Theoretical Guarantees and Novel CVaR Bounds</a></h3>
                <p class="meta">By Yaacov Pariente, Vadim Indelman</p>
                <p class="text">Risk-averse decision-making under uncertainty in partially observable domains is a central challenge in artificial intelligence and is essential for developing reliable autonomous agents. The formal framework for such problems is the partially observable Markov decision process (...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23056v1" target="_blank">ðŸ”¥ Learning-based Multi-agent Race Strategies in Formula 1</a></h3>
                <p class="meta">By Giona Fieni, Joschua WÃ¼thrich</p>
                <p class="text">In Formula 1, race strategies are adapted according to evolving race conditions and competitors' actions. This paper proposes a reinforcement learning approach for multi-agent race strategy optimization. Agents learn to balance energy management, tire degradation, aerodynamic int...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22963v1" target="_blank">ðŸ”¥ FactGuard: Agentic Video Misinformation Detection via Reinforcement Learning</a></h3>
                <p class="meta">By Zehao Li, Hongwei Yu</p>
                <p class="text">Multimodal large language models (MLLMs) have substantially advanced video misinformation detection through unified multimodal reasoning, but they often rely on fixed-depth inference and place excessive trust in internally generated assumptions, particularly in scenarios where cr...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22839v1" target="_blank">ðŸ”¥ DeepPresenter: Environment-Grounded Reflection for Agentic Presentation Generation</a></h3>
                <p class="meta">By Hao Zheng, Guozhao Mo</p>
                <p class="text">Presentation generation requires deep content research, coherent visual design, and iterative refinement based on observation. However, existing presentation agents often rely on predefined workflows and fixed templates. To address this, we present DeepPresenter, an agentic frame...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22817v1" target="_blank">ðŸ”¥ Hierarchy-of-Groups Policy Optimization for Long-Horizon Agentic Tasks</a></h3>
                <p class="meta">By Shuo He, Lang Feng</p>
                <p class="text">Group-based reinforcement learning (RL), such as GRPO, has advanced the capabilities of large language models on long-horizon agentic tasks. To enable more fine-grained policy updates, recent research has increasingly shifted toward stepwise group-based policy optimization, which...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22786v1" target="_blank">ðŸ”¥ QSIM: Mitigating Overestimation in Multi-Agent Reinforcement Learning via Action Similarity Weighted Q-Learning</a></h3>
                <p class="meta">By Yuanjun Li, Bin Zhang</p>
                <p class="text">Value decomposition (VD) methods have achieved remarkable success in cooperative multi-agent reinforcement learning (MARL). However, their reliance on the max operator for temporal-difference (TD) target calculation leads to systematic Q-value overestimation. This issue is partic...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22775v1" target="_blank">ðŸ”¥ TherapyProbe: Generating Design Knowledge for Relational Safety in Mental Health Chatbots Through Adversarial Simulation</a></h3>
                <p class="meta">By Joydeep Chandra, Satyam Kumar Navneet</p>
                <p class="text">As mental health chatbots proliferate to address the global treatment gap, a critical question emerges: How do we design for relational safety the quality of interaction patterns that unfold across conversations rather than the correctness of individual responses? Current safety ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22680v1" target="_blank">ðŸ”¥ Toward Personalized LLM-Powered Agents: Foundations, Evaluation, and Future Directions</a></h3>
                <p class="meta">By Yue Xu, Qian Chen</p>
                <p class="text">Large language models have enabled agents that reason, plan, and interact with tools and environments to accomplish complex tasks. As these agents operate over extended interaction horizons, their effectiveness increasingly depends on adapting behavior to individual users and mai...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22603v1" target="_blank">ðŸ”¥ SideQuest: Model-Driven KV Cache Management for Long-Horizon Agentic Reasoning</a></h3>
                <p class="meta">By Sanjay Kariyappa, G. Edward Suh</p>
                <p class="text">Long-running agentic tasks, such as deep research, require multi-hop reasoning over information distributed across multiple webpages and documents. In such tasks, the LLM context is dominated by tokens from external retrieval, causing memory usage to grow rapidly and limiting dec...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22557v1" target="_blank">ðŸ”¥ CourtGuard: A Model-Agnostic Framework for Zero-Shot Policy Adaptation in LLM Safety</a></h3>
                <p class="meta">By Umid Suleymanov, Rufiz Bayramov</p>
                <p class="text">Current safety mechanisms for Large Language Models (LLMs) rely heavily on static, fine-tuned classifiers that suffer from adaptation rigidity, the inability to enforce new governance rules without expensive retraining. To address this, we introduce CourtGuard, a retrieval-augmen...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22539v1" target="_blank">ðŸ”¥ Agentic AI for Intent-driven Optimization in Cell-free O-RAN</a></h3>
                <p class="meta">By Mohammad Hossein Shokouhi, Vincent W. S. Wong</p>
                <p class="text">Agentic artificial intelligence (AI) is emerging as a key enabler for autonomous radio access networks (RANs), where multiple large language model (LLM)-based agents reason and collaborate to achieve operator-defined intents. The open RAN (O-RAN) architecture enables the deployme...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22452v1" target="_blank">ðŸ”¥ CWM: Contrastive World Models for Action Feasibility Learning in Embodied Agent Pipelines</a></h3>
                <p class="meta">By Chayan Banerjee</p>
                <p class="text">A reliable action feasibility scorer is a critical bottleneck in embodied agent pipelines: before any planning or reasoning occurs, the agent must identify which candidate actions are physically executable in the current state. Existing approaches use supervised fine-tuning (SFT)...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22442v1" target="_blank">ðŸ”¥ A Framework for Assessing AI Agent Decisions and Outcomes in AutoML Pipelines</a></h3>
                <p class="meta">By Gaoyuan Du, Amit Ahlawat</p>
                <p class="text">Agent-based AutoML systems rely on large language models to make complex, multi-stage decisions across data processing, model selection, and evaluation. However, existing evaluation practices remain outcome-centric, focusing primarily on final task performance. Through a review o...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22425v1" target="_blank">ðŸ”¥ ArchAgent: Agentic AI-driven Computer Architecture Discovery</a></h3>
                <p class="meta">By Raghav Gupta, Akanksha Jain</p>
                <p class="text">Agile hardware design flows are a critically needed force multiplier to meet the exploding demand for compute. Recently, agentic generative AI systems have demonstrated significant advances in algorithm design, improving code efficiency, and enabling discovery across scientific d...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22124v1" target="_blank">ðŸ”¥ SWE-ProtÃ©gÃ©: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents</a></h3>
                <p class="meta">By Patrick Tser Jern Kon, Archana Pradeep</p>
                <p class="text">Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We intr...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21670v2" target="_blank">ðŸ”¥ Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning</a></h3>
                <p class="meta">By Tomoya Kawabe, Rin Takano</p>
                <p class="text">Multi-robot task planning requires decomposing natural-language instructions into executable actions for heterogeneous robot teams. Conventional Planning Domain Definition Language (PDDL) planners provide rigorous guarantees but struggle to handle ambiguous or long-horizon missio...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23330v1" target="_blank">ðŸ”¥ Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks</a></h3>
                <p class="meta">By Kunihiro Miyazaki, Takanobu Kawahara</p>
                <p class="text">The advancement of large language models (LLMs) has accelerated the development of autonomous financial trading systems. While mainstream approaches deploy multi-agent systems mimicking analyst and manager roles, they often rely on abstract instructions that overlook the intricac...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23271v1" target="_blank">ðŸ”¥ Evaluating Stochasticity in Deep Research Agents</a></h3>
                <p class="meta">By Haotian Zhai, Elias Stengel-Eskin</p>
                <p class="text">Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and scientific discovery. Despite recent improvements in research quality (e.g., outcome accura...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23123v1" target="_blank">ðŸ”¥ Multi-Agent Large Language Model Based Emotional Detoxification Through Personalized Intensity Control for Consumer Protection</a></h3>
                <p class="meta">By Keito Inoshita</p>
                <p class="text">In the attention economy, sensational content exposes consumers to excessive emotional stimulation, hindering calm decision-making. This study proposes Multi-Agent LLM-based Emotional deToxification (MALLET), a multi-agent information sanitization system consisting of four agents...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22953v1" target="_blank">ðŸ”¥ General Agent Evaluation</a></h3>
                <p class="meta">By Elron Bandel, Asaf Yehudai</p>
                <p class="text">The promise of general-purpose agents - systems that perform tasks in unfamiliar environments without domain-specific engineering - remains largely unrealized. Existing agents are predominantly specialized, and while emerging implementations like OpenAI SDK Agent and Claude Code ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22847v1" target="_blank">ðŸ”¥ Decentralized Ranking Aggregation: Gossip Algorithms for Borda and Copeland Consensus</a></h3>
                <p class="meta">By Anna Van Elst, Kerrian Le Caillec</p>
                <p class="text">The concept of ranking aggregation plays a central role in preference analysis, and numerous algorithms for calculating median rankings, often originating in social choice theory, have been documented in the literature, offering theoretical guarantees in a centralized setting, i....</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22814v1" target="_blank">ðŸ”¥ When Should an AI Act? A Human-Centered Model of Scene, Context, and Behavior for Agentic AI Design</a></h3>
                <p class="meta">By Soyoung Jung, Daehoo Yoon</p>
                <p class="text">Agentic AI increasingly intervenes proactively by inferring users' situations from contextual data yet often fails for lack of principled judgment about when, why, and whether to act. We address this gap by proposing a conceptual model that reframes behavior as an interpretive ou...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22769v1" target="_blank">ðŸ”¥ AMA-Bench: Evaluating Long-Horizon Memory for Agentic Applications</a></h3>
                <p class="meta">By Yujie Zhao, Boqin Yuan</p>
                <p class="text">Large Language Models (LLMs) are deployed as autonomous agents in increasingly complex applications, where enabling long-horizon memory is critical for achieving strong performance. However, a significant gap exists between practical applications and current evaluation standards ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22529v1" target="_blank">ðŸ”¥ Generative Agents Navigating Digital Libraries</a></h3>
                <p class="meta">By Saber Zerhoudi, Michael Granitzer</p>
                <p class="text">In the rapidly evolving field of digital libraries, the development of large language models (LLMs) has opened up new possibilities for simulating user behavior. This innovation addresses the longstanding challenge in digital library research: the scarcity of publicly available d...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22450v1" target="_blank">ðŸ”¥ Silent Egress: When Implicit Prompt Injection Makes LLM Agents Leak Without a Trace</a></h3>
                <p class="meta">By Qianlong Lan, Anuj Kaul</p>
                <p class="text">Agentic large language model systems increasingly automate tasks by retrieving URLs and calling external tools. We show that this workflow gives rise to implicit prompt injection: adversarial instructions embedded in automatically generated URL previews, including titles, metadat...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22302v1" target="_blank">ðŸ”¥ Agent Behavioral Contracts: Formal Specification and Runtime Enforcement for Reliable Autonomous AI Agents</a></h3>
                <p class="meta">By Varun Pratap Bhardwaj</p>
                <p class="text">Traditional software relies on contracts -- APIs, type systems, assertions -- to specify and enforce correct behavior. AI agents, by contrast, operate on prompts and natural language instructions with no formal behavioral specification. This gap is the root cause of drift, govern...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">NLP & LANGUAGE DESK <span>81 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22675v1" target="_blank">ðŸ”¥ Search More, Think Less: Rethinking Long-Horizon Agentic Search for Efficiency and Generalization</a></h3>
                <p class="meta">By Qianben Chen, Tianrui Qin</p>
                <p class="text">Recent deep research agents primarily improve performance by scaling reasoning depth, but this leads to high inference cost and latency in search-intensive scenarios. Moreover, generalization across heterogeneous research settings remains challenging. In this work, we propose \em...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22576v1" target="_blank">ðŸ”¥ Search-P1: Path-Centric Reward Shaping for Stable and Efficient Agentic RAG Training</a></h3>
                <p class="meta">By Tianle Xia, Ming Xu</p>
                <p class="text">Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by incorporating external knowledge, yet traditional single-round retrieval struggles with complex multi-step reasoning. Agentic RAG addresses this by enabling LLMs to dynamically decide when and what to r...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23075v1" target="_blank">ðŸ”¥ CiteLLM: An Agentic Platform for Trustworthy Scientific Reference Discovery</a></h3>
                <p class="meta">By Mengze Hong, Di Jiang</p>
                <p class="text">Large language models (LLMs) have created new opportunities to enhance the efficiency of scholarly activities; however, challenges persist in the ethical deployment of AI assistance, including (1) the trustworthiness of AI-generated content, (2) preservation of academic integrity...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22755v1" target="_blank">ðŸ”¥ AuditBench: Evaluating Alignment Auditing Techniques on Models with Hidden Behaviors</a></h3>
                <p class="meta">By Abhay Sheshadri, Aidan Ewart</p>
                <p class="text">We introduce AuditBench, an alignment auditing benchmark. AuditBench consists of 56 language models with implanted hidden behaviors. Each model has one of 14 concerning behaviors--such as sycophantic deference, opposition to AI regulation, or secret geopolitical loyalties--which ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23351v1" target="_blank">âš¡ Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning</a></h3>
                <p class="meta">By Amita Kamath, Jack Hessel</p>
                <p class="text">The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse. We posit that this behavior stems from a reporting bias in their training data. That is, how people communicate about visual content by default omits tacit inf...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23286v1" target="_blank">âš¡ SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables</a></h3>
                <p class="meta">By Sungho Park, Jueun Kim</p>
                <p class="text">Real-world Table-Text question answering (QA) tasks require models that can reason across long text and source tables, traversing multiple hops and executing complex operations such as aggregation. Yet existing benchmarks are small, manually curated - and therefore error-prone - ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23266v1" target="_blank">âš¡ Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems</a></h3>
                <p class="meta">By Siyuan Liu, Jiahui Xu</p>
                <p class="text">Achieving human-like responsiveness is a critical yet challenging goal for cascaded spoken dialogue systems. Conventional ASR-LLM-TTS pipelines follow a strictly sequential paradigm, requiring complete transcription and full reasoning before speech synthesis can begin, which resu...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23225v1" target="_blank">âš¡ Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?</a></h3>
                <p class="meta">By Pengxiang Li, Dilxat Muhtar</p>
                <p class="text">Diffusion Language Models (DLMs) are often advertised as enabling parallel token generation, yet practical fast DLMs frequently converge to left-to-right, autoregressive (AR)-like decoding dynamics. In contrast, genuinely non-AR generation is promising because it removes AR's seq...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23079v1" target="_blank">âš¡ Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent</a></h3>
                <p class="meta">By Boyang Zhang, Yang Zhang</p>
                <p class="text">The rapid advancement of large language models (LLMs) has enabled powerful authorship inference capabilities, raising growing concerns about unintended deanonymization risks in textual data such as news articles. In this work, we introduce an LLM agent designed to evaluate and mi...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22871v1" target="_blank">âš¡ Test-Time Scaling with Diffusion Language Models via Reward-Guided Stitching</a></h3>
                <p class="meta">By Roy Miles, Aysim Toker</p>
                <p class="text">Reasoning with large language models often benefits from generating multiple chains-of-thought, but existing aggregation strategies are typically trajectory-level (e.g., selecting the best trace or voting on the final answer), discarding useful intermediate work from partial or "...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22865v1" target="_blank">âš¡ Effective QA-driven Annotation of Predicate-Argument Relations Across Languages</a></h3>
                <p class="meta">By Jonathan Davidov, Aviv Slobodkin</p>
                <p class="text">Explicit representations of predicate-argument relations form the basis of interpretable semantic analysis, supporting reasoning, generation, and evaluation. However, attaining such semantic structures requires costly annotation efforts and has remained largely confined to Englis...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22828v1" target="_blank">âš¡ TCM-DiffRAG: Personalized Syndrome Differentiation Reasoning Method for Traditional Chinese Medicine based on Knowledge Graph and Chain of Thought</a></h3>
                <p class="meta">By Jianmin Li, Ying Chang</p>
                <p class="text">Background: Retrieval augmented generation (RAG) technology can empower large language models (LLMs) to generate more accurate, professional, and timely responses without fine tuning. However, due to the complex reasoning processes and substantial individual differences involved ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22766v1" target="_blank">âš¡ Imagination Helps Visual Reasoning, But Not Yet in Latent Space</a></h3>
                <p class="meta">By You Li, Chi Chen</p>
                <p class="text">Latent visual reasoning aims to mimic human's imagination process by meditating through hidden states of Multimodal Large Language Models. While recognized as a promising paradigm for visual reasoning, the underlying mechanisms driving its effectiveness remain unclear. Motivated ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22765v1" target="_blank">âš¡ Towards Better RL Training Data Utilization via Second-Order Rollout</a></h3>
                <p class="meta">By Zhe Yang, Yudong Wang</p>
                <p class="text">Reinforcement Learning (RL) has empowered Large Language Models (LLMs) with strong reasoning capabilities, but vanilla RL mainly focuses on generation capability improvement by training with only first-order rollout (generating multiple responses for a question), and we argue tha...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22698v1" target="_blank">âš¡ Tokenization, Fusion and Decoupling: Bridging the Granularity Mismatch Between Large Language Models and Knowledge Graphs</a></h3>
                <p class="meta">By Siyue Su, Jian Yang</p>
                <p class="text">Leveraging Large Language Models (LLMs) for Knowledge Graph Completion (KGC) is promising but hindered by a fundamental granularity mismatch. LLMs operate on fragmented token sequences, whereas entities are the fundamental units in knowledge graphs (KGs) scenarios. Existing appro...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22697v1" target="_blank">âš¡ Reinforcing Real-world Service Agents: Balancing Utility and Cost in Task-oriented Dialogue</a></h3>
                <p class="meta">By Ning Gao, Wei Zhang</p>
                <p class="text">The rapid evolution of Large Language Models (LLMs) has accelerated the transition from conversational chatbots to general agents. However, effectively balancing empathetic communication with budget-aware decision-making remains an open challenge. Since existing methods fail to c...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22584v1" target="_blank">âš¡ Towards Faithful Industrial RAG: A Reinforced Co-adaptation Framework for Advertising QA</a></h3>
                <p class="meta">By Wenwei Li, Ming Xu</p>
                <p class="text">Industrial advertising question answering (QA) is a high-stakes task in which hallucinated content, particularly fabricated URLs, can lead to financial loss, compliance violations, and legal risk. Although Retrieval-Augmented Generation (RAG) is widely adopted, deploying it in pr...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22453v1" target="_blank">âš¡ Bridging Latent Reasoning and Target-Language Generation via Retrieval-Transition Heads</a></h3>
                <p class="meta">By Shaswat Patel, Vishvesh Trivedi</p>
                <p class="text">Recent work has identified a subset of attention heads in Transformer as retrieval heads, which are responsible for retrieving information from the context. In this work, we first investigate retrieval heads in multilingual contexts. In multilingual language models, we find that ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22193v1" target="_blank">âš¡ Improving Parametric Knowledge Access in Reasoning Language Models</a></h3>
                <p class="meta">By Melody Ma, John Hewitt</p>
                <p class="text">We study reasoning for accessing world knowledge stored in a language model's parameters. For example, recalling that Canberra is Australia's capital may benefit from thinking through major cities and the concept of purpose-built capitals. While reasoning language models are trai...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22175v1" target="_blank">âš¡ DySCO: Dynamic Attention-Scaling Decoding for Long-Context LMs</a></h3>
                <p class="meta">By Xi Ye, Wuwei Zhang</p>
                <p class="text">Understanding and reasoning over long contexts is a crucial capability for language models (LMs). Although recent models support increasingly long context windows, their accuracy often deteriorates as input length grows. In practice, models often struggle to keep attention aligne...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22125v1" target="_blank">âš¡ IndicIFEval: A Benchmark for Verifiable Instruction-Following Evaluation in 14 Indic Languages</a></h3>
                <p class="meta">By Thanmay Jayakumar, Mohammed Safi Ur Rahman Khan</p>
                <p class="text">Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers. We introduce IndicIFEval, a benchmark evaluating constrained generation of LLMs across 14 Indic languages using automa...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22072v1" target="_blank">âš¡ Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models</a></h3>
                <p class="meta">By Christian Nickel, Laura Schrewe</p>
                <p class="text">Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and ex...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21951v1" target="_blank">âš¡ RADAR: Reasoning as Discrimination with Aligned Representations for LLM-based Knowledge Graph Reasoning</a></h3>
                <p class="meta">By Bo Xue, Yuan Jin</p>
                <p class="text">Knowledge graph reasoning (KGR) infers missing facts, with recent advances increasingly harnessing the semantic priors and reasoning abilities of Large Language Models (LLMs). However, prevailing generative paradigms are prone to memorizing surface-level co-occurrences rather tha...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21947v2" target="_blank">âš¡ Large Language Models are Algorithmically Blind</a></h3>
                <p class="meta">By Sohan Venkatesh, Ashish Mahendran Kurapath</p>
                <p class="text">Large language models (LLMs) demonstrate remarkable breadth of knowledge, yet their ability to reason about computational processes remains poorly understood. Closing this gap matters for practitioners who rely on LLMs to guide algorithm selection and deployment. We address this ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21887v1" target="_blank">âš¡ ExpLang: Improved Exploration and Exploitation in LLM Reasoning with On-Policy Thinking Language Selection</a></h3>
                <p class="meta">By Changjiang Gao, Zixian Huang</p>
                <p class="text">Current large reasoning models (LRMs) have shown strong ability on challenging tasks after reinforcement learning (RL) based post-training. However, previous work mainly focuses on English reasoning in expectation of the strongest performance, despite the demonstrated potential a...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21854v1" target="_blank">âš¡ FewMMBench: A Benchmark for Multimodal Few-Shot Learning</a></h3>
                <p class="meta">By Mustafa Dogan, Ilker Kesen</p>
                <p class="text">As multimodal large language models (MLLMs) advance in handling interleaved image-text data, assessing their few-shot learning capabilities remains an open challenge. In this paper, we introduce FewMMBench, a comprehensive benchmark designed to evaluate MLLMs under few-shot condi...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21786v1" target="_blank">âš¡ D-COT: Disciplined Chain-of-Thought Learning for Efficient Reasoning in Small Language Models</a></h3>
                <p class="meta">By Shunsuke Ubukata</p>
                <p class="text">Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) often induces "overthinking" in Small Language Models (SLMs), leading to performance degradation and excessive token consumption. In this study, we propose Disciplined Chain-of-Thought (D-CoT), a novel framewor...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21763v1" target="_blank">âš¡ Improving Implicit Discourse Relation Recognition with Natural Language Explanations from LLMs</a></h3>
                <p class="meta">By Heng Wang, Changxing Wu</p>
                <p class="text">Implicit Discourse Relation Recognition (IDRR) remains a challenging task due to the requirement for deep semantic understanding in the absence of explicit discourse markers. A further limitation is that existing methods only predict relations without providing any supporting exp...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21728v1" target="_blank">âš¡ Explore-on-Graph: Incentivizing Autonomous Exploration of Large Language Models on Knowledge Graphs with Path-refined Reward Modeling</a></h3>
                <p class="meta">By Shiqi Yan, Yubo Chen</p>
                <p class="text">The reasoning process of Large Language Models (LLMs) is often plagued by hallucinations and missing facts in question-answering tasks. A promising solution is to ground LLMs' answers in verifiable knowledge sources, such as Knowledge Graphs (KGs). Prevailing KG-enhanced methods ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21720v1" target="_blank">âš¡ Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning</a></h3>
                <p class="meta">By Andrea Silvi, Ponrawee Prasertsom</p>
                <p class="text">Human recursive numeral systems (i.e., counting systems such as English base-10 numerals), like many other grammatical systems, are highly regular. Following prior work that relates cross-linguistic tendencies to biases in learning, we ask whether regular systems are common becau...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">VISION & MULTIMODAL DESK <span>204 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23058v1" target="_blank">ðŸ”¥ GeoWorld: Geometric World Models</a></h3>
                <p class="meta">By Zeyu Zhang, Danning Li</p>
                <p class="text">Energy-based predictive world models provide a powerful approach for multi-step visual planning by reasoning over latent energy landscapes rather than generating pixels. However, existing approaches face two major challenges: (i) their latent representations are typically learned...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22923v1" target="_blank">ðŸ”¥ WaterVideoQA: ASV-Centric Perception and Rule-Compliant Reasoning via Multi-Modal Agents</a></h3>
                <p class="meta">By Runwei Guan, Shaofeng Liang</p>
                <p class="text">While autonomous navigation has achieved remarkable success in passive perception (e.g., object detection and segmentation), it remains fundamentally constrained by a void in knowledge-driven, interactive environmental cognition. In the high-stakes domain of maritime navigation, ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22809v1" target="_blank">ðŸ”¥ PhotoAgent: Agentic Photo Editing with Exploratory Visual Aesthetic Planning</a></h3>
                <p class="meta">By Mingde Yao, Zhiyuan You</p>
                <p class="text">With the recent fast development of generative models, instruction-based image editing has shown great potential in generating high-quality images. However, the quality of editing highly depends on carefully designed instructions, placing the burden of task decomposition and sequ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23259v1" target="_blank">ðŸ”¥ Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving</a></h3>
                <p class="meta">By Jiangxin Sun, Feng Xue</p>
                <p class="text">With advances in imitation learning (IL) and large-scale driving datasets, end-to-end autonomous driving (E2E-AD) has made great progress recently. Currently, IL-based methods have become a mainstream paradigm: models rely on standard driving behaviors given by experts, and learn...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23088v1" target="_blank">ðŸ”¥ Cytoarchitecture in Words: Weakly Supervised Vision-Language Modeling for Human Brain Microscopy</a></h3>
                <p class="meta">By Matthew Sutton, Katrin Amunts</p>
                <p class="text">Foundation models increasingly offer potential to support interactive, agentic workflows that assist researchers during analysis and interpretation of image data. Such workflows often require coupling vision to language to provide a natural-language interface. However, paired ima...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22960v1" target="_blank">ðŸ”¥ UCM: Unifying Camera Control and Memory with Time-aware Positional Encoding Warping for World Models</a></h3>
                <p class="meta">By Tianxing Xu, Zixuan Wang</p>
                <p class="text">World models based on video generation demonstrate remarkable potential for simulating interactive environments but face persistent difficulties in two key areas: maintaining long-term content consistency when scenes are revisited and enabling precise camera control from user-pro...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22959v1" target="_blank">ðŸ”¥ Can Agents Distinguish Visually Hard-to-Separate Diseases in a Zero-Shot Setting? A Pilot Study</a></h3>
                <p class="meta">By Zihao Zhao, Frederik Hauke</p>
                <p class="text">The rapid progress of multimodal large language models (MLLMs) has led to increasing interest in agent-based systems. While most prior work in medical imaging concentrates on automating routine clinical workflows, we study an underexplored yet clinically significant setting: dist...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22208v2" target="_blank">ðŸ”¥ Solaris: Building a Multiplayer Video World Model in Minecraft</a></h3>
                <p class="meta">By Georgy Savva, Oscar Michel</p>
                <p class="text">Existing action-conditioned video generation models (video world models) are limited to single-agent perspectives, failing to capture the multi-agent interactions of real-world environments. We introduce Solaris, a multiplayer video world model that simulates consistent multi-vie...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21835v1" target="_blank">ðŸ”¥ UniVBench: Towards Unified Evaluation for Video Foundation Models</a></h3>
                <p class="meta">By Jianhui Wei, Xiaotian Zhang</p>
                <p class="text">Video foundation models aim to integrate video understanding, generation, editing, and instruction following within a single framework, making them a central direction for next-generation multimodal systems. However, existing evaluation benchmarks remain fragmented and limited in...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23363v1" target="_blank">âš¡ MediX-R1: Open Ended Medical Reinforcement Learning</a></h3>
                <p class="meta">By Sahal Shaji Mullappilly, Mohammed Irfan Kurpath</p>
                <p class="text">We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group B...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23359v1" target="_blank">âš¡ SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation</a></h3>
                <p class="meta">By Vaibhav Agrawal, Rishubh Parihar</p>
                <p class="text">We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation. It is essential for synthesizing partially occluded objects with depth-consistent geometry and scale. While existing methods can generate realistic scenes that follow inpu...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23306v1" target="_blank">âš¡ ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding</a></h3>
                <p class="meta">By Yiran Guan, Sifan Tu</p>
                <p class="text">Omni-modal reasoning is essential for intelligent systems to understand and draw inferences from diverse data sources. While existing omni-modal large language models (OLLM) excel at perceiving diverse modalities, they lack the complex reasoning abilities of recent large reasonin...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23290v1" target="_blank">âš¡ LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction</a></h3>
                <p class="meta">By Zhengyang Wei, Renzhi Jing</p>
                <p class="text">The accurate and automatic extraction of roads from satellite imagery is critical for applications in navigation and urban planning, significantly reducing the need for manual annotation. Many existing methods decompose this task into keypoint extraction and connectedness predict...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23228v1" target="_blank">âš¡ MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction</a></h3>
                <p class="meta">By Yizhi Li, Xiaohan Chen</p>
                <p class="text">With the explosive growth of digital entertainment, automated video summarization has become indispensable for applications such as content indexing, personalized recommendation, and efficient media archiving. Automatic synopsis generation for long-form videos, such as movies and...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23224v1" target="_blank">âš¡ UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception</a></h3>
                <p class="meta">By Mohammad Mahdavian, Gordon Tan</p>
                <p class="text">We present UniScale, a unified, scale-aware multi-view 3D reconstruction framework for robotic applications that flexibly integrates geometric priors through a modular, semantically informed design. In vision-based robotic navigation, the accurate extraction of environmental stru...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23177v1" target="_blank">âš¡ Phys-3D: Physics-Constrained Real-Time Crowd Tracking and Counting on Railway Platforms</a></h3>
                <p class="meta">By Bin Zeng, Johannes KÃ¼nzel</p>
                <p class="text">Accurate, real-time crowd counting on railway platforms is essential for safety and capacity management. We propose to use a single camera mounted in a train, scanning the platform while arriving. While hardware constraints are simple, counting remains challenging due to dense oc...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.23166v1" target="_blank">âš¡ AgentVista: Evaluating Multimodal Agents in Ultra-Challenging Realistic Visual Scenarios</a></h3>
                <p class="meta">By Zhaochen Su, Jincheng Gao</p>
                <p class="text">Real-world multimodal agents solve multi-step workflows grounded in visual evidence. For example, an agent can troubleshoot a device by linking a wiring photo to a schematic and validating the fix with online documentation, or plan a trip by interpreting a transit map and checkin...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22955v1" target="_blank">âš¡ MM-NeuroOnco: A Multimodal Benchmark and Instruction Dataset for MRI-Based Brain Tumor Diagnosis</a></h3>
                <p class="meta">By Feng Guo, Jiaxiang Liu</p>
                <p class="text">Accurate brain tumor diagnosis requires models to not only detect lesions but also generate clinically interpretable reasoning grounded in imaging manifestations, yet existing public datasets remain limited in annotation richness and diagnostic semantics. To bridge this gap, we i...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22932v1" target="_blank">âš¡ MSJoE: Jointly Evolving MLLM and Sampler for Efficient Long-Form Video Understanding</a></h3>
                <p class="meta">By Wenhui Tan, Xiaoyi Yu</p>
                <p class="text">Efficiently understanding long-form videos remains a fundamental challenge for multimodal large language models (MLLMs). In this paper, we present MLLM-Sampler Joint Evolution (MSJoE), a novel framework that jointly evolves the MLLM and a lightweight key-frame sampler for efficie...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22859v1" target="_blank">âš¡ From Blind Spots to Gains: Diagnostic-Driven Iterative Training for Large Multimodal Models</a></h3>
                <p class="meta">By Hongrui Jia, Chaoya Jiang</p>
                <p class="text">As Large Multimodal Models (LMMs) scale up and reinforcement learning (RL) methods mature, LMMs have made notable progress in complex reasoning and decision making. Yet training still relies on static data and fixed recipes, making it difficult to diagnose capability blind spots ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22779v1" target="_blank">âš¡ TrajTok: Learning Trajectory Tokens enables better Video Understanding</a></h3>
                <p class="meta">By Chenhao Zheng, Jieyu Zhang</p>
                <p class="text">Tokenization in video models, typically through patchification, generates an excessive and redundant number of tokens. This severely limits video efficiency and scalability. While recent trajectory-based tokenizers offer a promising solution by decoupling video duration from toke...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22759v1" target="_blank">âš¡ Beyond Detection: Multi-Scale Hidden-Code for Natural Image Deepfake Recovery and Factual Retrieval</a></h3>
                <p class="meta">By Yuan-Chih Chen, Chun-Shien Lu</p>
                <p class="text">Recent advances in image authenticity have primarily focused on deepfake detection and localization, leaving recovery of tampered contents for factual retrieval relatively underexplored. We propose a unified hidden-code recovery framework that enables both retrieval and restorati...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22683v1" target="_blank">âš¡ SUPERGLASSES: Benchmarking Vision Language Models as Intelligent Agents for AI Smart Glasses</a></h3>
                <p class="meta">By Zhuohang Jiang, Xu Yuan</p>
                <p class="text">The rapid advancement of AI-powered smart glasses, one of the hottest wearable devices, has unlocked new frontiers for multimodal interaction, with Visual Question Answering (VQA) over external knowledge sources emerging as a core application. Existing Vision Language Models (VLM...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22654v1" target="_blank">âš¡ Denoising as Path Planning: Training-Free Acceleration of Diffusion Models with DPCache</a></h3>
                <p class="meta">By Bowen Cui, Yuanbin Wang</p>
                <p class="text">Diffusion models have demonstrated remarkable success in image and video generation, yet their practical deployment remains hindered by the substantial computational overhead of multi-step iterative sampling. Among acceleration strategies, caching-based methods offer a training-f...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22629v1" target="_blank">âš¡ CRAG: Can 3D Generative Models Help 3D Assembly?</a></h3>
                <p class="meta">By Zeyu Jiang, Sihang Li</p>
                <p class="text">Most existing 3D assembly methods treat the problem as pure pose estimation, rearranging observed parts via rigid transformations. In contrast, human assembly naturally couples structural reasoning with holistic shape inference. Inspired by this intuition, we reformulate 3D assem...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-26</div>
                <h3><a href="http://arxiv.org/abs/2602.22624v1" target="_blank">âš¡ Instruction-based Image Editing with Planning, Reasoning, and Generation</a></h3>
                <p class="meta">By Liya Ji, Chenyang Qi</p>
                <p class="text">Editing images via instruction provides a natural way to generate interactive content, but it is a big challenge due to the higher requirement of scene understanding and generation. Prior work utilizes a chain of large language models, object segmentation models, and editing mode...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22142v1" target="_blank">âš¡ WeaveTime: Stream from Earlier Frames into Emergent Memory in VideoLLMs</a></h3>
                <p class="meta">By Yulin Zhang, Cheng Shi</p>
                <p class="text">Recent advances in Multimodal Large Language Models have greatly improved visual understanding and reasoning, yet their quadratic attention and offline training protocols make them ill-suited for streaming settings where frames arrive sequentially and future observations are inac...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22091v1" target="_blank">âš¡ Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos</a></h3>
                <p class="meta">By Matthew Strong, Wei-Jer Chang</p>
                <p class="text">Ego-centric driving videos available online provide an abundant source of visual data for autonomous driving, yet their lack of annotations makes it difficult to learn representations that capture both semantic structure and 3D geometry. Recent advances in large feedforward spati...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22033v1" target="_blank">âš¡ RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking</a></h3>
                <p class="meta">By Yanqiu Yu, Zhifan Jin</p>
                <p class="text">Referring Multi-Object Tracking has attracted increasing attention due to its human-friendly interactive characteristics, yet it exhibits limitations in low-visibility conditions, such as nighttime, smoke, and other challenging scenarios. To overcome this limitation, we propose a...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21992v1" target="_blank">âš¡ PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning</a></h3>
                <p class="meta">By Zekai Lin, Xu Zheng</p>
                <p class="text">360 panoramic images are increasingly used in virtual reality, autonomous driving, and robotics for holistic scene understanding. However, current Vision-Language Models (VLMs) struggle with 3D spatial reasoning on Equirectangular Projection (ERP) images due to geometric distorti...</p>
            </div>
            
            </div>
        </section>
        
    </body>
    </html>
    