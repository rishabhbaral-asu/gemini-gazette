
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>The Silicon Scroll | Weekly Research</title>
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@900&family=Libre+Baskerville:wght@400;700&display=swap');
            
            body { background: #f4f1ea; color: #1a1a1a; font-family: 'Libre Baskerville', serif; margin: 0; padding: 2vw; }
            .masthead { text-align: center; border-bottom: 5px double #333; margin-bottom: 40px; padding-bottom: 15px; }
            .masthead h1 { font-family: 'Playfair Display'; font-size: 5rem; margin: 0; letter-spacing: -2px; }
            
            .news-desk { margin-bottom: 50px; }
            .desk-title { 
                border-bottom: 2px solid #333; 
                font-family: 'Playfair Display'; 
                font-size: 1.8rem; 
                margin-bottom: 15px; 
                padding-bottom: 5px; 
                display: flex; 
                justify-content: space-between; 
                align-items: center; 
            }
            .desk-title span { font-size: 0.7rem; font-family: 'Libre Baskerville'; opacity: 0.5; }
            
            .horizontal-scroll { 
                display: flex; 
                overflow-x: auto; 
                gap: 25px; 
                padding-bottom: 20px;
                scrollbar-width: thin;
                scrollbar-color: #333 #f4f1ea;
            }
            
            .horizontal-scroll::-webkit-scrollbar { height: 8px; }
            .horizontal-scroll::-webkit-scrollbar-thumb { background: #333; border-radius: 4px; }

            .card { 
                flex: 0 0 350px; 
                background: #fffefc; 
                border: 1px solid #d1cec1; 
                padding: 25px; 
                box-shadow: 4px 4px 0px rgba(0,0,0,0.05);
                transition: transform 0.2s;
                display: flex;
                flex-direction: column;
            }
            .card:hover { transform: translateY(-5px); }
            
            .card-date { font-size: 10px; font-weight: bold; color: #777; margin-bottom: 10px; }
            h3 { font-family: 'Playfair Display'; font-size: 1.3rem; margin: 0 0 10px 0; line-height: 1.2; }
            h3 a { color: #1a1a1a; text-decoration: none; }
            .meta { font-size: 11px; font-weight: bold; text-transform: uppercase; color: #555; margin-bottom: 10px; display: block; }
            .text { font-size: 13px; line-height: 1.6; color: #333; flex-grow: 1; }

            .ai-accent { border-top: 6px solid #2c3e50; }
            .nlp-accent { border-top: 6px solid #27ae60; }
            .vision-accent { border-top: 6px solid #e67e22; }
        </style>
    </head>
    <body>
        <div class="masthead">
            <div style="font-size: 50px; margin-bottom: 10px;">ðŸ¦‰</div>
            <h1>The Silicon Scroll</h1>
            <p>TEMPE, AZ â€” FEBRUARY 26, 2026 â€” WEEKLY INTELLIGENCE</p>
        </div>
        
        <section class="news-desk">
            <h2 class="desk-title">AI & REINFORCEMENT DESK <span>203 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22124v1" target="_blank">ðŸ”¥ SWE-ProtÃ©gÃ©: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents</a></h3>
                <p class="meta">By Patrick Tser Jern Kon, Archana Pradeep</p>
                <p class="text">Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We intr...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21670v1" target="_blank">ðŸ”¥ Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning</a></h3>
                <p class="meta">By Tomoya Kawabe, Rin Takano</p>
                <p class="text">Multi-robot task planning requires decomposing natural-language instructions into executable actions for heterogeneous robot teams. Conventional Planning Domain Definition Language (PDDL) planners provide rigorous guarantees but struggle to handle ambiguous or long-horizon missio...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21534v1" target="_blank">ðŸ”¥ ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning</a></h3>
                <p class="meta">By Xiaoxuan Wang, Han Zhang</p>
                <p class="text">Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limit...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21515v1" target="_blank">ðŸ”¥ Training Generalizable Collaborative Agents via Strategic Risk Aversion</a></h3>
                <p class="meta">By Chengrui Qu, Yizhou Zhang</p>
                <p class="text">Many emerging agentic paradigms require agents to collaborate with one another (or people) to achieve shared goals. Unfortunately, existing approaches to learning policies for such collaborative problems produce brittle solutions that fail when paired with new partners. We attrib...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21496v1" target="_blank">ðŸ”¥ Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information</a></h3>
                <p class="meta">By Umid Suleymanov, Zaur Rajabov</p>
                <p class="text">While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21447v1" target="_blank">ðŸ”¥ Adversarial Intent is a Latent Variable: Stateful Trust Inference for Securing Multimodal Agentic RAG</a></h3>
                <p class="meta">By Inderjeet Singh, Vikas Pahuja</p>
                <p class="text">Current stateless defences for multimodal agentic RAG fail to detect adversarial strategies that distribute malicious semantics across retrieval, planning, and generation components. We formulate this security challenge as a Partially Observable Markov Decision Process (POMDP), w...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21136v1" target="_blank">ðŸ”¥ SparkMe: Adaptive Semi-Structured Interviewing for Qualitative Insight Discovery</a></h3>
                <p class="meta">By David Anugraha, Vishakh Padmakumar</p>
                <p class="text">Qualitative insights from user experiences are critical for informing product and policy decisions, but collecting such data at scale is constrained by the time and availability of experts to conduct semi-structured interviews. Recent work has explored using large language models...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21119v1" target="_blank">ðŸ”¥ Cooperative-Competitive Team Play of Real-World Craft Robots</a></h3>
                <p class="meta">By Rui Zhao, Xihui Li</p>
                <p class="text">Multi-agent deep Reinforcement Learning (RL) has made significant progress in developing intelligent game-playing agents in recent years. However, the efficient training of collective robots using multi-agent RL and the transfer of learned policies to real-world applications rema...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20946v2" target="_blank">ðŸ”¥ Some Simple Economics of AGI</a></h3>
                <p class="meta">By Christian Catalini, Xiang Hui</p>
                <p class="text">For millennia, human cognition was the primary engine of progress on Earth. As AI decouples cognition from biology, the marginal cost of measurable execution falls to zero, absorbing any labor capturable by metrics--including creative, analytical, and innovative work. The binding...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20934v1" target="_blank">ðŸ”¥ Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence</a></h3>
                <p class="meta">By ChengYou Li, XiaoDong Liu</p>
                <p class="text">The paradigm of Large Language Models is undergoing a fundamental transition from static inference engines to dynamic autonomous cognitive systems.While current research primarily focuses on scaling context windows or optimizing prompt engineering the theoretical bridge between m...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20924v1" target="_blank">ðŸ”¥ Airavat: An Agentic Framework for Internet Measurement</a></h3>
                <p class="meta">By Alagappan Ramanathan, Eunju Kang</p>
                <p class="text">Internet measurement faces twin challenges: complex analyses require expert-level orchestration of tools, yet even syntactically correct implementations can have methodological flaws and can be difficult to verify. Democratizing measurement capabilities thus demands automating bo...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20867v1" target="_blank">ðŸ”¥ SoK: Agentic Skills -- Beyond Tool Use in LLM Agents</a></h3>
                <p class="meta">By Yanna Jiang, Delong Li</p>
                <p class="text">Agentic systems increasingly rely on reusable procedural capabilities, \textit{a.k.a., agentic skills}, to execute long-horizon workflows reliably. These capabilities are callable modules that package procedural knowledge with explicit applicability conditions, execution policies...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20739v1" target="_blank">ðŸ”¥ PyVision-RL: Forging Open Agentic Vision Models via RL</a></h3>
                <p class="meta">By Shitian Zhao, Shaoheng Lin</p>
                <p class="text">Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20424v1" target="_blank">ðŸ”¥ Implicit Intelligence -- Evaluating Agents on What Users Don't Say</a></h3>
                <p class="meta">By Ved Sirdeshmukh, Marc Wetter</p>
                <p class="text">Real-world requests to AI agents are fundamentally underspecified. Natural human communication relies on shared context and unstated constraints that speakers expect listeners to infer. Current agentic benchmarks test explicit instruction-following but fail to evaluate whether ag...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20292v2" target="_blank">ðŸ”¥ Quantifying the Expectation-Realisation Gap for Agentic AI Systems</a></h3>
                <p class="meta">By Sebastian Lobentanzer</p>
                <p class="text">Agentic AI systems are deployed with expectations of substantial productivity gains, yet rigorous empirical evidence reveals systematic discrepancies between pre-deployment expectations and post-deployment outcomes. We review controlled trials and independent validations across s...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20078v1" target="_blank">ðŸ”¥ Descent-Guided Policy Gradient for Scalable Cooperative Multi-Agent Learning</a></h3>
                <p class="meta">By Shan Yang, Yang Liu</p>
                <p class="text">Scaling cooperative multi-agent reinforcement learning (MARL) is fundamentally limited by cross-agent noise: when agents share a common reward, the actions of all $N$ agents jointly determine each agent's learning signal, so cross-agent noise grows with $N$. In the policy gradien...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22010v1" target="_blank">ðŸ”¥ World Guidance: World Modeling in Condition Space for Action Generation</a></h3>
                <p class="meta">By Yue Su, Sijin Chen</p>
                <p class="text">Leveraging future observation modeling to facilitate action generation presents a promising avenue for enhancing the capabilities of Vision-Language-Action (VLA) models. However, existing approaches struggle to strike a balance between maintaining efficient, predictable future re...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21401v1" target="_blank">ðŸ”¥ The Headless Firm: How AI Reshapes Enterprise Boundaries</a></h3>
                <p class="meta">By Tassilo Klein, Sebastian Wieczorek</p>
                <p class="text">The boundary of the firm is determined by coordination cost. We argue that agentic AI induces a structural change in how coordination costs scale: in prior modular systems, integration cost grew with interaction topology (O(n^2) in the number of components); in protocol-mediated ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21351v1" target="_blank">ðŸ”¥ A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives</a></h3>
                <p class="meta">By Dmitrii Pantiukhin, Ivan Kuznetsov</p>
                <p class="text">The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21319v1" target="_blank">ðŸ”¥ Uncertainty-Aware Diffusion Model for Multimodal Highway Trajectory Prediction via DDIM Sampling</a></h3>
                <p class="meta">By Marion Neumeier, Niklas RoÃŸberg</p>
                <p class="text">Accurate and uncertainty-aware trajectory prediction remains a core challenge for autonomous driving, driven by complex multi-agent interactions, diverse scene contexts and the inherently stochastic nature of future motion. Diffusion-based generative models have recently shown st...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21127v1" target="_blank">ðŸ”¥ "Are You Sure?": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems</a></h3>
                <p class="meta">By Xinfeng Li, Shenyu Dai</p>
                <p class="text">Large language model (LLM) agents are rapidly becoming trusted copilots in high-stakes domains like software development and healthcare. However, this deepening trust introduces a novel attack surface: Agent-Mediated Deception (AMD), where compromised agents are weaponized agains...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20979v1" target="_blank">ðŸ”¥ Toward an Agentic Infused Software Ecosystem</a></h3>
                <p class="meta">By Mark Marron</p>
                <p class="text">Fully leveraging the capabilities of AI agents in software development requires a rethinking of the software ecosystem itself. To this end, this paper outlines the creation of an Agentic Infused Software Ecosystem (AISE), that rests on three pillars. The first, of course, is the ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20720v1" target="_blank">ðŸ”¥ AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs</a></h3>
                <p class="meta">By Che Wang, Jiaming Zhang</p>
                <p class="text">The integration of external data services (e.g., Model Context Protocol, MCP) has made large language model-based agents increasingly powerful for complex task execution. However, this advancement introduces critical security vulnerabilities, particularly indirect prompt injectio...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20708v1" target="_blank">ðŸ”¥ ICON: Indirect Prompt Injection Defense for Agents based on Inference-Time Correction</a></h3>
                <p class="meta">By Che Wang, Fuyao Zhang</p>
                <p class="text">Large Language Model (LLM) agents are susceptible to Indirect Prompt Injection (IPI) attacks, where malicious instructions in retrieved content hijack the agent's execution. Existing defenses typically rely on strict filtering or refusal mechanisms, which suffer from a critical l...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20541v2" target="_blank">ðŸ”¥ Maximin Share Guarantees via Limited Cost-Sensitive Sharing</a></h3>
                <p class="meta">By Hana Salavcova, Martin ÄŒernÃ½</p>
                <p class="text">We study the problem of fairly allocating indivisible goods when limited sharing is allowed, that is, each good may be allocated to up to $k$ agents, while incurring a cost for sharing. While classic maximin share (MMS) allocations may not exist in many instances, we demonstrate ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20144v1" target="_blank">ðŸ”¥ Agentic AI for Scalable and Robust Optical Systems Control</a></h3>
                <p class="meta">By Zehao Wang, Mingzhe Han</p>
                <p class="text">We present AgentOptics, an agentic AI framework for high-fidelity, autonomous optical system control built on the Model Context Protocol (MCP). AgentOptics interprets natural language tasks and executes protocol-compliant actions on heterogeneous optical devices through a structu...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22190v1" target="_blank">âš¡ GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL</a></h3>
                <p class="meta">By Rui Yang, Qianhui Wu</p>
                <p class="text">Open-source native GUI agents still lag behind closed-source systems on long-horizon navigation tasks. This gap stems from two limitations: a shortage of high-quality, action-aligned reasoning data, and the direct adoption of generic post-training pipelines that overlook the uniq...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22146v1" target="_blank">âš¡ Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual</a></h3>
                <p class="meta">By Yining Li, Peizhong Ju</p>
                <p class="text">Reinforcement Learning from Human Feedback (RLHF) plays a significant role in aligning Large Language Models (LLMs) with human preferences. While RLHF with expected reward constraints can be formulated as a primal-dual optimization problem, standard primal-dual methods only guara...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22094v1" target="_blank">âš¡ Petri Net Relaxation for Infeasibility Explanation and Sequential Task Planning</a></h3>
                <p class="meta">By Nguyen Cong Nhat Le, John G. Rogers</p>
                <p class="text">Plans often change due to changes in the situation or our understanding of the situation. Sometimes, a feasible plan may not even exist, and identifying such infeasibilities is useful to determine when requirements need adjustment. Common planning approaches focus on efficient on...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22067v1" target="_blank">âš¡ Semantic Partial Grounding via LLMs</a></h3>
                <p class="meta">By Giuseppe Canonaco, Alberto Pozanco</p>
                <p class="text">Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding on...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">NLP & LANGUAGE DESK <span>77 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22193v1" target="_blank">âš¡ Improving Parametric Knowledge Access in Reasoning Language Models</a></h3>
                <p class="meta">By Melody Ma, John Hewitt</p>
                <p class="text">We study reasoning for accessing world knowledge stored in a language model's parameters. For example, recalling that Canberra is Australia's capital may benefit from thinking through major cities and the concept of purpose-built capitals. While reasoning language models are trai...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22175v1" target="_blank">âš¡ DySCO: Dynamic Attention-Scaling Decoding for Long-Context LMs</a></h3>
                <p class="meta">By Xi Ye, Wuwei Zhang</p>
                <p class="text">Understanding and reasoning over long contexts is a crucial capability for language models (LMs). Although recent models support increasingly long context windows, their accuracy often deteriorates as input length grows. In practice, models often struggle to keep attention aligne...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22125v1" target="_blank">âš¡ IndicIFEval: A Benchmark for Verifiable Instruction-Following Evaluation in 14 Indic Languages</a></h3>
                <p class="meta">By Thanmay Jayakumar, Mohammed Safi Ur Rahman Khan</p>
                <p class="text">Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers. We introduce IndicIFEval, a benchmark evaluating constrained generation of LLMs across 14 Indic languages using automa...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22072v1" target="_blank">âš¡ Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models</a></h3>
                <p class="meta">By Christian Nickel, Laura Schrewe</p>
                <p class="text">Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and ex...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21951v1" target="_blank">âš¡ RADAR: Reasoning as Discrimination with Aligned Representations for LLM-based Knowledge Graph Reasoning</a></h3>
                <p class="meta">By Bo Xue, Yuan Jin</p>
                <p class="text">Knowledge graph reasoning (KGR) infers missing facts, with recent advances increasingly harnessing the semantic priors and reasoning abilities of Large Language Models (LLMs). However, prevailing generative paradigms are prone to memorizing surface-level co-occurrences rather tha...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21947v1" target="_blank">âš¡ Large Language Models are Algorithmically Blind</a></h3>
                <p class="meta">By Sohan Venkatesh, Ashish Mahendran Kurapath</p>
                <p class="text">Large language models (LLMs) demonstrate remarkable breadth of knowledge, yet their ability to reason about computational processes remains poorly understood. Closing this gap matters for practitioners who rely on LLMs to guide algorithm selection and deployment. We address this ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21887v1" target="_blank">âš¡ ExpLang: Improved Exploration and Exploitation in LLM Reasoning with On-Policy Thinking Language Selection</a></h3>
                <p class="meta">By Changjiang Gao, Zixian Huang</p>
                <p class="text">Current large reasoning models (LRMs) have shown strong ability on challenging tasks after reinforcement learning (RL) based post-training. However, previous work mainly focuses on English reasoning in expectation of the strongest performance, despite the demonstrated potential a...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21854v1" target="_blank">âš¡ FewMMBench: A Benchmark for Multimodal Few-Shot Learning</a></h3>
                <p class="meta">By Mustafa Dogan, Ilker Kesen</p>
                <p class="text">As multimodal large language models (MLLMs) advance in handling interleaved image-text data, assessing their few-shot learning capabilities remains an open challenge. In this paper, we introduce FewMMBench, a comprehensive benchmark designed to evaluate MLLMs under few-shot condi...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21786v1" target="_blank">âš¡ D-COT: Disciplined Chain-of-Thought Learning for Efficient Reasoning in Small Language Models</a></h3>
                <p class="meta">By Shunsuke Ubukata</p>
                <p class="text">Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) often induces "overthinking" in Small Language Models (SLMs), leading to performance degradation and excessive token consumption. In this study, we propose Disciplined Chain-of-Thought (D-CoT), a novel framewor...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21763v1" target="_blank">âš¡ Improving Implicit Discourse Relation Recognition with Natural Language Explanations from LLMs</a></h3>
                <p class="meta">By Heng Wang, Changxing Wu</p>
                <p class="text">Implicit Discourse Relation Recognition (IDRR) remains a challenging task due to the requirement for deep semantic understanding in the absence of explicit discourse markers. A further limitation is that existing methods only predict relations without providing any supporting exp...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21728v1" target="_blank">âš¡ Explore-on-Graph: Incentivizing Autonomous Exploration of Large Language Models on Knowledge Graphs with Path-refined Reward Modeling</a></h3>
                <p class="meta">By Shiqi Yan, Yubo Chen</p>
                <p class="text">The reasoning process of Large Language Models (LLMs) is often plagued by hallucinations and missing facts in question-answering tasks. A promising solution is to ground LLMs' answers in verifiable knowledge sources, such as Knowledge Graphs (KGs). Prevailing KG-enhanced methods ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21720v1" target="_blank">âš¡ Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning</a></h3>
                <p class="meta">By Andrea Silvi, Ponrawee Prasertsom</p>
                <p class="text">Human recursive numeral systems (i.e., counting systems such as English base-10 numerals), like many other grammatical systems, are highly regular. Following prior work that relates cross-linguistic tendencies to biases in learning, we ask whether regular systems are common becau...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21628v1" target="_blank">âš¡ RuCL: Stratified Rubric-Based Curriculum Learning for Multimodal Large Language Model Reasoning</a></h3>
                <p class="meta">By Yukun Chen, Jiaming Li</p>
                <p class="text">Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a prevailing paradigm for enhancing reasoning in Multimodal Large Language Models (MLLMs). However, relying solely on outcome supervision risks reward hacking, where models learn spurious reasoning patterns to s...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21619v1" target="_blank">âš¡ When More Is Less: A Systematic Analysis of Spatial and Commonsense Information for Visual Spatial Reasoning</a></h3>
                <p class="meta">By Muku Akasaka, Soyeon Caren Han</p>
                <p class="text">Visual spatial reasoning (VSR) remains challenging for modern vision-language models (VLMs), despite advances in multimodal architectures. A common strategy is to inject additional information at inference time, such as explicit spatial cues, external commonsense knowledge, or ch...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21346v1" target="_blank">âš¡ Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment</a></h3>
                <p class="meta">By Mengxuan Hu, Vivek V. Datla</p>
                <p class="text">Recent advances in alignment techniques such as Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and Direct Preference Optimization (DPO) have improved the safety of large language models (LLMs). However, these LLMs remain vulnerable to jailbreak a...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21103v1" target="_blank">âš¡ Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning</a></h3>
                <p class="meta">By Sanket Badhe, Deep Shah</p>
                <p class="text">Advanced reasoning typically requires Chain-of-Thought prompting, which is accurate but incurs prohibitive latency and substantial test-time inference costs. The standard alternative, fine-tuning smaller models, often sacrifices interpretability while introducing significant reso...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20973v1" target="_blank">âš¡ Linear Reasoning vs. Proof by Cases: Obstacles for Large Language Models in FOL Problem Solving</a></h3>
                <p class="meta">By Yuliang Ji, Fuchen Shen</p>
                <p class="text">To comprehensively evaluate the mathematical reasoning capabilities of Large Language Models (LLMs), researchers have introduced abundant mathematical reasoning datasets. However, most existing datasets primarily focus on linear reasoning, neglecting other parts such as proof by ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20966v1" target="_blank">âš¡ Blackbird Language Matrices: A Framework to Investigate the Linguistic Competence of Language Models</a></h3>
                <p class="meta">By Paola Merlo, Chunyang Jiang</p>
                <p class="text">This article describes a novel language task, the Blackbird Language Matrices (BLM) task, inspired by intelligence tests, and illustrates the BLM datasets, their construction and benchmarking, and targeted experiments on chunking and systematicity. BLMs are multiple-choice proble...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20945v2" target="_blank">âš¡ The Art of Efficient Reasoning: Data, Reward, and Optimization</a></h3>
                <p class="meta">By Taiqiang Wu, Zenan Xu</p>
                <p class="text">Large Language Models (LLMs) consistently benefit from scaled Chain-of-Thought (CoT) reasoning, but also suffer from heavy computational overhead. To address this issue, efficient reasoning aims to incentivize short yet accurate thinking trajectories, typically through reward sha...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20759v1" target="_blank">âš¡ Overton Pluralistic Reinforcement Learning for Large Language Models</a></h3>
                <p class="meta">By Yu Fu, Seongho Son</p>
                <p class="text">Existing alignment paradigms remain limited in capturing the pluralistic nature of human values. Overton Pluralism addresses this gap by generating responses with diverse perspectives from a single query. This paper introduces OP-GRPO (Overton Pluralistic Group Relative Policy Op...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20751v1" target="_blank">âš¡ SibylSense: Adaptive Rubric Learning via Memory Tuning and Adversarial Probing</a></h3>
                <p class="meta">By Yifei Xu, Guilherme Potje</p>
                <p class="text">Designing aligned and robust rewards for open-ended generation remains a key barrier to RL post-training. Rubrics provide structured, interpretable supervision, but scaling rubric construction is difficult: expert rubrics are costly, prompted rubrics are often superficial or inco...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20727v1" target="_blank">âš¡ ID-LoRA: Efficient Low-Rank Adaptation Inspired by Matrix Interpolative Decomposition</a></h3>
                <p class="meta">By Xindian Ma, Rundong Kong</p>
                <p class="text">LoRA has become a universal Parameter-Efficient Fine-Tuning (PEFT) technique that equips Large Language Models (LLMs) to adapt quickly to new tasks. However, when these models are scaled up, even the latest LoRA variants still introduce considerable overhead in trainable paramete...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21265v1" target="_blank">âš¡ ToolMATH: A Math Tool Benchmark for Realistic Long-Horizon Multi-Tool Reasoning</a></h3>
                <p class="meta">By Hyeonje Choi, Jeongsoo Lee</p>
                <p class="text">We introduce \ToolMATH, a math-grounded benchmark that evaluates tool-augmented language models in realistic multi-tool environments where the output depends on calling schema-specified tools and sustaining multi-step execution. It turns math problems into a controlled, correctne...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20670v1" target="_blank">âš¡ CAMEL: Confidence-Gated Reflection for Reward Modeling</a></h3>
                <p class="meta">By Zirui Zhu, Hailun Xu</p>
                <p class="text">Reward models play a fundamental role in aligning large language models with human preferences. Existing methods predominantly follow two paradigms: scalar discriminative preference models, which are efficient but lack interpretability, and generative judging models, which offer ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20528v1" target="_blank">âš¡ Stop-Think-AutoRegress: Language Modeling with Latent Diffusion Planning</a></h3>
                <p class="meta">By Justin Lovelace, Christian Belardi</p>
                <p class="text">The Stop-Think-AutoRegress Language Diffusion Model (STAR-LDM) integrates latent diffusion planning with autoregressive generation. Unlike conventional autoregressive language models limited to token-by-token decisions, STAR-LDM incorporates a "thinking" phase that pauses generat...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20332v1" target="_blank">âš¡ No One Size Fits All: QueryBandits for Hallucination Mitigation</a></h3>
                <p class="meta">By Nicole Cho, William Watson</p>
                <p class="text">Advanced reasoning capabilities in Large Language Models (LLMs) have led to more frequent hallucinations; yet most mitigation work focuses on open-source models for post-hoc detection and parameter editing. The dearth of studies focusing on hallucinations in closed-source models ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-23</div>
                <h3><a href="http://arxiv.org/abs/2602.20130v1" target="_blank">âš¡ To Reason or Not to: Selective Chain-of-Thought in Medical Question Answering</a></h3>
                <p class="meta">By Zaifu Zhan, Min Zeng</p>
                <p class="text">Objective: To improve the efficiency of medical question answering (MedQA) with large language models (LLMs) by avoiding unnecessary reasoning while maintaining accuracy.   Methods: We propose Selective Chain-of-Thought (Selective CoT), an inference-time strategy that first predi...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22207v1" target="_blank">Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets</a></h3>
                <p class="meta">By Hanna Yukhymenko, Anton Alexandrov</p>
                <p class="text">The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this wor...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22200v1" target="_blank">SumTablets: A Transliteration Dataset of Sumerian Tablets</a></h3>
                <p class="meta">By Cole Simmons, Richard Diehl Martinez</p>
                <p class="text">Sumerian transliteration is a conventional system for representing a scholar's interpretation of a tablet in the Latin script. Thanks to visionary digital Assyriology projects such as ETCSL, CDLI, and Oracc, a large number of Sumerian transliterations have been published online, ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22182v1" target="_blank">LiCQA : A Lightweight Complex Question Answering System</a></h3>
                <p class="meta">By Sourav Saha, Dwaipayan Roy</p>
                <p class="text">Over the last twenty years, significant progress has been made in designing and implementing Question Answering (QA) systems. However, addressing complex questions, the answers to which are spread across multiple documents, remains a challenging problem. Recent QA systems that ar...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">VISION & MULTIMODAL DESK <span>220 PAPERS THIS WEEK</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21517v1" target="_blank">ðŸ”¥ Which Tool Response Should I Trust? Tool-Expertise-Aware Chest X-ray Agent with Multimodal Agentic Learning</a></h3>
                <p class="meta">By Zheang Huai, Honglong Yang</p>
                <p class="text">AI agents with tool-use capabilities show promise for integrating the domain expertise of various tools. In the medical field, however, tools are usually AI models that are inherently error-prone and can produce contradictory responses. Existing research on medical agents lacks s...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21137v1" target="_blank">ðŸ”¥ UDVideoQA: A Traffic Video Question Answering Dataset for Multi-Object Spatio-Temporal Reasoning in Urban Dynamics</a></h3>
                <p class="meta">By Joseph Raj Vishal, Nagasiri Poluri</p>
                <p class="text">Understanding the complex, multi-agent dynamics of urban traffic remains a fundamental challenge for video language models. This paper introduces Urban Dynamics VideoQA, a benchmark dataset that captures the unscripted real-world behavior of dynamic urban scenes. UDVideoQA is cur...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21053v1" target="_blank">ðŸ”¥ OCR-Agent: Agentic OCR with Capability and Memory Reflection</a></h3>
                <p class="meta">By Shimin Wen, Zeyu Zhang</p>
                <p class="text">Large Vision-Language Models (VLMs) have demonstrated significant potential on complex visual understanding tasks through iterative optimization methods.However, these models generally lack effective self-correction mechanisms, making it difficult for them to independently rectif...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20685v2" target="_blank">ðŸ”¥ RAYNOVA: Scale-Temporal Autoregressive World Modeling in Ray Space</a></h3>
                <p class="meta">By Yichen Xie, Chensheng Peng</p>
                <p class="text">World foundation models aim to simulate the evolution of the real world with physically plausible behavior. Unlike prior methods that handle spatial and temporal correlations separately, we propose RAYNOVA, a geometry-agonistic multiview world model for driving scenarios that emp...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22208v1" target="_blank">ðŸ”¥ Solaris: Building a Multiplayer Video World Model in Minecraft</a></h3>
                <p class="meta">By Georgy Savva, Oscar Michel</p>
                <p class="text">Existing action-conditioned video generation models (video world models) are limited to single-agent perspectives, failing to capture the multi-agent interactions of real-world environments. We introduce Solaris, a multiplayer video world model that simulates consistent multi-vie...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21835v1" target="_blank">ðŸ”¥ UniVBench: Towards Unified Evaluation for Video Foundation Models</a></h3>
                <p class="meta">By Jianhui Wei, Xiaotian Zhang</p>
                <p class="text">Video foundation models aim to integrate video understanding, generation, editing, and instruction following within a single framework, making them a central direction for next-generation multimodal systems. However, existing evaluation benchmarks remain fragmented and limited in...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20951v1" target="_blank">ðŸ”¥ See and Fix the Flaws: Enabling VLMs and Diffusion Models to Comprehend Visual Artifacts via Agentic Data Synthesis</a></h3>
                <p class="meta">By Jaehyun Park, Minyoung Ahn</p>
                <p class="text">Despite recent advances in diffusion models, AI generated images still often contain visual artifacts that compromise realism. Although more thorough pre-training and bigger models might reduce artifacts, there is no assurance that they can be completely eliminated, which makes a...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20664v1" target="_blank">ðŸ”¥ AnimeAgent: Is the Multi-Agent via Image-to-Video models a Good Disney Storytelling Artist?</a></h3>
                <p class="meta">By Hailong Yan, Shice Liu</p>
                <p class="text">Custom Storyboard Generation (CSG) aims to produce high-quality, multi-character consistent storytelling. Current approaches based on static diffusion models, whether used in a one-shot manner or within multi-agent frameworks, face three key limitations: (1) Static models lack dy...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20550v1" target="_blank">ðŸ”¥ The Finite Primitive Basis Theorem for Computational Imaging: Formal Foundations of the OperatorGraph Representation</a></h3>
                <p class="meta">By Chengshuai Yang</p>
                <p class="text">Computational imaging forward models, from coded aperture spectral cameras to MRI scanners, are traditionally implemented as monolithic, modality-specific codes. We prove that every forward model in a broad, precisely defined operator class Cimg (encompassing clinical, scientific...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.20543v1" target="_blank">ðŸ”¥ Beyond Human Performance: A Vision-Language Multi-Agent Approach for Quality Control in Pharmaceutical Manufacturing</a></h3>
                <p class="meta">By Subhra Jyoti Mandal, Lara Rachidi</p>
                <p class="text">Colony-forming unit (CFU) detection is critical in pharmaceutical manufacturing, serving as a key component of Environmental Monitoring programs and ensuring compliance with stringent quality standards. Manual counting is labor-intensive and error-prone, while deep learning (DL) ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22142v1" target="_blank">âš¡ WeaveTime: Stream from Earlier Frames into Emergent Memory in VideoLLMs</a></h3>
                <p class="meta">By Yulin Zhang, Cheng Shi</p>
                <p class="text">Recent advances in Multimodal Large Language Models have greatly improved visual understanding and reasoning, yet their quadratic attention and offline training protocols make them ill-suited for streaming settings where frames arrive sequentially and future observations are inac...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22091v1" target="_blank">âš¡ Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos</a></h3>
                <p class="meta">By Matthew Strong, Wei-Jer Chang</p>
                <p class="text">Ego-centric driving videos available online provide an abundant source of visual data for autonomous driving, yet their lack of annotations makes it difficult to learn representations that capture both semantic structure and 3D geometry. Recent advances in large feedforward spati...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.22033v1" target="_blank">âš¡ RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking</a></h3>
                <p class="meta">By Yanqiu Yu, Zhifan Jin</p>
                <p class="text">Referring Multi-Object Tracking has attracted increasing attention due to its human-friendly interactive characteristics, yet it exhibits limitations in low-visibility conditions, such as nighttime, smoke, and other challenging scenarios. To overcome this limitation, we propose a...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21992v1" target="_blank">âš¡ PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning</a></h3>
                <p class="meta">By Zekai Lin, Xu Zheng</p>
                <p class="text">360 panoramic images are increasingly used in virtual reality, autonomous driving, and robotics for holistic scene understanding. However, current Vision-Language Models (VLMs) struggle with 3D spatial reasoning on Equirectangular Projection (ERP) images due to geometric distorti...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21987v1" target="_blank">âš¡ PatchDenoiser: Parameter-efficient multi-scale patch learning and fusion denoiser for medical images</a></h3>
                <p class="meta">By Jitindra Fartiyal, Pedro Freire</p>
                <p class="text">Medical images are essential for diagnosis, treatment planning, and research, but their quality is often degraded by noise from low-dose acquisition, patient motion, or scanner limitations, affecting both clinical interpretation and downstream analysis. Traditional filtering appr...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21952v1" target="_blank">âš¡ MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving</a></h3>
                <p class="meta">By Lingjun Zhang, Yujian Yuan</p>
                <p class="text">Vision-Language Models (VLM) exhibit strong reasoning capabilities, showing promise for end-to-end autonomous driving systems. Chain-of-Thought (CoT), as VLM's widely used reasoning strategy, is facing critical challenges. Existing textual CoT has a large gap between text semanti...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21855v1" target="_blank">âš¡ Understanding Annotation Error Propagation and Learning an Adaptive Policy for Expert Intervention in Barrett's Video Segmentation</a></h3>
                <p class="meta">By Lokesha Rasanjalee, Jin Lin Tan</p>
                <p class="text">Accurate annotation of endoscopic videos is essential yet time-consuming, particularly for challenging datasets such as dysplasia in Barrett's esophagus, where the affected regions are irregular and lack clear boundaries. Semi-automatic tools like Segment Anything Model 2 (SAM2) ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21820v1" target="_blank">âš¡ Joint Shadow Generation and Relighting via Light-Geometry Interaction Maps</a></h3>
                <p class="meta">By Shan Wang, Peixia Li</p>
                <p class="text">We propose Light-Geometry Interaction (LGI) maps, a novel representation that encodes light-aware occlusion from monocular depth. Unlike ray tracing, which requires full 3D reconstruction, LGI captures essential light-shadow interactions reliably and accurately, computed from off...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21779v1" target="_blank">âš¡ Beyond Static Artifacts: A Forensic Benchmark for Video Deepfake Reasoning in Vision Language Models</a></h3>
                <p class="meta">By Zheyuan Gu, Qingsong Zhao</p>
                <p class="text">Current Vision-Language Models (VLMs) for deepfake detection excel at identifying spatial artifacts but overlook a critical dimension: temporal inconsistencies in video forgeries. Adapting VLMs to reason about these dynamic cues remains a distinct challenge. To bridge this gap, w...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21778v1" target="_blank">âš¡ From Statics to Dynamics: Physics-Aware Image Editing with Latent Transition Priors</a></h3>
                <p class="meta">By Liangbing Zhao, Le Zhuo</p>
                <p class="text">Instruction-based image editing has achieved remarkable success in semantic alignment, yet state-of-the-art models frequently fail to render physically plausible results when editing involves complex causal dynamics, such as refraction or material deformation. We attribute this l...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21743v1" target="_blank">âš¡ Enhancing Multi-Modal LLMs Reasoning via Difficulty-Aware Group Normalization</a></h3>
                <p class="meta">By Jinghan Li, Junfeng Fang</p>
                <p class="text">Reinforcement Learning with Verifiable Rewards (RLVR) and Group Relative Policy Optimization (GRPO) have significantly advanced the reasoning capabilities of large language models. Extending these methods to multimodal settings, however, faces a critical challenge: the instabilit...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21706v1" target="_blank">âš¡ SurGo-R1: Benchmarking and Modeling Contextual Reasoning for Operative Zone in Surgical Video</a></h3>
                <p class="meta">By Guanyi Qin, Xiaozhen Wang</p>
                <p class="text">Minimally invasive surgery has dramatically improved patient operative outcomes, yet identifying safe operative zones remains challenging in critical phases, requiring surgeons to integrate visual cues, procedural phase, and anatomical context under high cognitive load. Existing ...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21698v1" target="_blank">âš¡ E-comIQ-ZH: A Human-Aligned Dataset and Benchmark for Fine-Grained Evaluation of E-commerce Posters with Chain-of-Thought</a></h3>
                <p class="meta">By Meiqi Sun, Mingyu Li</p>
                <p class="text">Generative AI is widely used to create commercial posters. However, rapid advances in generation have outpaced automated quality assessment. Existing models emphasize generic esthetics or low level distortions and lack the functional criteria required for e-commerce design. It is...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21655v1" target="_blank">âš¡ CCCaption: Dual-Reward Reinforcement Learning for Complete and Correct Image Captioning</a></h3>
                <p class="meta">By Zhijiang Tang, Linhua Wang</p>
                <p class="text">Image captioning remains a fundamental task for vision language understanding, yet ground-truth supervision still relies predominantly on human-annotated references. Because human annotations reflect subjective preferences and expertise, ground-truth captions are often incomplete...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21552v1" target="_blank">âš¡ Generalizing Visual Geometry Priors to Sparse Gaussian Occupancy Prediction</a></h3>
                <p class="meta">By Changqing Zhou, Yueru Luo</p>
                <p class="text">Accurate 3D scene understanding is essential for embodied intelligence, with occupancy prediction emerging as a key task for reasoning about both objects and free space. Existing approaches largely rely on depth priors (e.g., DepthAnything) but make only limited use of 3D cues, r...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21539v1" target="_blank">âš¡ VasGuideNet: Vascular Topology-Guided Couinaud Liver Segmentation with Structural Contrastive Loss</a></h3>
                <p class="meta">By Chaojie Shen, Jingjun Gu</p>
                <p class="text">Accurate Couinaud liver segmentation is critical for preoperative surgical planning and tumor localization.However, existing methods primarily rely on image intensity and spatial location cues, without explicitly modeling vascular topology. As a result, they often produce indisti...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-25</div>
                <h3><a href="http://arxiv.org/abs/2602.21497v1" target="_blank">âš¡ See It, Say It, Sorted: An Iterative Training-Free Framework for Visually-Grounded Multimodal Reasoning in LVLMs</a></h3>
                <p class="meta">By Yongchang Zhang, Xianzheng Ma</p>
                <p class="text">Recent large vision-language models (LVLMs) have demonstrated impressive reasoning ability by generating long chain-of-thought (CoT) responses. However, CoT reasoning in multimodal contexts is highly vulnerable to visual hallucination propagation: once an intermediate reasoning s...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21435v1" target="_blank">âš¡ Synergizing Understanding and Generation with Interleaved Analyzing-Drafting Thinking</a></h3>
                <p class="meta">By Shengqiong Wu, Bobo Li</p>
                <p class="text">Unified Vision-Language Models (UVLMs) aim to advance multimodal learning by supporting both understanding and generation within a single framework. However, existing approaches largely focus on architectural unification while overlooking the need for explicit interaction between...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21186v1" target="_blank">âš¡ Spa3R: Predictive Spatial Field Modeling for 3D Visual Reasoning</a></h3>
                <p class="meta">By Haoyi Jiang, Liu Liu</p>
                <p class="text">While Vision-Language Models (VLMs) exhibit exceptional 2D visual understanding, their ability to comprehend and reason about 3D space--a cornerstone of spatial intelligence--remains superficial. Current methodologies attempt to bridge this domain gap either by relying on explici...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-24</div>
                <h3><a href="http://arxiv.org/abs/2602.21178v1" target="_blank">âš¡ XMorph: Explainable Brain Tumor Analysis Via LLM-Assisted Hybrid Deep Intelligence</a></h3>
                <p class="meta">By Sepehr Salem Ghahfarokhi, M. Moein Esfahani</p>
                <p class="text">Deep learning has significantly advanced automated brain tumor diagnosis, yet clinical adoption remains limited by interpretability and computational constraints. Conventional models often act as opaque ''black boxes'' and fail to quantify the complex, irregular tumor boundaries ...</p>
            </div>
            
            </div>
        </section>
        
    </body>
    </html>
    