
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>The Silicon Scroll | AI Research</title>
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@900&family=Libre+Baskerville:wght@400;700&display=swap');
            
            body { background: #f4f1ea; color: #1a1a1a; font-family: 'Libre Baskerville', serif; margin: 0; padding: 2vw; }
            .masthead { text-align: center; border-bottom: 5px double #333; margin-bottom: 40px; padding-bottom: 15px; }
            .masthead h1 { font-family: 'Playfair Display'; font-size: 5rem; margin: 0; letter-spacing: -2px; }
            
            .news-desk { margin-bottom: 50px; }
            .desk-title { 
                border-bottom: 2px solid #333; 
                font-family: 'Playfair Display'; 
                font-size: 1.8rem; 
                margin-bottom: 15px; 
                padding-bottom: 5px; 
                display: flex; 
                justify-content: space-between; 
                align-items: center; 
            }
            .desk-title span { font-size: 0.7rem; font-family: 'Libre Baskerville'; opacity: 0.5; }
            
            .horizontal-scroll { 
                display: flex; 
                overflow-x: auto; 
                gap: 25px; 
                padding-bottom: 20px;
                scrollbar-width: thin;
                scrollbar-color: #333 #f4f1ea;
            }
            
            .horizontal-scroll::-webkit-scrollbar { height: 8px; }
            .horizontal-scroll::-webkit-scrollbar-thumb { background: #333; border-radius: 4px; }

            .card { 
                flex: 0 0 350px; 
                background: #fffefc; 
                border: 1px solid #d1cec1; 
                padding: 25px; 
                box-shadow: 4px 4px 0px rgba(0,0,0,0.05);
                transition: transform 0.2s;
            }
            .card:hover { transform: translateY(-5px); }
            
            .card-date { font-size: 10px; font-weight: bold; color: #777; margin-bottom: 10px; }
            h3 { font-family: 'Playfair Display'; font-size: 1.3rem; margin: 0 0 10px 0; line-height: 1.2; }
            h3 a { color: #1a1a1a; text-decoration: none; }
            .meta { font-size: 11px; font-weight: bold; text-transform: uppercase; color: #555; margin-bottom: 10px; display: block; }
            .text { font-size: 13px; line-height: 1.6; color: #333; }

            .ai-accent { border-top: 6px solid #2c3e50; }
            .nlp-accent { border-top: 6px solid #27ae60; }
            .vision-accent { border-top: 6px solid #e67e22; }
        </style>
    </head>
    <body>
        <div class="masthead">
            <div style="font-size: 50px; margin-bottom: 10px;">ðŸ¦‰</div>
            <h1>The Silicon Scroll</h1>
            <p>TEMPE, AZ â€” FEBRUARY 15, 2026 â€” LATEST RESEARCH</p>
        </div>
        
        <section class="news-desk">
            <h2 class="desk-title">AI & REINFORCEMENT DESK <span>SCROLL FOR MORE â†’</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12281v1" target="_blank">Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment</a></h3>
                <p class="meta">By Jacky Kwok, Xilun Zhang</p>
                <p class="text">The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given i...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12278v1" target="_blank">AttentionRetriever: Attention Layers are Secretly Long Document Retrievers</a></h3>
                <p class="meta">By David Jiahao Fu, Lam Thanh Do</p>
                <p class="text">Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12276v1" target="_blank">Agentic Test-Time Scaling for WebAgents</a></h3>
                <p class="meta">By Nicholas Lee, Lutfi Eren Erdogan</p>
                <p class="text">Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive polici...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12270v1" target="_blank">Creative Ownership in the Age of AI</a></h3>
                <p class="meta">By Annie Liang, Jay Lu</p>
                <p class="text">Copyright law focuses on whether a new work is "substantially similar" to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to thi...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12268v1" target="_blank">CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use</a></h3>
                <p class="meta">By Zhen Zhang, Kaiqiang Song</p>
                <p class="text">AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphas...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12259v1" target="_blank">Think like a Scientist: Physics-guided LLM Agent for Equation Discovery</a></h3>
                <p class="meta">By Jianke Yang, Ohm Venkatachalam</p>
                <p class="text">Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12257v1" target="_blank">On the implicit regularization of Langevin dynamics with projected noise</a></h3>
                <p class="meta">By Govind Menon, Austin J. Stromme</p>
                <p class="text">We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12249v1" target="_blank">"Sorry, I Didn't Catch That": How Speech Models Miss What Matters Most</a></h3>
                <p class="meta">By Kaitlyn Zhou, Martijn Bartelds</p>
                <p class="text">Despite speech recognition systems achieving low word error rates on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S. p...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12247v1" target="_blank">ExtractBench: A Benchmark and Evaluation Methodology for Complex Structured Extraction</a></h3>
                <p class="meta">By Nick Ferguson, Josh Pennington</p>
                <p class="text">Unstructured documents like PDFs contain valuable structured information, but downstream systems require this data in reliable, standardized formats. LLMs are increasingly deployed to automate this extraction, making accuracy and reliability paramount. However, progress is bottle...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12245v1" target="_blank">Intrinsic-Energy Joint Embedding Predictive Architectures Induce Quasimetric Spaces</a></h3>
                <p class="meta">By Anthony Kobanda, Waris Radji</p>
                <p class="text">Joint-Embedding Predictive Architectures (JEPAs) aim to learn representations by predicting target embeddings from context embeddings, inducing a scalar compatibility energy in a latent space. In contrast, Quasimetric Reinforcement Learning (QRL) studies goal-conditioned control ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12237v1" target="_blank">Olmix: A Framework for Data Mixing Throughout LM Development</a></h3>
                <p class="meta">By Mayee F. Chen, Tyler Murray</p>
                <p class="text">Data mixing -- determining the ratios of data from different domains -- is a first-order concern for training language models (LMs). While existing mixing methods show promise, they fall short when applied during real-world LM development. We present Olmix, a framework that addre...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12236v1" target="_blank">Energy-Aware Spike Budgeting for Continual Learning in Spiking Neural Networks for Neuromorphic Vision</a></h3>
                <p class="meta">By Anika Tabassum Meem, Muntasir Hossain Nadid</p>
                <p class="text">Neuromorphic vision systems based on spiking neural networks (SNNs) offer ultra-low-power perception for event-based and frame-based cameras, yet catastrophic forgetting remains a critical barrier to deployment in continually evolving environments. Existing continual learning met...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12224v1" target="_blank">Bandit Learning in Matching Markets with Interviews</a></h3>
                <p class="meta">By Amirmahdi Mirfakhar, Xuchuang Wang</p>
                <p class="text">Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matc...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12222v1" target="_blank">Towards On-Policy SFT: Distribution Discriminant Theory and its Applications in LLM Training</a></h3>
                <p class="meta">By Miaosen Zhang, Yishan Liu</p>
                <p class="text">Supervised fine-tuning (SFT) is computationally efficient but often yields inferior generalization compared to reinforcement learning (RL). This gap is primarily driven by RL's use of on-policy data. We propose a framework to bridge this chasm by enabling On-Policy SFT. We first ...</p>
            </div>
            
            <div class="card ai-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12218v1" target="_blank">The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics</a></h3>
                <p class="meta">By Christian InternÃ², Jumpei Yamaguchi</p>
                <p class="text">Determining whether neural models internalize physical laws as world models, rather than exploiting statistical shortcuts, remains challenging, especially under out-of-distribution (OOD) shifts. Standard evaluations often test latent capability via downstream adaptation (e.g., fi...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">NLP & LANGUAGE DESK <span>SCROLL FOR MORE â†’</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12275v1" target="_blank">On-Policy Context Distillation for Language Models</a></h3>
                <p class="meta">By Tianzhu Ye, Li Dong</p>
                <p class="text">Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12262v1" target="_blank">T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization</a></h3>
                <p class="meta">By Tunyu Zhang, Xinxi Zhang</p>
                <p class="text">Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of step...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12251v1" target="_blank">A technical curriculum on language-oriented artificial intelligence in translation and specialised communication</a></h3>
                <p class="meta">By Ralph KrÃ¼ger</p>
                <p class="text">This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communi...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12241v1" target="_blank">Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications</a></h3>
                <p class="meta">By Manjunath Kudlur, Evan King</p>
                <p class="text">Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12235v1" target="_blank">Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation</a></h3>
                <p class="meta">By Julia Belikova, Danila Rozhevskii</p>
                <p class="text">Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller s...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12203v1" target="_blank">ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images</a></h3>
                <p class="meta">By Mathieu Sibue, Andres MuÃ±oz Garza</p>
                <p class="text">Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12196v1" target="_blank">Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education</a></h3>
                <p class="meta">By Mohamed Huti, Alasdair Mackintosh</p>
                <p class="text">AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual rea...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12192v1" target="_blank">Query-focused and Memory-aware Reranker for Long Context Processing</a></h3>
                <p class="meta">By Yuqing Li, Jiangnan Li</p>
                <p class="text">Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverag...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12153v1" target="_blank">dVoting: Fast Voting for dLLMs</a></h3>
                <p class="meta">By Sicheng Feng, Zigeng Chen</p>
                <p class="text">Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with s...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12137v1" target="_blank">CitiLink-Minutes: A Multilayer Annotated Dataset of Municipal Meeting Minutes</a></h3>
                <p class="meta">By Ricardo Campos, Ana Filipa Pacheco</p>
                <p class="text">City councils play a crucial role in local governance, directly influencing citizens' daily lives through decisions made during municipal meetings. These deliberations are formally documented in meeting minutes, which serve as official records of discussions, decisions, and votin...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12135v1" target="_blank">WavBench: Benchmarking Reasoning, Colloquialism, and Paralinguistics for End-to-End Spoken Dialogue Models</a></h3>
                <p class="meta">By Yangzhuo Li, Shengpeng Ji</p>
                <p class="text">With the rapid integration of advanced reasoning capabilities into spoken dialogue models, the field urgently demands benchmarks that transcend simple interactions to address real-world complexity. However, current evaluations predominantly adhere to text-generation standards, ov...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12132v1" target="_blank">A Rule-based Computational Model for Gaidhlig Morphology</a></h3>
                <p class="meta">By Peter J Barclay</p>
                <p class="text">Language models and software tools are essential to support the continuing vitality of lesser-used languages; however, currently popular neural models require considerable data for training, which normally is not available for such low-resource languages. This paper describes wor...</p>
            </div>
            
            <div class="card nlp-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12116v1" target="_blank">P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling</a></h3>
                <p class="meta">By Pinyi Zhang, Ting-En Lin</p>
                <p class="text">Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two...</p>
            </div>
            
            </div>
        </section>
        
        <section class="news-desk">
            <h2 class="desk-title">VISION & MULTIMODAL DESK <span>SCROLL FOR MORE â†’</span></h2>
            <div class="horizontal-scroll">
                
            <div class="card vision-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12280v1" target="_blank">Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching</a></h3>
                <p class="meta">By Huai-Hsun Cheng, Siang-Ling Zhang</p>
                <p class="text">Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12279v1" target="_blank">UniT: Unified Multimodal Chain-of-Thought Test-time Scaling</a></h3>
                <p class="meta">By Leon Liangyu Chen, Haoyu Ma</p>
                <p class="text">Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple in...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12271v1" target="_blank">MonarchRT: Efficient Attention for Real-Time Video Generation</a></h3>
                <p class="meta">By Krish Agarwal, Zhuoming Chen</p>
                <p class="text">Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more in...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12221v1" target="_blank">Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching</a></h3>
                <p class="meta">By Onkar Susladkar, Tushar Prakash</p>
                <p class="text">We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel ref...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12205v1" target="_blank">DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing</a></h3>
                <p class="meta">By Dianyi Wang, Ruihang Li</p>
                <p class="text">Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehen...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12177v1" target="_blank">EO-VAE: Towards A Multi-sensor Tokenizer for Earth Observation Data</a></h3>
                <p class="meta">By Nils Lehmann, Yi Wang</p>
                <p class="text">State-of-the-art generative image and video models rely heavily on tokenizers that compress high-dimensional inputs into more efficient latent representations. While this paradigm has revolutionized RGB generation, Earth observation (EO) data presents unique challenges due to div...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12160v1" target="_blank">DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation</a></h3>
                <p class="meta">By Xu Guo, Fulong Ye</p>
                <p class="text">Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as is...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12157v1" target="_blank">TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation</a></h3>
                <p class="meta">By Ziteng Lu, Yushuang Wu</p>
                <p class="text">High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods,...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12155v1" target="_blank">FAIL: Flow Matching Adversarial Imitation Learning for Image Generation</a></h3>
                <p class="meta">By Yeyao Ma, Chen Li</p>
                <p class="text">Post-training of flow matching models-aligning the output distribution with a high-quality target-is mathematically equivalent to imitation learning. While Supervised Fine-Tuning mimics expert demonstrations effectively, it cannot correct policy drift in unseen states. Preference...</p>
            </div>
            
            <div class="card vision-accent">
                <div class="card-date">2026-02-12</div>
                <h3><a href="http://arxiv.org/abs/2602.12127v1" target="_blank">PosterOmni: Generalized Artistic Poster Creation via Task Distillation and Unified Reward Feedback</a></h3>
                <p class="meta">By Sixiang Chen, Jianyu Lai</p>
                <p class="text">Image-to-poster generation is a high-demand task requiring not only local adjustments but also high-level design understanding. Models must generate text, layout, style, and visual elements while preserving semantic fidelity and aesthetic coherence. The process spans two regimes:...</p>
            </div>
            
            </div>
        </section>
        
    </body>
    </html>
    